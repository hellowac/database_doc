<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>数据库相关的记录文档</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item affix "><a href="introduction.html">简介</a></li><li class="spacer"></li><li class="chapter-item "><div>SQL</div></li><li class="chapter-item "><a href="mysql/index.html">MySQL</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="mysql/introduction.html">简介</a></li></ol></li><li class="chapter-item "><a href="postgre/index.html">PostgreSQL</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="postgre/introduction.html">简介</a></li></ol></li><li class="chapter-item "><a href="clickhouse/index.html">ClickHouse</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="clickhouse/clickhouse-sqlalchemy.html">Clickhouse-SQLAlchemy</a></li><li class="chapter-item "><a href="clickhouse/clickhouse-driver.html">Clickhouse-driver</a></li><li class="chapter-item "><a href="clickhouse/connecti.html">连接数据库</a></li><li class="chapter-item "><a href="clickhouse/inner_tools.html">内置工具</a></li><li class="chapter-item "><a href="clickhouse/define_data.html">数据定义</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="clickhouse/define_data_base_type.html">基础数据类型</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="clickhouse/base_type_int.html">数值类型</a></li><li class="chapter-item "><a href="clickhouse/base_type_string.html">字符串类型</a></li><li class="chapter-item "><a href="clickhouse/base_type_datetime.html">时间类型</a></li></ol></li><li class="chapter-item "><a href="clickhouse/define_data_complex_type.html">复合数据类型</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="clickhouse/complex_type_array.html">数组</a></li><li class="chapter-item "><a href="clickhouse/complex_type_tuple.html">元组</a></li><li class="chapter-item "><a href="clickhouse/complex_type_enum.html">枚举</a></li><li class="chapter-item "><a href="clickhouse/complex_type_nested.html">嵌套</a></li></ol></li><li class="chapter-item "><a href="clickhouse/special_type.html">特殊类型</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="clickhouse/special_type_nullable.html">Nullable</a></li><li class="chapter-item "><a href="clickhouse/special_type_domain.html">Domain</a></li></ol></li></ol></li><li class="chapter-item "><a href="clickhouse/define_data_table_index.html">定义数据表</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="clickhouse/define_database.html">数据库</a></li><li class="chapter-item "><a href="clickhouse/define_data_table.html">数据表</a></li><li class="chapter-item "><a href="clickhouse/define_field_default.html">字段默认值表达式</a></li><li class="chapter-item "><a href="clickhouse/define_temp_data_table.html">临时表</a></li><li class="chapter-item "><a href="clickhouse/define_partition_data_table.html">分区表</a></li><li class="chapter-item "><a href="clickhouse/define_view_data_table.html">视图</a></li></ol></li><li class="chapter-item "><a href="clickhouse/op_table_index.html">表的操作</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="clickhouse/op_table_add_column.html">追加字段</a></li><li class="chapter-item "><a href="clickhouse/op_table_alter_data_type.html">修改数据类型</a></li><li class="chapter-item "><a href="clickhouse/op_table_alter_comment.html">修改备注</a></li><li class="chapter-item "><a href="clickhouse/op_table_delete_column.html">删除已有字段</a></li><li class="chapter-item "><a href="clickhouse/op_table_move_data.html">移动数据表</a></li><li class="chapter-item "><a href="clickhouse/op_table_truncate_data.html">清空数据表</a></li></ol></li><li class="chapter-item "><a href="clickhouse/op_partition_index.html">数据分区操作</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="clickhouse/op_partition_query.html">查询分区信息</a></li><li class="chapter-item "><a href="clickhouse/op_partition_delete.html">删除指定分区</a></li><li class="chapter-item "><a href="clickhouse/op_partition_copy.html">复制分区数据</a></li><li class="chapter-item "><a href="clickhouse/op_partition_reset.html">重置分区数据</a></li><li class="chapter-item "><a href="clickhouse/op_partition_load.html">卸载与装载分区</a></li><li class="chapter-item "><a href="clickhouse/op_partition_backup.html">备份与还原分区</a></li></ol></li><li class="chapter-item "><a href="clickhouse/op_distribute_ddl.html">分布式DDL执行</a></li><li class="chapter-item "><a href="clickhouse/insert_data.html">数据的写入</a></li><li class="chapter-item "><a href="clickhouse/modify_and_delete_data.html">数据的删除与修改</a></li><li class="chapter-item "><a href="clickhouse/replicas_and_shards.html">副本与分片</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="clickhouse/data_replicas.html">数据副本</a></li><li class="chapter-item "><a href="clickhouse/replicated_megetree_principle.html">ReplicatedMergeTree原理解析</a></li><li class="chapter-item "><a href="clickhouse/data_shards.html">数据分片</a></li><li class="chapter-item "><a href="clickhouse/distribute_principle.html">Distributed原理解析</a></li></ol></li><li class="chapter-item "><a href="clickhouse/manage_and_op_index.html">管理与运维</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="clickhouse/manage_user_config.html">用户配置</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="clickhouse/manage_user_profile.html">用户profile</a></li><li class="chapter-item "><a href="clickhouse/manage_user_constraint.html">用户约束</a></li><li class="chapter-item "><a href="clickhouse/manage_user_define.html">用户定义</a></li></ol></li><li class="chapter-item "><a href="clickhouse/manage_authority.html">权限管理</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="clickhouse/authority_access.html">访问权限</a></li><li class="chapter-item "><a href="clickhouse/authority_query.html">查询权限</a></li><li class="chapter-item "><a href="clickhouse/authority_row.html">数据行级权限</a></li></ol></li><li class="chapter-item "><a href="clickhouse/manage_circuit.html">熔断机制</a></li><li class="chapter-item "><a href="clickhouse/manage_data_backup.html">数据备份</a></li><li class="chapter-item "><a href="clickhouse/manage_service_monitor.html">服务监控</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><div>系统表</div></li><li class="chapter-item "><div>查询日志</div></li></ol></li></ol></li></ol></li><li class="chapter-item "><a href="scripts/script_select_size.html">常用语句</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="scripts/select_data_size.html">查询数据大小</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">数据库相关的记录文档</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="简介"><a class="header" href="#简介">简介</a></h1>
<p>本文档主要记录与数据库相关的技术、技巧、问题等。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mysql"><a class="header" href="#mysql">MySQL</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="简介-1"><a class="header" href="#简介-1">简介</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="postgresql"><a class="header" href="#postgresql">PostgreSQL</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="简介-2"><a class="header" href="#简介-2">简介</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="clickhouse"><a class="header" href="#clickhouse">ClickHouse</a></h1>
<p>官网：<a href="https://clickhouse.com/docs/en/">https://clickhouse.com/docs/en/</a></p>
<p>ClickHouse拥有完备的管理功能，所以它称得上是一个DBMS（Database Management System，数据库管理系统），而不仅是一个数据库。一些基本功能，如下所示：</p>
<ul>
<li><strong>DDL</strong>（数据定义语言）：可以动态地创建、修改或删除数据库、表和视图，而无须重启服务。</li>
<li><strong>DML</strong>（数据操作语言）：可以动态查询、插入、修改或删除数据。</li>
<li><strong>权限控制</strong>：可以按照用户粒度设置数据库或者表的操作权限，保障数据的安全性。</li>
<li><strong>数据备份与恢复</strong>：提供了数据备份导出与导入恢复机制，满足生产环境的要求。</li>
<li><strong>分布式管理</strong>：提供集群模式，能够自动管理多个数据库节点。</li>
</ul>
<p>ClickHouse就是一款使用<code>列式存储</code>的数据库，数据按列进行组织，属于同一列的数据会被保存在一起，列与列之间也会由不同的文件分别保存. 【主要针对<a href="https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/mergetree/">MergeTree</a>引擎】</p>
<p>ClickHouse目前利用<code>SSE4.2指令集</code>实现向量化执行。</p>
<p>ClickHouse是大小写敏感的，这意味着<code>SELECT a</code>和<code>SELECT A</code>所代表的语义是不同的。</p>
<p>ClickHouse在数据存取方面，既支持分区（纵向扩展，利用多线程原理），也支持分片（横向扩展，利用分布式原理），ClickHouse将多线程和分布式的技术应用到了极致。</p>
<p>ClickHouse则采用<code>Multi-Master多主架构</code>，集群中的每个节点角色对等，客户端访问任意一个节点都能得到相同的效果。</p>
<p>ClickHouse支持分片，而分片则依赖集群。每个集群由1到多个分片组成，而每个分片则对应了ClickHouse的1个服务节点。分片的数量上限取决于节点数量（1个分片只能对应1个服务节点）。【数据分片是将数据进行横向切分，这是一种在面对海量数据的场景下，解决存储和查询瓶颈的有效手段，是一种分治思想的体现。】</p>
<p>ClickHouse提供了本地表（Local Table）与分布式表（Distributed Table）的概念。一张本地表等同于一份数据的分片。而分布式表本身不存储任何数据，它是本地表的访问代理，其作用类似分库中间件。借助分布式表，能够代理访问多个数据分片，从而实现分布式查询。</p>
<div style="break-before: page; page-break-before: always;"></div><ul>
<li><a href="clickhouse/clickhouse-sqlalchemy.html#clickhouse-sqlalchemy">Clickhouse-SQLAlchemy</a>
<ul>
<li><a href="clickhouse/clickhouse-sqlalchemy.html#%E5%AE%89%E8%A3%85">安装</a>
<ul>
<li><a href="clickhouse/clickhouse-sqlalchemy.html#%E6%8E%A5%E5%8F%A3%E6%94%AF%E6%8C%81">接口支持</a></li>
</ul>
</li>
<li><a href="clickhouse/clickhouse-sqlalchemy.html#%E8%BF%9E%E6%8E%A5%E5%8F%82%E6%95%B0">连接参数</a>
<ul>
<li><a href="clickhouse/clickhouse-sqlalchemy.html#%E9%A9%B1%E5%8A%A8%E9%80%89%E9%A1%B9">驱动选项</a></li>
</ul>
</li>
<li><a href="clickhouse/clickhouse-sqlalchemy.html#%E5%8A%9F%E8%83%BD">功能</a>
<ul>
<li><a href="clickhouse/clickhouse-sqlalchemy.html#sqlalchemy-%E5%A3%B0%E6%98%8E%E5%BC%8F%E6%94%AF%E6%8C%81">SQLAlchemy 声明式支持</a></li>
<li><a href="clickhouse/clickhouse-sqlalchemy.html#%E5%9F%BA%E6%9C%AC%E7%9A%84ddl%E6%95%B0%E6%8D%AE%E5%AE%9A%E4%B9%89%E6%94%AF%E6%8C%81">基本的DDL(数据定义)支持</a></li>
<li><a href="clickhouse/clickhouse-sqlalchemy.html#%E5%9F%BA%E6%9C%AC-insert-%E5%AD%90%E5%8F%A5%E6%94%AF%E6%8C%81">基本 INSERT 子句支持</a></li>
<li><a href="clickhouse/clickhouse-sqlalchemy.html#%E5%B8%B8%E8%A7%81%E7%9A%84-sqlalchemy-%E9%93%BE%E5%BC%8F%E6%9F%A5%E8%AF%A2%E6%96%B9%E6%B3%95">常见的 SQLAlchemy 链式查询方法</a></li>
<li><a href="clickhouse/clickhouse-sqlalchemy.html#%E9%AB%98%E7%BA%A7-insert-%E5%AD%90%E5%8F%A5%E6%94%AF%E6%8C%81">高级 INSERT 子句支持</a></li>
<li><a href="clickhouse/clickhouse-sqlalchemy.html#%E7%94%A8%E4%BA%8E%E6%9F%A5%E8%AF%A2%E5%A4%84%E7%90%86%E7%9A%84%E5%A4%96%E9%83%A8%E6%95%B0%E6%8D%AE">用于查询处理的外部数据</a></li>
<li><a href="clickhouse/clickhouse-sqlalchemy.html#%E6%94%AF%E6%8C%81%E7%9A%84-clickhouse-%E7%89%B9%E5%88%AB%E7%9A%84-sql">支持的 ClickHouse 特别的 SQL</a></li>
</ul>
</li>
<li><a href="clickhouse/clickhouse-sqlalchemy.html#%E8%A6%86%E7%9B%96%E9%BB%98%E8%AE%A4%E6%9F%A5%E8%AF%A2%E8%AE%BE%E7%BD%AE">覆盖默认查询设置</a></li>
<li><a href="clickhouse/clickhouse-sqlalchemy.html#%E8%BF%90%E8%A1%8C%E6%B5%8B%E8%AF%95">运行测试</a></li>
</ul>
</li>
</ul>
<h1 id="clickhouse-sqlalchemy"><a class="header" href="#clickhouse-sqlalchemy">Clickhouse-SQLAlchemy</a></h1>
<p>原文: <a href="https://github.com/xzkostyan/clickhouse-sqlalchemy/blob/master/README.rst">https://github.com/xzkostyan/clickhouse-sqlalchemy/blob/master/README.rst</a></p>
<p><strong>ClickHouse SQLAlchemy</strong> <a href="http://docs.sqlalchemy.org/en/latest/">SQLAlchemy</a>的连接Clickhouse数据库的方言版本。</p>
<h2 id="安装"><a class="header" href="#安装">安装</a></h2>
<p>可以使用 pip 安装该软件包：</p>
<pre><code class="language-text">`pip install clickhouse-sqlalchemy`
</code></pre>
<h3 id="接口支持"><a class="header" href="#接口支持">接口支持</a></h3>
<ul>
<li>native 方式: 通过 <a href="https://github.com/mymarilyn/clickhouse-driver">clickhouse-driver</a> 【推荐】【TCP】</li>
<li>http 方式: 通过 <a href="https://2.python-requests.org/en/latest/">requests</a></li>
</ul>
<h2 id="连接参数"><a class="header" href="#连接参数">连接参数</a></h2>
<p>ClickHouse SQLAlchemy 使用下面的语法作为连接字符串:</p>
<pre><code class="language-text">'clickhouse+&lt;driver&gt;://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;database&gt;[?key=value..]'
</code></pre>
<p>注意:</p>
<ul>
<li><em>driver</em> 是驱动选项. 可选: <code>http</code>, <code>native</code>. 默认为 <code>http</code>.</li>
<li><em>database</em> 是要连接的数据库. 默认为 <code>default</code>数据库.</li>
</ul>
<h3 id="驱动选项"><a class="header" href="#驱动选项">驱动选项</a></h3>
<p>可以在查询字符串中指定几个选项。</p>
<p><strong>HTTP</strong></p>
<ul>
<li><code>port</code> 是ClickHouse绑定的端口. 默认为 <code>8123</code>.</li>
<li><code>timeout</code> 以秒为单位的超时. 无默认值.</li>
<li><code>protocol</code> 要使用的协议. 可选: <code>http</code>, <code>https</code>. 默认为 <code>http</code>.</li>
</ul>
<p>安装ClickHouse后，默认的测试连接字符串是：</p>
<pre><code class="language-text">'clickhouse://default:@localhost/test'
</code></pre>
<p>当您使用 nginx 作为 ClickHouse 的代理服务器时，服务器连接字符串可能如下所示：</p>
<pre><code class="language-text">'clickhouse://user:password@example.com:8124/test?protocol=https'
</code></pre>
<p>这里的<code>8124</code>是代理端口。</p>
<p>如果您需要控制底层 HTTP 连接，请将 <a href="https://requests.readthedocs.io/en/master/user/advanced/#session-objects">requests.Session</a> 实例传递给 <code>create_engine()</code>，如下所示：</p>
<pre><code class="language-python">from sqlalchemy import create_engine
from requests import Session

uri = 'clickhouse://default:@localhost/test'

engine = create_engine(uri, connect_args={'http_session': Session()})
</code></pre>
<p><strong>Native</strong></p>
<p>请注意，<code>native</code>连接方式未加密。 包括用户/密码在内的所有数据都以纯文本形式传输。 通过不受信任的网络进行通信时，您应该通过 <code>SSH</code> 或 <code>VPN</code>（例如）使用此连接。</p>
<p>安装ClickHouse后，默认的测试连接字符串是：</p>
<pre><code class="language-text">'clickhouse+native://default:@localhost/test'
</code></pre>
<p>所有连接字符串参数都代理到 clickhouse-driver。 参考其<a href="https://clickhouse-driver.readthedocs.io/en/latest/api.html#clickhouse_driver.connection.Connection">parameters</a></p>
<h2 id="功能"><a class="header" href="#功能">功能</a></h2>
<h3 id="sqlalchemy-声明式支持"><a class="header" href="#sqlalchemy-声明式支持">SQLAlchemy 声明式支持</a></h3>
<p>ORM声明式和构造表的函数式两种方式都支持：</p>
<pre><code class="language-python">from sqlalchemy import create_engine, Column, MetaData, literal

from clickhouse_sqlalchemy import Table, make_session, get_declarative_base, types, engines

uri = 'clickhouse://default:@localhost/test'

engine = create_engine(uri)
session = make_session(engine)
metadata = MetaData(bind=engine)

Base = get_declarative_base(metadata=metadata)

class Rate(Base):
    day = Column(types.Date, primary_key=True)
    value = Column(types.Int32)
    other_value = Column(
        types.DateTime,
        clickhouse_codec=('DoubleDelta', 'ZSTD'),
    )

    __table_args__ = (
        engines.Memory(),
    )

another_table = Table('another_rate', metadata,
    Column('day', types.Date, primary_key=True),
    Column('value', types.Int32, server_default=literal(1)),
    engines.Memory()
)
</code></pre>
<p>以声明方式创建的表名具有小写字母，单词由下划线命名约定分隔。 但是您可以通过 SQLAlchemy 的 <code>__tablename__</code> 属性轻松设置您自己的表名。</p>
<h3 id="基本的ddl数据定义支持"><a class="header" href="#基本的ddl数据定义支持">基本的DDL(数据定义)支持</a></h3>
<p>您可以发出简单的 DDL。 例如 CREATE/DROP 表：</p>
<pre><code class="language-python">table = Rate.__table__
table.create()
another_table.create()


another_table.drop()
table.drop()
</code></pre>
<h3 id="基本-insert-子句支持"><a class="header" href="#基本-insert-子句支持">基本 INSERT 子句支持</a></h3>
<p>简单的批量插入：</p>
<pre><code class="language-python">from datetime import date, timedelta
from sqlalchemy import func

today = date.today()
rates = [{'day': today - timedelta(i), 'value': 200 - i} for i in range(100)]

# Emits single INSERT statement.
session.execute(table.insert(), rates)
</code></pre>
<h3 id="常见的-sqlalchemy-链式查询方法"><a class="header" href="#常见的-sqlalchemy-链式查询方法">常见的 SQLAlchemy 链式查询方法</a></h3>
<p><code>order_by</code>, <code>filter</code>, <code>limit</code>, <code>offset</code>等都是支持的：</p>
<pre><code class="language-python">session.query(func.count(Rate.day)) \
    .filter(Rate.day &gt; today - timedelta(20)) \
    .scalar()

session.query(Rate.value) \
    .order_by(Rate.day.desc()) \
    .first()

session.query(Rate.value) \
    .order_by(Rate.day) \
    .limit(10) \
    .all()

session.query(func.sum(Rate.value)) \
    .scalar()
</code></pre>
<h3 id="高级-insert-子句支持"><a class="header" href="#高级-insert-子句支持">高级 INSERT 子句支持</a></h3>
<p>INSERT FROM SELECT 语句:</p>
<pre><code class="language-python">from sqlalchemy import cast

# Labels must be present.
select_query = session.query(
    Rate.day.label('day'),
    cast(Rate.value * 1.5, types.Int32).label('value')
).subquery()

# Emits single INSERT FROM SELECT statement
session.execute(
    another_table.insert()
    .from_select(['day', 'value'], select_query)
)
</code></pre>
<p>许多但不是所有的 SQLAlchemy 特性都支持开箱即用。</p>
<p>UNION ALL 示例：</p>
<pre><code class="language-python">from sqlalchemy import union_all

select_rate = session.query(
    Rate.day.label('date'),
    Rate.value.label('x')
)
select_another_rate = session.query(
    another_table.c.day.label('date'),
    another_table.c.value.label('x')
)

union_all(select_rate, select_another_rate).execute().fetchone()
</code></pre>
<h3 id="用于查询处理的外部数据"><a class="header" href="#用于查询处理的外部数据">用于查询处理的外部数据</a></h3>
<p>目前可以与native方式的接口一起使用:</p>
<pre><code class="language-python">ext = Table(
    'ext', metadata, Column('x', types.Int32),
    clickhouse_data=[(101, ), (103, ), (105, )], extend_existing=True
)

rv = session.query(Rate) \
    .filter(Rate.value.in_(session.query(ext.c.x))) \
    .execution_options(external_tables=[ext]) \
    .all()

print(rv)
</code></pre>
<h3 id="支持的-clickhouse-特别的-sql"><a class="header" href="#支持的-clickhouse-特别的-sql">支持的 ClickHouse 特别的 SQL</a></h3>
<ul>
<li><strong>SELECT query</strong>:
<ul>
<li><strong>WITH TOTALS</strong></li>
<li><strong>SAMPLE</strong></li>
<li><strong>lambda functions: x -&gt; expr</strong></li>
<li><strong>JOIN</strong></li>
</ul>
</li>
</ul>
<p>示例请参考 <a href="https://github.com/xzkostyan/clickhouse-sqlalchemy/tree/master/tests">tests</a></p>
<h2 id="覆盖默认查询设置"><a class="header" href="#覆盖默认查询设置">覆盖默认查询设置</a></h2>
<p>设置较低的查询优先级并限制执行请求的最大线程数。</p>
<pre><code class="language-python">rv = session.query(func.sum(Rate.value)) \
    .execution_options(settings={'max_threads': 2, 'priority': 10}) \
    .scalar()

print(rv)
</code></pre>
<h2 id="运行测试"><a class="header" href="#运行测试">运行测试</a></h2>
<pre><code class="language-shell">mkvirtualenv testenv &amp;&amp; python setup.py test
</code></pre>
<p><code>pip</code> 将自动安装所有必需的模块进行测试。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="clickhouse-driver"><a class="header" href="#clickhouse-driver">Clickhouse-driver</a></h1>
<p>原文: <a href="https://github.com/mymarilyn/clickhouse-driver/blob/master/README.rst">https://github.com/mymarilyn/clickhouse-driver/blob/master/README.rst</a></p>
<p>具有Native (TCP) 接口支持的 ClickHouse Python 驱动程序。</p>
<p>异步包装器可用在: <a href="https://github.com/mymarilyn/aioch">https://github.com/mymarilyn/aioch</a></p>
<h2 id="功能-1"><a class="header" href="#功能-1">功能</a></h2>
<ul>
<li>基于外部数据的查询处理支持.</li>
<li>Query查询设置.</li>
<li>压缩支持.</li>
<li>TLS 支持.</li>
<li>类型支持:
<ul>
<li>Float32/64</li>
<li>[U]Int8/16/32/64/128/256</li>
<li>Date/Date32/DateTime('timezone')/DateTime64('timezone')</li>
<li>String/FixedString(N)</li>
<li>Enum8/16</li>
<li>Array(T)</li>
<li>Nullable(T)</li>
<li>Bool</li>
<li>UUID</li>
<li>Decimal</li>
<li>IPv4/IPv6</li>
<li>LowCardinality(T)</li>
<li>SimpleAggregateFunction(F, T)</li>
<li>Tuple(T1, T2, ...)</li>
<li>Nested</li>
<li>Map(key, value)</li>
</ul>
</li>
<li>Query查询进度信息。</li>
<li>基于Block块式的结果流传输.</li>
<li>读取查询配置文件信息.</li>
<li>接收服务器日志.</li>
<li>多主机支持.</li>
<li>Python DB API 2.0 规范支持.</li>
<li>可选的 NumPy 数组支持.</li>
</ul>
<h2 id="文档"><a class="header" href="#文档">文档</a></h2>
<p>文档可在 <a href="https://clickhouse-driver.readthedocs.io">https://clickhouse-driver.readthedocs.io</a> 获得。</p>
<h2 id="用法"><a class="header" href="#用法">用法</a></h2>
<p>与服务器通信有两种方式：</p>
<ol>
<li>使用纯客户端；</li>
<li>使用数据库 API。</li>
</ol>
<p><strong>纯客户端</strong> 示例：</p>
<pre><code class="language-python">&gt;&gt;&gt; from clickhouse_driver import Client
&gt;&gt;&gt;
&gt;&gt;&gt; client = Client('localhost')
&gt;&gt;&gt;
&gt;&gt;&gt; client.execute('SHOW TABLES')
[('test',)]
&gt;&gt;&gt; client.execute('DROP TABLE IF EXISTS test')
[]
&gt;&gt;&gt; client.execute('CREATE TABLE test (x Int32) ENGINE = Memory')
[]
&gt;&gt;&gt; client.execute(
...     'INSERT INTO test (x) VALUES',
...     [{'x': 100}]
... )
1
&gt;&gt;&gt; client.execute('INSERT INTO test (x) VALUES', [[200]])
1
&gt;&gt;&gt; client.execute(
...     'INSERT INTO test (x) '
...     'SELECT * FROM system.numbers LIMIT %(limit)s',
...     {'limit': 3}
... )
[]
&gt;&gt;&gt; client.execute('SELECT sum(x) FROM test')
[(303,)]
</code></pre>
<p><strong>数据库API</strong> 示例:</p>
<pre><code class="language-python">&gt;&gt;&gt; from clickhouse_driver import connect
&gt;&gt;&gt;
&gt;&gt;&gt; conn = connect('clickhouse://localhost')
&gt;&gt;&gt; cursor = conn.cursor()
&gt;&gt;&gt;
&gt;&gt;&gt; cursor.execute('SHOW TABLES')
&gt;&gt;&gt; cursor.fetchall()
[('test',)]
&gt;&gt;&gt; cursor.execute('DROP TABLE IF EXISTS test')
&gt;&gt;&gt; cursor.fetchall()
[]
&gt;&gt;&gt; cursor.execute('CREATE TABLE test (x Int32) ENGINE = Memory')
&gt;&gt;&gt; cursor.fetchall()
[]
&gt;&gt;&gt; cursor.executemany(
...     'INSERT INTO test (x) VALUES',
...     [{'x': 100}]
... )
&gt;&gt;&gt; cursor.rowcount
1
&gt;&gt;&gt; cursor.executemany('INSERT INTO test (x) VALUES', [[200]])
&gt;&gt;&gt; cursor.rowcount
1
&gt;&gt;&gt; cursor.execute(
...     'INSERT INTO test (x) '
...     'SELECT * FROM system.numbers LIMIT %(limit)s',
...     {'limit': 3}
... )
&gt;&gt;&gt; cursor.rowcount
0
&gt;&gt;&gt; cursor.execute('SELECT sum(x) FROM test')
&gt;&gt;&gt; cursor.fetchall()
[(303,)]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="连接数据库"><a class="header" href="#连接数据库">连接数据库</a></h1>
<pre><code class="language-shell">&gt; clickhouse-client -h host -p port
</code></pre>
<p><strong>常见参数:</strong></p>
<ul>
<li>
<p>--host/-h：服务端的地址，默认值为localhost。</p>
<pre><code class="language-shell">&gt; clickhouse-client -h 10.37.129.10
</code></pre>
</li>
<li>
<p>--port：服务端的TCP端口，默认值为9000。</p>
</li>
<li>
<p>--user/-u：登录的用户名，默认值为default。</p>
</li>
<li>
<p>--password：登录的密码，默认值为空。</p>
</li>
<li>
<p>--database/-d：登录的数据库，默认值为default。</p>
</li>
<li>
<p>--query/-q：只能在非交互式查询时使用，用于指定SQL语句。</p>
</li>
<li>
<p>--multiquery/-n：在非交互式执行时，允许一次运行多条SQL语句，多条语句之间以分号间隔。</p>
</li>
<li>
<p>--time/-t：在非交互式执行时，会打印每条SQL的执行时间，例如</p>
<pre><code class="language-shell">&gt; clickhouse-client -h 10.37.129.10 -n -t --query=&quot;SELECT 1;SELECT 2;&quot;
1
0.002
2
0.001
</code></pre>
</li>
<li>
<p>完整的参数列表，可以通过--help查阅。</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="内置工具"><a class="header" href="#内置工具">内置工具</a></h1>
<h2 id="clickhouse-local"><a class="header" href="#clickhouse-local">clickhouse-local</a></h2>
<p>clickhouse-local可以独立运行大部分SQL查询，不需要依赖任何ClickHouse的服务端程序，它可以理解成是ClickHouse服务的单机版微内核，是一个轻量级的应用程序。</p>
<p>clickhouse-local只能够使用File表引擎（关于表引擎的更多介绍在后续章节展开），它的数据与同机运行的ClickHouse服务也是完全隔离的，相互之间并不能访问。</p>
<p>clickhouse-local是非交互式运行的，每次执行都需要指定数据来源，例如通过stdin标准输入，以echo打印作为数据来源：</p>
<pre><code class="language-shell">&gt; echo -e &quot;1\n2\n3&quot; | clickhouse-local -q &quot;CREATE TABLE test_table (id Int64)  ENGINE = File(CSV, stdin); SELECT id FROM test_table;&quot;
1
2
3
</code></pre>
<p>也可以借助操作系统的命令，实现对系统用户内存用量的查询：</p>
<pre><code class="language-shell">&gt; ps aux | tail -n +2 | awk '{ printf(&quot;%s\t%s\n&quot;, $1, $4) }' | clickhouse-local -S &quot;user String, memory Float64&quot; -q &quot;SELECT user, round(sum(memory), 2) as memoryTotal FROM table GROUP BY user ORDER BY memoryTotal DESC FORMAT Pretty&quot;
┏----------┳-----------------------------┓
┃ user     ┃        memoryTotal          ┃
┡----------╇-----------------------------┩
│ nauu     │        42.7                 │
├──────────┼──────────----------------───┤
│ root     │        20.4                 │
├──────────┼─────────----------------────┤
│ clickho+ │         1.8                 │
└──────────┴────────----------------─────┘
</code></pre>
<p><strong>核心参数</strong>：</p>
<ul>
<li>
<p>（1）-S/--structure：表结构的简写方式，例如以下两种声明的效果是相同的。</p>
<pre><code class="language-shell">--使用-S简写
clickhouse-local -S &quot;id Int64&quot;
--使用DDL
clickhouse-local -q &quot;CREATE TABLE test_table (id Int64) ENGINE = File(CSV, stdin)&quot;
</code></pre>
</li>
<li>
<p>（2）-N/--table：表名称，默认值是table，例如下面的代码。</p>
<pre><code class="language-shell">clickhouse-local -S &quot;id Int64&quot; -N &quot;test_table&quot; -q &quot;SELECt id FROM test_table&quot;
</code></pre>
</li>
<li>
<p>（3）-if/--input-format：输入数据的格式，默认值是TSV，例如下面的代码。</p>
<pre><code class="language-shell">echo -e &quot;1\n2\n3&quot; | clickhouse-local -S &quot;id Int64&quot; -if &quot;CSV&quot; -N &quot;test_table&quot;
</code></pre>
</li>
<li>
<p>（4）-f/--file：输入数据的地址，默认值是stdin标准输入。</p>
</li>
<li>
<p>（5）-q/--query：待执行的SQL语句，多条语句之间以分号间隔。</p>
</li>
</ul>
<p>完整的参数列表可以通过--help查阅。</p>
<h2 id="clickhouse-benchmark"><a class="header" href="#clickhouse-benchmark">clickhouse-benchmark</a></h2>
<p>clickhouse-benchmark是基准测试的小工具，它可以自动运行SQL查询，并生成相应的运行指标报告，例如执行下面的语句启动测试：</p>
<pre><code class="language-shell">&gt; echo &quot;SELECT * FROM system.numbers LIMIT 100&quot; | clickhouse-benchmark -i 5
Loaded 1 queries.

# 执行之后，按照指定的参数该查询会执行5次：
Queries executed: 5.  

# 执行完毕后，会出具包含QPS、RPS等指标信息的报告：
127.0.0.1:9000, queries 5, QPS: 812.189, RPS: 81218.868, MiB/s: 0.620, result RPS: 81218.868, result MiB/s: 0.620.

# 还会出具各百分位的查询执行时间：
0.000%          0.001 sec.
10.000%         0.001 sec.
20.000%         0.001 sec.
30.000%         0.001 sec.
40.000%         0.001 sec.
50.000%         0.001 sec.
60.000%         0.001 sec.
70.000%         0.001 sec.
80.000%         0.001 sec.
90.000%         0.002 sec.
95.000%         0.002 sec.
99.000%         0.002 sec.
99.900%         0.002 sec.
99.990%         0.002 sec.

# 可以指定多条SQL进行测试，此时需要将SQL语句定义在文件中：
&gt; cat ./multi-sqls 
SELECT * FROM system.numbers LIMIT 100
SELECT * FROM system.numbers LIMIT 200

# 在multi-sqls文件内定义了两条SQL，按照定义的顺序它们会依次执行：
&gt; clickhouse-benchmark -i 5 &lt; ./multi-sqls
Loaded 2 queries.
……
</code></pre>
<p><strong>核心参数</strong>:</p>
<ul>
<li>
<p>（1）-i/--iterations：SQL查询执行的次数，默认值是0。</p>
</li>
<li>
<p>（2）-c/--concurrency：同时执行查询的并发数，默认值是1。</p>
</li>
<li>
<p>（3）-r/--randomize：在执行多条SQL语句的时候，按照随机顺序执行，例如:</p>
<pre><code class="language-shell">&gt; clickhouse-benchmark -r 1 -i 5  &lt; ./multi-sqls
</code></pre>
</li>
<li>
<p>（4）-h/--host：服务端地址，默认值是localhost。clickhouse-benchmark支持对比测试，此时需要通过此参数声明两个服务端的地址，例如:</p>
<pre><code class="language-shell">&gt; echo &quot;SELECT * FROM system.numbers LIMIT 100&quot; | clickhouse-benchmark -i 5 -h localhost -h localhost
Loaded 1 queries.

Queries executed: 5.

# 第一个服务
127.0.0.1:9000, queries 2, QPS: 878.703, RPS: 87870.258, MiB/s: 0.670, result RPS: 87870.258, result MiB/s: 0.670.
# 第二个服务
127.0.0.1:9000, queries 3, QPS: 748.210, RPS: 74820.972, MiB/s: 0.571, result RPS: 74820.972, result MiB/s: 0.571.

# 在对比测试中，clickhouse-benchmark会通过抽样的方式比较两组查询指标的差距，在默认的情况下，置信区间为99.5%：
0.000%          0.001 sec.      0.001 sec.
10.000%         0.001 sec.      0.001 sec.
20.000%         0.001 sec.      0.001 sec.
30.000%         0.001 sec.      0.001 sec.
40.000%         0.001 sec.      0.001 sec.
50.000%         0.001 sec.      0.001 sec.
60.000%         0.001 sec.      0.001 sec.
70.000%         0.001 sec.      0.001 sec.
80.000%         0.001 sec.      0.002 sec.
90.000%         0.001 sec.      0.002 sec.
95.000%         0.001 sec.      0.002 sec.
99.000%         0.001 sec.      0.002 sec.
99.900%         0.001 sec.      0.002 sec.
99.990%         0.001 sec.      0.002 sec.

No difference proven at 99.5% confidence
</code></pre>
</li>
<li>
<p>（5）--confidence：设置对比测试中置信区间的范围，默认值是5(99.5%)，它的取值范围有0(80%)、1(90%)、2(95%)、3(98%)、4(99%)和5(99.5%)。</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="数据定义"><a class="header" href="#数据定义">数据定义</a></h1>
<p>ClickHouse提供了许多数据类型，它们可以划分为基础类型、复合类型和特殊类型。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="基础数据类型"><a class="header" href="#基础数据类型">基础数据类型</a></h1>
<p>基础类型只有<code>数值</code>、<code>字符串</code>和<code>时间</code>三种类型，没有<code>Boolean</code>类型，但可以使用整型的<code>0</code>或<code>1</code>替代。</p>
<div style="break-before: page; page-break-before: always;"></div><ul>
<li><a href="clickhouse/base_type_int.html#%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B">数值类型</a>
<ul>
<li><a href="clickhouse/base_type_int.html#int">Int</a></li>
<li><a href="clickhouse/base_type_int.html#float">Float</a></li>
<li><a href="clickhouse/base_type_int.html#decimal">Decimal</a></li>
</ul>
</li>
</ul>
<h1 id="数值类型"><a class="header" href="#数值类型">数值类型</a></h1>
<p>数值类型分为<code>整数</code>、<code>浮点数</code>和<code>定点数</code>三类.</p>
<h2 id="int"><a class="header" href="#int">Int</a></h2>
<p>参考官网: <a href="https://clickhouse.com/docs/zh/sql-reference/data-types/int-uint/">https://clickhouse.com/docs/zh/sql-reference/data-types/int-uint/</a></p>
<p>创建表时，可以为整数设置类型参数 (例如. TINYINT(8), SMALLINT(16), INT(32), BIGINT(64)), 但 ClickHouse 会忽略它们.</p>
<p>有符号</p>
<table><thead><tr><th>名称</th><th>大小(字节)</th><th>范围</th><th>常用</th></tr></thead><tbody>
<tr><td>Int8</td><td>1</td><td>-128 - 127</td><td>Tinyint</td></tr>
<tr><td>Int16</td><td>2</td><td>-32768 - 32767</td><td>Smallint</td></tr>
<tr><td>Int32</td><td>4</td><td>-2147483648 - 2147483647</td><td>Int</td></tr>
<tr><td>Int64</td><td>8</td><td>-9223372036854775808 - 9223372036854775807</td><td>Bigint</td></tr>
<tr><td>Int128</td><td>16</td><td>-1701411834604692317... - 1701411834604692317...</td><td>-</td></tr>
<tr><td>Int256</td><td>32</td><td>-5789604461865809771... - 5789604461865809771...</td><td>-</td></tr>
</tbody></table>
<p>无符号</p>
<table><thead><tr><th>名称</th><th>大小(字节)</th><th>范围</th><th>常用</th></tr></thead><tbody>
<tr><td>UInt8</td><td>1</td><td>0 - 255</td><td>Tinyint Unsigned</td></tr>
<tr><td>UInt16</td><td>2</td><td>0 - 65535</td><td>Smallint Unsigned</td></tr>
<tr><td>UInt32</td><td>4</td><td>0 - 4294967295</td><td>Int Unsigned</td></tr>
<tr><td>UInt64</td><td>8</td><td>0 - 18446744073709551615</td><td>Bigint Unsigned</td></tr>
<tr><td>UInt128</td><td>16</td><td>0 - 340282366920938463463374607431768211455</td><td>-</td></tr>
<tr><td>UInt256</td><td>32</td><td>0 - 115792089237316195423570985008687907853...</td><td>-</td></tr>
</tbody></table>
<h2 id="float"><a class="header" href="#float">Float</a></h2>
<p>参考官网: <a href="https://clickhouse.com/docs/zh/sql-reference/data-types/float/">https://clickhouse.com/docs/zh/sql-reference/data-types/float/</a></p>
<p>与整数类似，ClickHouse直接使用<code>Float32</code>和<code>Float64</code>代表单精度浮点数以及双精度浮点数</p>
<table><thead><tr><th>名称</th><th>大小(字节)</th><th>有效经度(位数)</th><th>常用</th></tr></thead><tbody>
<tr><td>Float32</td><td>4</td><td>7</td><td>Float</td></tr>
<tr><td>Float64</td><td>8</td><td>16</td><td>Double</td></tr>
</tbody></table>
<p>ClickHouse的浮点数支持正无穷、负无穷以及非数字的表达方式。</p>
<ul>
<li>
<p>Inf – 正无穷</p>
<pre><code class="language-sql">&gt;) SELECT 0.5 / 0
┌─divide(0.5, 0)─┐
│            inf │
└────────────────┘
</code></pre>
</li>
<li>
<p>-Inf – 负无穷</p>
<pre><code class="language-sql">&gt;) SELECT -0.5 / 0
┌─divide(-0.5, 0)─┐
│            -inf │
└─────────────────┘
</code></pre>
</li>
<li>
<p>NaN – 非数字</p>
<pre><code class="language-sql">&gt;) SELECT 0 / 0
┌─divide(0, 0)──┐
│            nan│
└───────────────┘
</code></pre>
</li>
</ul>
<h2 id="decimal"><a class="header" href="#decimal">Decimal</a></h2>
<p>参考官网: <a href="https://clickhouse.com/docs/zh/sql-reference/data-types/decimal/">https://clickhouse.com/docs/zh/sql-reference/data-types/decimal/</a></p>
<p>更高精度的数值运算，则需要使用定点数。ClickHouse提供了Decimal32、Decimal64和Decimal128三种精度的定点数。可以通过两种形式声明定点：简写方式有Decimal32(S)、Decimal64(S)、Decimal128(S)三种，原生方式为Decimal(P,S)，其中：</p>
<ul>
<li>P代表精度，决定总位数（整数部分+小数部分），取值范围是1～38；</li>
<li>S代表规模，决定小数位数，取值范围是0～P。</li>
</ul>
<p>对应关系：</p>
<table><thead><tr><th>名称</th><th>有效声明</th><th>范围</th></tr></thead><tbody>
<tr><td>Decimal32(S)</td><td>Decimal(1 ~ 9 , S)</td><td>-1 * 10<sup>^</sup>(9-S) 至  10<sup>^</sup>(9-S)</td></tr>
<tr><td>Decimal64(S)</td><td>Decimal(10 ~ 18 , S)</td><td>-1 * 10<sup>^</sup>(18-S) 至  10<sup>^</sup>(18-S)</td></tr>
<tr><td>Decimal128(S)</td><td>Decimal(19 ~ 38 , S)</td><td>-1 * 10<sup>^</sup>(38-S) 至  10<sup>^</sup>(38-S)</td></tr>
</tbody></table>
<p>由于现代CPU不支持128位数字，因此 <code>Decimal128</code> 上的操作由软件模拟。所以 <code>Decimal128</code> 的运算速度明显慢于 <code>Decimal32</code>/<code>Decimal64</code>。</p>
<p><strong>对Decimal的二进制运算导致更宽的结果类型（无论参数的顺序如何）。</strong></p>
<ul>
<li>Decimal64(S1) &lt;op&gt; Decimal32(S2) -&gt; Decimal64(S)</li>
<li>Decimal128(S1) &lt;op&gt; Decimal32(S2) -&gt; Decimal128(S)</li>
<li>Decimal128(S1) &lt;op&gt; Decimal64(S2) -&gt; Decimal128(S)</li>
</ul>
<p><strong>精度变化的规则：</strong></p>
<ul>
<li>加法，减法：S = max(S1, S2)。</li>
<li>乘法：S = S1 + S2。</li>
<li>除法：S = S1。</li>
</ul>
<p>例如<code>toDecimal64(2,4)</code>与<code>toDecimal32(2,2)</code>相加或相减后<code>S=4</code>：</p>
<pre><code class="language-shell"># 相加
:) SELECT toDecimal64(2,4) + toDecimal32(2,2)
 
┌─plus(toDecimal64(2, 4), toDecimal32(2, 2))─┐
│ 4.0000                                     │ # 保留四位
└────────────────────────────────────────────┘

# 相减
:) SELECT toDecimal32(4,4) - toDecimal64(2,2)

┌─minus(toDecimal32(4, 4), toDecimal64(2, 2))┐
│ 2.0000                                     │ # 保留四位
└────────────────────────────────────────────┘

# toDecimal64(2,4)与toDecimal32(2,2)相乘后S=4+2=6
:) SELECT toDecimal64(2,4) * toDecimal32(2,2)

┌─multiply(toDecimal64(2, 4), toDecimal32(2, 2))┐
│ 4.000000                                      │
└───────────────────────────────────────────────┘

# toDecimal64(2,4)与toDecimal32(2,2)相除后S=4
:) SELECT toDecimal64(2,4) / toDecimal32(2,2)

┌─divide(toDecimal64(2, 4), toDecimal32(2, 2))─┐
│  1.0000                                      │
└──────────────────────────────────────────────┘

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><ul>
<li><a href="clickhouse/base_type_string.html#%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%B1%BB%E5%9E%8B">字符串类型</a>
<ul>
<li><a href="clickhouse/base_type_string.html#string">String</a></li>
<li><a href="clickhouse/base_type_string.html#fixedstring">FixedString</a></li>
<li><a href="clickhouse/base_type_string.html#uuid">UUID</a></li>
</ul>
</li>
</ul>
<h1 id="字符串类型"><a class="header" href="#字符串类型">字符串类型</a></h1>
<p>字符串类型可以细分为<code>String</code>、<code>FixedString</code>和<code>UUID</code>三类</p>
<h2 id="string"><a class="header" href="#string">String</a></h2>
<p>字符串由String定义，长度不限。因此在使用String的时候无须声明大小。它完全代替了传统意义上数据库的Varchar、Text、Clob和Blob等字符类型。String类型不限定字符集，因为它根本就没有这个概念，所以可以将任意编码的字符串存入其中。但是为了程序的规范性和可维护性，在同一套程序中应该遵循使用统一的编码，例如“统一保持UTF-8编码”就是一种很好的约定。</p>
<h2 id="fixedstring"><a class="header" href="#fixedstring">FixedString</a></h2>
<p>FixedString类型和传统意义上的Char类型有些类似，对于一些字符有明确长度的场合，可以使用固定长度的字符串。定长字符串通过FixedString(N)声明，其中N表示字符串长度。但与Char不同的是，FixedString使用null字节填充末尾字符，而Char通常使用空格填充。比如在下面的例子中，字符串‘abc’虽然只有3位，但长度却是5，因为末尾有2位空字符填充：</p>
<pre><code class="language-sql">:) SELECT toFixedString('abc',5) , LENGTH(toFixedString('abc',5)) AS LENGTH

┌─toFixedString('abc', 5)─┬─LENGTH──────┐
│ abc                     │ 5           │
└─────────────────────────┴─────────────┘
</code></pre>
<h2 id="uuid"><a class="header" href="#uuid">UUID</a></h2>
<p>UUID是一种数据库常见的主键类型，在ClickHouse中直接把它作为一种数据类型。UUID共有32位，它的格式为8-4-4-4-12。如果一个UUID类型的字段在写入数据时没有被赋值，则会依照格式使用0填充，例如：</p>
<pre><code class="language-sql">
CREATE TABLE UUID_TEST (
  c1 UUID,
  c2 String
) ENGINE = Memory;

--第一行UUID有值
INSERT INTO UUID_TEST SELECT generateUUIDv4(),'t1'
--第二行UUID没有值
INSERT INTO UUID_TEST(c2) VALUES ('t2')

:) SELECT * FROM UUID_TEST
┌─────────────────────c1─┬─c2─┐
│ f36c709e-1b73-4370-a703-f486bdd22749 │ t1 │
└───────────────────────┴────┘
┌─────────────────────c1─┬─c2─┐
│ 00000000-0000-0000-0000-000000000000 │ t2 │
└───────────────────────┴────┘
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><ul>
<li><a href="clickhouse/base_type_datetime.html#%E6%97%B6%E9%97%B4%E7%B1%BB%E5%9E%8B">时间类型</a>
<ul>
<li><a href="clickhouse/base_type_datetime.html#datetime">DateTime</a></li>
<li><a href="clickhouse/base_type_datetime.html#datetime64">DateTime64</a></li>
<li><a href="clickhouse/base_type_datetime.html#date">Date</a></li>
<li><a href="clickhouse/base_type_datetime.html#date32">Date32</a></li>
</ul>
</li>
</ul>
<h1 id="时间类型"><a class="header" href="#时间类型">时间类型</a></h1>
<p>时间类型分为<code>DateTime</code>、<code>DateTime64</code>、<code>Date</code>、<code>Date32</code>四类。ClickHouse目前没有时间戳类型。</p>
<p>时间类型最高的精度是秒，也就是说，如果需要处理毫秒、微秒等大于秒分辨率的时间，则只能借助<code>UInt</code>类型实现.</p>
<h2 id="datetime"><a class="header" href="#datetime">DateTime</a></h2>
<p>DateTime类型包含时、分、秒信息，精确到秒，支持使用字符串形式写入：</p>
<pre><code class="language-sql">CREATE TABLE Datetime_TEST (
    c1 Datetime
) ENGINE = Memory

--以字符串形式写入
INSERT INTO Datetime_TEST VALUES('2019-06-22 00:00:00')
 
 SELECT c1, toTypeName(c1) FROM Datetime_TEST

┌──────────c1─┬─toTypeName(c1)───────────┐
│ 2019-06-22 00:00:00 │  DateTime        │
└─────────────────────┴──────────────────┘
</code></pre>
<h2 id="datetime64"><a class="header" href="#datetime64">DateTime64</a></h2>
<p>DateTime64可以记录亚秒，它在DateTime之上增加了精度的设置，例如：</p>
<pre><code class="language-sql">CREATE TABLE Datetime64_TEST (
    c1 Datetime64(2)    
) ENGINE = Memory

--以字符串形式写入
INSERT INTO Datetime64_TEST VALUES('2019-06-22 00:00:00')
 
SELECT c1, toTypeName(c1) FROM Datetime64_TEST

┌─────────────c1─┬─toTypeName(c1)─────────┐
│ 2019-06-22 00:00:00.00 │ DateTime       │
└────────────────────────┴────────────────┘
</code></pre>
<h2 id="date"><a class="header" href="#date">Date</a></h2>
<p>Date类型不包含具体的时间信息，只精确到天，它同样也支持字符串形式写入：</p>
<pre><code class="language-sql">CREATE TABLE Date_TEST (
  c1 Date
) ENGINE = Memory

--以字符串形式写入
INSERT INTO Date_TEST VALUES('2019-06-22')

SELECT c1, toTypeName(c1) FROM Date_TEST

┌─────────c1─┬─toTypeName(c1)────────┐
│ 2019-06-22       │ Date            │
└──────────────────┴─────────────────┘

</code></pre>
<h2 id="date32"><a class="header" href="#date32">Date32</a></h2>
<blockquote>
<p>注意: <a href="https://clickhouse.com/docs/zh/whats-new/changelog/#clickhouse-release-v22-1-2022-01-18">v22.1</a>版本中新增支持。</p>
</blockquote>
<p>一个日期。 支持与 <a href="clickhouse/base_type_datetime.html#datetime64">Datetime64</a> 相同的日期范围。 存储自 <code>1925-01-01</code> 以来的天数，占用4个字节。 允许将日期存储到<code>2283-11-11</code>。</p>
<pre><code class="language-sql">CREATE TABLE Date32_TEST ( c1 Date32 ) ENGINE = Memory

--以字符串形式写入
INSERT INTO Date32_TEST VALUES('2282-06-22')

SELECT c1, toTypeName(c1) FROM Date32_TEST

┌─────────c1─┬─toTypeName(c1)────────┐
│ 2282-06-22       │ Date32          │
└──────────────────┴─────────────────┘
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="复合数据类型"><a class="header" href="#复合数据类型">复合数据类型</a></h1>
<p>除了基础数据类型之外，ClickHouse还提供了数组、元组、枚举和嵌套四类复合类型。这些类型通常是其他数据库原生不具备的特性。拥有了复合类型之后，ClickHouse的数据模型表达能力更强了。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="数组"><a class="header" href="#数组">数组</a></h1>
<p><strong>数组有两种定义形式</strong></p>
<ul>
<li>
<p>常规方式array(T)</p>
<pre><code class="language-sql">SELECT array(1, 2) as a , toTypeName(a)
┌─a─────┬─toTypeName(array(1, 2))─┐
│ [1,2] │ Array(UInt8)            │
└───────┴─────────────────────────┘
</code></pre>
</li>
<li>
<p>简写方式[T]:</p>
<pre><code class="language-sql">SELECT [1, 2]
</code></pre>
</li>
</ul>
<p>因为ClickHouse的数组拥有类型推断的能力, 所以在查询时并不需要主动声明数组的元素类型。</p>
<p>推断依据：以最小存储代价为原则，即使用最小可表达的数据类型。</p>
<p>例如在例子中，<code>array(1,2)</code>会通过自动推断将<code>UInt8</code>作为数组类型。但是数组元素中如果存在<code>Null</code>值，则元素类型将变为<code>Nullable</code>，例如：</p>
<pre><code class="language-sql">SELECT [1, 2, null] as a , toTypeName(a)
┌─a──────┬─toTypeName([1, 2, NULL])────┐
│ [1,2,NULL] │ Array(Nullable(UInt8))  │
└────────┴─────────────────────────────┘
</code></pre>
<p>在同一个数组内可以包含多种数据类型，例如数组<code>[1,2.0]</code>是可行的。但各类型之间必须兼容，例如数组<code>[1,'2']</code>则会报错。</p>
<p>在定义表字段时，数组需要指定明确的元素类型，例如：</p>
<pre><code class="language-sql">CREATE TABLE Array_TEST (
  c1 Array(String)
) engine = Memory
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="元组"><a class="header" href="#元组">元组</a></h1>
<p>元组类型由<code>1～n</code>个元素组成，每个元素之间允许设置不同的数据类型，且彼此之间不要求兼容。</p>
<p>元组同样支持类型推断，其推断依据仍然以最小存储代价为原则。</p>
<p>与数组类似，元组也可以使用两种方式定义:</p>
<ul>
<li>
<p><strong>常规方式</strong><code>tuple(T)</code>：</p>
<pre><code class="language-sql">
SELECT tuple(1,'a',now()) AS x, toTypeName(x)
┌─x─────────────────────────────┬─toTypeName(tuple(1, 'a', now()))──┐
│ (1,'a','2019-08-28 21:36:32') │ Tuple(UInt8, String, DateTime)    │
└───────────────────────────────┴───────────────────────────────────┘
</code></pre>
</li>
<li>
<p><strong>简写方式（T）</strong>:</p>
</li>
</ul>
<pre><code class="language-sql">SELECT (1,2.0,null) AS x, toTypeName(x)
┌─x────────────┬─toTypeName(tuple(1, 2., NULL))───────────┐
│ (1,2,NULL)   │ Tuple(UInt8, Float64, Nullable(Nothing)) │
└──────────────┴──────────────────────────────────────────┘
</code></pre>
<p>在定义表字段时，元组需要指定明确的元素类型：</p>
<pre><code class="language-sql">CREATE TABLE Tuple_TEST (
  c1 Tuple(String,Int8)
) ENGINE = Memory;
</code></pre>
<p>元素类型和泛型的作用类似，可以进一步保障数据质量。在数据写入的过程中会进行类型检查。</p>
<p>例如，写入<code>INSERT INTO Tuple_TEST VALUES(('abc',123))</code>是可行的，而写入<code>INSERT INTO Tuple_TEST VALUES(('abc','efg'))</code>则会报错。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="枚举"><a class="header" href="#枚举">枚举</a></h1>
<p>ClickHouse支持枚举类型，这是一种在定义常量时经常会使用的数据类型。</p>
<p>ClickHouse提供了<code>Enum8</code>和<code>Enum16</code>两种枚举类型，它们除了取值范围不同之外，别无二致。</p>
<p>枚举固定使用 (String:Int) Key/Value键值对的形式定义数据，</p>
<p>所以<code>Enum8</code>和<code>Enum16</code>分别会对应<code>(String:Int8)</code>和<code>(String:Int16)</code>，例如：</p>
<pre><code class="language-sql">CREATE TABLE Enum_TEST (
    c1 Enum8('ready' = 1, 'start' = 2, 'success' = 3, 'error' = 4)
) ENGINE = Memory;
</code></pre>
<p><strong>注意</strong>：</p>
<ul>
<li>
<p>Key和Value是不允许重复的，要保证唯一性。</p>
</li>
<li>
<p>Key和Value的值都不能为Null，但Key允许是空字符串</p>
</li>
</ul>
<p>在写入枚举数据的时候，只会用到Key字符串部分，例如：</p>
<pre><code class="language-sql">INSERT INTO Enum_TEST VALUES('ready');
INSERT INTO Enum_TEST VALUES('start');
</code></pre>
<p>数据在写入的过程中，会对照枚举集合项的内容逐一检查。如果Key字符串不在集合范围内则会抛出异常，比如执行下面的语句就会出错：</p>
<pre><code class="language-sql">INSERT INTO Enum_TEST VALUES('stop');
</code></pre>
<p>枚举完全可以使用String代替枚举，为什么还需要专门的枚举类型呢？</p>
<p>这是出于性能的考虑。因为虽然枚举定义中的Key属于String类型，但是在后续对枚举的所有操作中（包括排序、分组、去重、过滤等），会使用Int类型的Value值。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="嵌套"><a class="header" href="#嵌套">嵌套</a></h1>
<p>嵌套类型，顾名思义是一种嵌套表结构。</p>
<p>一张数据表，可以定义任意多个嵌套类型字段，但每个字段的嵌套层级只支持一级，即嵌套表内不能继续使用嵌套类型。</p>
<p>对于简单场景的层级关系或关联关系，使用嵌套类型也是一种不错的选择。</p>
<p>例如，下面的nested_test是一张模拟的员工表，它的所属部门字段就使用了嵌套类型：</p>
<pre><code class="language-sql">CREATE TABLE nested_test (
  name String,
  age  UInt8 ,
  dept Nested(
  id UInt8,
  name String
)
) ENGINE = Memory;
</code></pre>
<p>ClickHouse的嵌套类型和传统的嵌套类型不相同，导致在初次接触它的时候会让人十分困惑。以上面这张表为例，如果按照它的字面意思来理解，会很容易理解成nested_test与dept是一对一的包含关系，其实这是错误的。不信可以执行下面的语句，看看会是什么结果：</p>
<pre><code class="language-sql">INSERT INTO nested_test VALUES ('nauu',18, 10000, '研发部');
Exception on client:
Code: 53. DB::Exception: Type mismatch in IN or VALUES section. Expected: Array(UInt8). Got: UInt64
</code></pre>
<p>注意上面的异常信息，它提示期望写入的是一个Array数组类型。</p>
<p><strong>嵌套类型本质是一种多维数组的结构。嵌套表中的每个字段都是一个数组，同一行数据中数据必须对其，但行与行之间数组的长度无须对齐。</strong></p>
<p>所以需要把刚才的INSERT语句调整成下面的形式：</p>
<pre><code class="language-sql">INSERT INTO nested_test VALUES ('bruce' , 30 , [10000,10001,10002], ['研发部','技术支持中心','测试部']);
--行与行之间,数组长度无须对齐
INSERT INTO nested_test VALUES ('bruce' , 30 , [10000,10001], ['研发部','技术支持中心']);
</code></pre>
<p>需要注意的是，在同一行数据内每个数组字段的长度必须相等。例如，在下面的示例中，由于行内数组字段的长度没有对齐，所以会抛出异常：</p>
<pre><code class="language-sql">INSERT INTO nested_test VALUES ('bruce' , 30 , [10000,10001], ['研发部','技术支持中心', '测试部']); 
DB::Exception: Elements 'dept.id' and 'dept.name' of Nested data structure 'dept' (Array columns) have different array sizes..
</code></pre>
<p>在访问嵌套类型的数据时需要使用点符号，例如：</p>
<pre><code class="language-sql">SELECT name, dept.id, dept.name FROM nested_test

┌─name──┬─dept.id────┬────dept.name───────────────────┐
│ bruce │ [16,17,18] │ ['研发部','技术支持中心','测试部'] │
└───────┴────────────┴────────────────────────────────┘
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="特殊类型"><a class="header" href="#特殊类型">特殊类型</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="nullable"><a class="header" href="#nullable">Nullable</a></h1>
<p>原文：<a href="https://clickhouse.com/docs/zh/sql-reference/data-types/nullable/">https://clickhouse.com/docs/zh/sql-reference/data-types/nullable/</a></p>
<p>准确来说，Nullable并不能算是一种独立的数据类型，它更像是一种辅助的修饰符，需要与基础数据类型一起搭配使用。</p>
<p>Nullable类型与Java8的Optional对象有些相似，它表示某个基础数据类型可以是Null值。</p>
<pre><code class="language-sql">CREATE TABLE Null_TEST (
  c1 String,
  c2 Nullable(UInt8)
) ENGINE = TinyLog;

- 通过Nullable修饰后c2字段可以被写入Null值：

INSERT INTO Null_TEST VALUES ('nauu',null)
INSERT INTO Null_TEST VALUES ('bruce',20)

SELECT c1 , c2 ,toTypeName(c2) FROM Null_TEST

┌───c1───┬────c2───┬──toTypeName(c2)─┐
│ nauu   │ NULL    │ Nullable(UInt8) │
│ bruce  │ 20      │ Nullable(UInt8) │
└────────┴─────────┴─────────────────┘
</code></pre>
<p><strong>注意</strong>：</p>
<ul>
<li>
<p>它只能和基础类型搭配使用，不能用于数组和元组这些复合类型，也不能作为索引字段</p>
</li>
<li>
<p>慎用Nullable类型，包括Nullable的数据表，不然会使查询和写入性能变慢。【因为在正常情况下，每个列字段的数据会被存储在对应的[Column].bin文件中。如果一个列字段被Nullable类型修饰后，会额外生成一个[Column].null.bin文件专门保存它的Null值。这意味着在读取和写入数据时，需要一倍的额外文件操作。】</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="domain"><a class="header" href="#domain">Domain</a></h1>
<p>域名类型分为IPv4和IPv6两类，本质上它们是对整型和字符串的进一步封装。IPv4类型是基于UInt32封装的。</p>
<pre><code class="language-sql">CREATE TABLE IP4_TEST (
  url String,
  ip IPv4
) ENGINE = Memory;

INSERT INTO IP4_TEST VALUES ('www.nauu.com','192.0.0.0')

SELECT url , ip ,toTypeName(ip) FROM IP4_TEST

┌─url──────────┬─────ip────┬─toTypeName(ip)───────┐
│ www.nauu.com │ 192.0.0.0 │     IPv4             │
└──────────────┴───────────┴──────────────────────┘
</code></pre>
<p>直接使用字符串不就行了吗？</p>
<ul>
<li>
<p>（1）出于便捷性的考量，例如IPv4类型支持格式检查，格式错误的IP数据是无法被写入的，例如：</p>
<pre><code class="language-sql">INSERT INTO IP4_TEST VALUES ('www.nauu.com','192.0.0')
Code: 441. DB::Exception: Invalid IPv4 value.
</code></pre>
</li>
<li>
<p>（2）出于性能的考量，同样以IPv4为例，IPv4使用UInt32存储，相比String更加紧凑，占用的空间更小，查询性能更快。IPv6类型是基于FixedString(16)封装的，它的使用方法与IPv4别无二致.</p>
</li>
</ul>
<p>在使用Domain类型的时候还有一点需要注意，虽然它从表象上看起来与String一样，但Domain类型并不是字符串，所以它不支持隐式的自动类型转换。</p>
<p>如果需要返回IP的字符串形式，则需要显式调用<a href="https://clickhouse.com/docs/en/sql-reference/functions/ip-address-functions/#ipv4numtostringnum">IPv4NumToString</a>或<a href="https://clickhouse.com/docs/en/sql-reference/functions/ip-address-functions/#ipv6numtostringx">IPv6NumToString</a>函数进行转换。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="定义数据表"><a class="header" href="#定义数据表">定义数据表</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="数据库"><a class="header" href="#数据库">数据库</a></h1>
<p>数据库起到了命名空间的作用，可以有效规避命名冲突的问题，也为后续的数据隔离提供了支撑。</p>
<p>任何一张数据表，都必须归属在某个数据库之下。</p>
<p>创建数据库的完整语法如下所示：</p>
<pre><code class="language-sql">CREATE DATABASE IF NOT EXISTS db_name [ENGINE = engine]
</code></pre>
<p>其中，<code>IF NOT EXISTS</code>表示如果已经存在一个同名的数据库，则会忽略后续的创建过程；<code>[ENGINE=engine]</code>表示数据库所使用的引擎类型.</p>
<p>数据库目前一共支持5种引擎，如下所示。</p>
<ul>
<li><strong>Ordinary</strong>：默认引擎，在绝大多数情况下我们都会使用默认引擎，使用时无须刻意声明。在此数据库下可以使用任意类型的表引擎。</li>
<li><strong>Dictionary</strong>：字典引擎，此类数据库会自动为所有数据字典创建它们的数据表，关于数据字典的详细介绍会在第5章展开。</li>
<li><strong>Memory</strong>：内存引擎，用于存放临时数据。此类数据库下的数据表只会停留在内存中，不会涉及任何磁盘操作，当服务重启后数据会被清除。</li>
<li><strong>Lazy</strong>：日志引擎，此类数据库下只能使用Log系列的表引擎，关于Log表引擎的详细介绍会在第8章展开。</li>
<li><strong>MySQL</strong>：MySQL引擎，此类数据库下会自动拉取远端MySQL中的数据，并为它们创建MySQL表引擎的数据表。</li>
</ul>
<p>在绝大多数情况下都只需使用默认的数据库引擎。例如执行下面的语句，即能够创建属于我们的第一个数据库：</p>
<pre><code class="language-sql">CREATE DATABASE DB_TEST
</code></pre>
<p>默认数据库的实质是物理磁盘上的一个文件目录，所以在语句执行之后，ClickHouse便会在安装路径下创建DB_TEST数据库的文件目录：</p>
<pre><code class="language-shell"># pwd
/chbase/data
# ls
DB_TEST  default  system
</code></pre>
<p>与此同时，在metadata路径下也会一同创建用于恢复数据库的DB_TEST.sql文件：</p>
<pre><code class="language-shell"># pwd
/chbase/data/metadata
# ls
DB_TEST  DB_TEST.sql  default  system
</code></pre>
<p>使用SHOW DATABASES查询，即能够返回ClickHouse当前的数据库列表：</p>
<pre><code class="language-shell">SHOW DATABASES
┌─name──────┐
│  DB_TEST  │
│  default  │
│  system   │
└───────────┘
</code></pre>
<p>使用USE查询可以实现在多个数据库之间进行切换，而通过SHOW TABLES查询可以查看当前数据库的数据表列表。删除一个数据库，则需要用到下面的DROP查询。</p>
<pre><code class="language-sql">DROP DATABASE [IF EXISTS] db_name
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="数据表"><a class="header" href="#数据表">数据表</a></h1>
<p>ClickHouse目前提供了三种最基本的建表方法。</p>
<p><strong>常规定义方法</strong></p>
<blockquote>
<p>语法：</p>
<pre><code class="language-sql">CREATE TABLE [IF NOT EXISTS] [db_name.]table_name (
    name1 [type] [DEFAULT|MATERIALIZED|ALIAS expr],
    name2 [type] [DEFAULT|MATERIALIZED|ALIAS expr],
    省略…
) ENGINE = engine
</code></pre>
<p>使用[db_name.]参数可以为数据表指定数据库，如果不指定此参数，则默认会使用default数据库:</p>
<pre><code class="language-sql">CREATE TABLE hits_v1 ( 
  Title String,
  URL String ,
  EventTime DateTime
) ENGINE = Memory;
</code></pre>
<p>末尾的<code>ENGINE</code>参数，它被用于指定数据表的引擎。<strong><code>表引擎</code>决定了数据表的特性，也决定了数据将会被如何存储及加载。</strong></p>
<p>示例中使用的Memory表引擎，是ClickHouse最简单的表引擎，数据只会被保存在内存中，在服务重启时数据会丢失。</p>
</blockquote>
<p><strong>复制其他表的结构</strong></p>
<blockquote>
<p>语法：</p>
<pre><code class="language-sql">CREATE TABLE [IF NOT EXISTS] [db_name1.]table_name AS [db_name2.] table_name2 [ENGINE = engine]
</code></pre>
<p>这种方式支持在不同的数据库之间复制表结构</p>
<pre><code class="language-sql">--创建新的数据库
CREATE DATABASE IF NOT EXISTS new_db 
--将default.hits_v1的结构复制到new_db.hits_v1
CREATE TABLE IF NOT EXISTS new_db.hits_v1 AS default.hits_v1 ENGINE = TinyLog
</code></pre>
<p>上述语句将会把<code>default.hits_v1</code>的表结构原样复制到<code>new_db.hits_v1</code>，并且ENGINE表引擎可以与原表不同</p>
</blockquote>
<p><strong>通过SELECT子句创建</strong></p>
<blockquote>
<p>语法：</p>
<pre><code class="language-sql">CREATE TABLE [IF NOT EXISTS] [db_name.]table_name ENGINE = engine AS SELECT …
</code></pre>
<p>在这种方式下，不仅会根据SELECT子句建立相应的表结构，同时还会将SELECT子句查询的数据顺带写入, 例如：</p>
<pre><code class="language-sql">CREATE TABLE IF NOT EXISTS hits_v1_1 ENGINE = Memory AS SELECT * FROM hits_v1
</code></pre>
</blockquote>
<p><strong>DESC查询</strong></p>
<blockquote>
<p>ClickHouse和大多数数据库一样，使用DESC查询可以返回数据表的定义结构。</p>
<pre><code class="language-sql">:) desc hits_v1

DESCRIBE TABLE  hits_v1

Query id: eaa69aa2-5cd9-4ff8-9b70-7f0960aa33d8

┌─name──────┬─type─────┬─default_type─┬─default_expression─┬─comment─┬─codec_expression─┬─ttl_expression─┐
│ Title     │ String   │              │                    │         │                  │                │
│ URL       │ String   │              │                    │         │                  │                │
│ EventTime │ DateTime │              │                    │         │                  │                │
└───────────┴──────────┴──────────────┴────────────────────┴─────────┴──────────────────┴────────────────┘

3 rows in set. Elapsed: 0.001 sec.
</code></pre>
</blockquote>
<p><strong>DROP删除表</strong></p>
<blockquote>
<p>如果想删除一张数据表，则可以使用下面的DROP语句：</p>
<pre><code class="language-sql">DROP TABLE [IF EXISTS] [db_name.]table_name
</code></pre>
<pre><code class="language-sql">:) DROP　table default.hits_v1

DROP TABLE default.hits_v1

Query id: 2deeda6b-9922-41c9-b2af-5e8e3efbddfe

Ok.

0 rows in set. Elapsed: 0.002 sec.
</code></pre>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="字段默认值表达式"><a class="header" href="#字段默认值表达式">字段默认值表达式</a></h1>
<p>表字段支持三种默认值表达式的定义方法，分别是<code>DEFAULT</code>、<code>MATERIALIZED</code>和<code>ALIAS</code>。</p>
<p>无论使用哪种形式，表字段一旦被定义了默认值，它便不再强制要求定义数据类型，因为ClickHouse会根据默认值进行类型推断。</p>
<p>如果同时对表字段定义了数据类型和默认值表达式，则以明确定义的数据类型为主，例如:</p>
<pre><code class="language-sql">CREATE TABLE dfv_v1 ( 
  id String,
  c1 DEFAULT 1000,  -- c1字段没有定义数据类型，默认值为整型1000；
  c2 String DEFAULT c1  -- c2字段定义了数据类型和默认值，且默认值等于c1, 由于同时定义了数据类型和默认值，所以它最终的数据类型来自明确定义的String。
) ENGINE = TinyLog
</code></pre>
<p>现在写入测试数据：</p>
<pre><code class="language-sql">INSERT INTO dfv_v1(id) VALUES ('A000')
</code></pre>
<p>在写入之后执行以下查询：</p>
<pre><code class="language-sql">:) SELECT c1, c2, toTypeName(c1), toTypeName(c2) from dfv_v1

Query id: 2508b947-02c8-4676-baca-658d90af2765

┌───c1─┬─c2───┬─toTypeName(c1)─┬─toTypeName(c2)─┐
│ 1000 │ 1000 │ UInt16         │ String         │
└──────┴──────┴────────────────┴────────────────┘

1 rows in set. Elapsed: 0.002 sec.
</code></pre>
<p>默认值表达式的三种定义方法之间也存在着不同之处:</p>
<ul>
<li>
<p><strong>数据写入</strong>：在数据写入时，只有<code>DEFAULT类型</code>的字段可以出现在<code>INSERT语句</code>中。而<code>MATERIALIZED</code>和<code>ALIAS</code>都不能被显式赋值，它们只能依靠计算取值。例如试图为<code>MATERIALIZED类型</code>的字段写入数据，将会得到如下的错误。</p>
<pre><code class="language-sql">DB::Exception: Cannot insert column URL, because it is MATERIALIZED column..
</code></pre>
</li>
<li>
<p><strong>数据查询</strong>：在数据查询时，只有<code>DEFAULT类型</code>的字段可以通过<code>SELECT *</code>返回。而<code>MATERIALIZED</code>和<code>ALIAS</code>类型的字段不会出现在<code>SELECT*</code>查询的返回结果集中。</p>
</li>
<li>
<p><strong>数据存储</strong>：在数据存储时，只有<code>DEFAULT</code>和<code>MATERIALIZED类型</code>的字段才支持持久化。如果使用的表引擎支持物理存储（例如TinyLog表引擎），那么这些列字段将会拥有物理存储。而<code>ALIAS类型</code>的字段不支持持久化，它的取值总是需要依靠计算产生，数据不会落到磁盘。</p>
</li>
</ul>
<p><strong>使用ALTER语句修改默认值</strong></p>
<pre><code class="language-sql">ALTER TABLE [db_name.]table MODIFY COLUMN col_name DEFAULT value
</code></pre>
<p><strong>修改动作并不会影响数据表内先前已经存在的数据。但是默认值的修改有诸多限制</strong>，例如在合并树表引擎中，它的主键字段是无法被修改的；而某些表引擎则完全不支持修改（例如TinyLog）。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="临时表"><a class="header" href="#临时表">临时表</a></h1>
<p>ClickHouse也有临时表的概念，创建临时表的方法是在普通表的基础之上添加TEMPORARY关键字.</p>
<p>语法：</p>
<pre><code class="language-sql">CREATE TEMPORARY TABLE [IF NOT EXISTS] table_name (
    name1 [type] [DEFAULT|MATERIALIZED|ALIAS expr],
    name2 [type] [DEFAULT|MATERIALIZED|ALIAS expr],
)
</code></pre>
<p>两点特殊之处:</p>
<ul>
<li>它的生命周期是会话绑定的，所以它只支持Memory表引擎，如果会话结束，数据表就会被销毁；</li>
<li>临时表不属于任何数据库，所以在它的建表语句中，既没有数据库参数也没有表引擎参数。</li>
</ul>
<blockquote>
<p>如果临时表和普通表名称相同，会出现什么状况呢？</p>
<p>临时表的优先级是大于普通表的。当两张数据表名称相同的时候，会优先读取临时表的数据。</p>
</blockquote>
<p>在ClickHouse的日常使用中，通常不会刻意使用临时表。它更多被运用在ClickHouse的内部，是数据在集群间传播的载体。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="分区表"><a class="header" href="#分区表">分区表</a></h1>
<p>数据分区（partition）和数据分片（shard）是完全不同的两个概念。</p>
<p>数据分区是针对本地数据而言的，是数据的一种纵向切分; 而数据分片是数据的一种横向切分。</p>
<p>数据分区对于一款OLAP数据库而言意义非凡：借助数据分区，在后续的查询过程中能够跳过不必要的数据目录，从而提升查询的性能。</p>
<p>合理地利用分区特性，还可以变相实现数据的更新操作，因为数据分区支持删除、替换和重置操作。</p>
<p>假设数据表按照月份分区，那么数据就可以按月份的粒度被替换更新。</p>
<p>分区虽好，但不是所有的表引擎都可以使用这项特性，目前只有合并树（<code>MergeTree</code>）家族系列的表引擎才支持数据分区。</p>
<p>创建表时，由<code>PARTITION BY</code>指定分区键，例如使用了日期字段作为分区键，并将其格式化为年月的形式:</p>
<pre><code class="language-sql">CREATE TABLE partition_v1 ( 
  ID String,
  URL String,
  EventTime Date
) ENGINE =  MergeTree()
PARTITION BY toYYYYMM(EventTime) 
ORDER BY ID
</code></pre>
<p>接着写入不同月份的测试数据：</p>
<pre><code class="language-sql">INSERT INTO partition_v1 VALUES 
('A000','www.nauu.com', '2019-05-01'),
('A001','www.brunce.com', '2019-06-02')
</code></pre>
<p>最后通过<code>system.parts</code>系统表，查询数据表的分区状态：</p>
<pre><code class="language-sql">SELECT table,partition,path from system.parts WHERE table = 'partition_v1' 
┌─table────────┬──partition─┬─path───────────────────────────────────────────┐
│ partition_v1 │ 201905     │ /chbase/data/default/partition_v1/201905_1_1_0/│
│ partition_v1 │ 201906     │ /chbase/data/default/partition_v1/201906_2_2_0/│
└──────────────┴────────────┴────────────────────────────────────────────────┘
</code></pre>
<blockquote>
<p>partition_v1按年月划分后，目前拥有两个数据分区，且每个分区都对应一个独立的文件目录，用于保存各自部分的数据。</p>
</blockquote>
<p><strong>合理设计分区键非常重要，通常会按照数据表的查询场景进行针对性设计。</strong></p>
<p>例如：</p>
<pre><code class="language-sql">SELECT * FROM  partition_v1 WHERE EventTime ='2019-05-01'
</code></pre>
<p>那么在后续的查询过程中，可以利用分区索引跳过6月份的分区目录，只加载5月份的数据，从而带来查询的性能提升。</p>
<p>当然，使用不合理的分区键也会适得其反，分区键不应该使用粒度过细的数据字段。例如，按照小时分区，将会带来分区数量的急剧增长，从而导致性能下降。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="视图"><a class="header" href="#视图">视图</a></h1>
<p>参考原文: <a href="https://clickhouse.com/docs/zh/sql-reference/statements/create/view/">CREATE VIEW</a></p>
<p>ClickHouse拥有普通和物化两种视图，其中物化视图拥有独立的存储，而普通视图只是一层简单的查询代理。</p>
<p>语法:</p>
<pre><code class="language-sql">CREATE VIEW [IF NOT EXISTS] [db_name.]view_name AS SELECT ...
</code></pre>
<p>普通视图不会存储任何数据，它只是一层单纯的SELECT查询映射，起着简化查询、明晰语义的作用，对查询性能不会有任何增强。</p>
<p>假设有一张普通视图view_tb_v1，它是基于数据表tb_v1创建的，那么下面的两条SELECT查询是完全等价的：</p>
<pre><code class="language-sql">--普通表
SELECT * FROM tb_v1
-- tb_v1的视图
SELECT * FROM view_tb_v1
</code></pre>
<p>物化视图支持表引擎，数据保存形式由它的表引擎决定，创建物化视图的完整语法如下所示：</p>
<pre><code class="language-sql">CREATE [MATERIALIZED] VIEW [IF NOT EXISTS] [db.]table_name [TO[db.]name] [ENGINE = engine] [POPULATE] AS SELECT ...
</code></pre>
<p><strong>物化视图创建好之后，如果源表被写入新数据，那么物化视图也会同步更新。</strong></p>
<p><strong>POPULATE修饰符决定了物化视图的初始化策略：</strong></p>
<ul>
<li>
<p>如果使用了POPULATE修饰符，那么在创建视图的过程中，会连带将源表中已存在的数据一并导入，如同执行了SELECT INTO一般；</p>
</li>
<li>
<p>如果不使用POPULATE修饰符，那么物化视图在创建之后是没有数据的，它只会同步在此之后被写入源表的数据。</p>
</li>
</ul>
<p><strong>物化视图目前并不支持同步删除，如果在源表中删除了数据，物化视图的数据仍会保留。</strong></p>
<p>物化视图本质是一张特殊的数据表，例如使用<code>SHOW TABLE</code>查看数据表的列表：</p>
<pre><code class="language-sql">SHOW TABLES
┌───────name────────┐
│ .inner.view_test2 │
│ .inner.view_test3 │
└───────────────────┘
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="表的操作"><a class="header" href="#表的操作">表的操作</a></h1>
<p>目前只有<code>MergeTree</code>、<code>Merge</code>和<code>Distributed</code>这三类表引擎支持<code>ALTER</code>查询.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="追加字段"><a class="header" href="#追加字段">追加字段</a></h1>
<p>假如需要对一张数据表追加新的字段，可以使用如下语法：</p>
<pre><code class="language-sql">ALTER TABLE tb_name ADD COLUMN [IF NOT EXISTS] name [type] [default_expr] [AFTER name_after]
</code></pre>
<p>例如，在数据表的末尾增加新字段：</p>
<pre><code class="language-sql">ALTER TABLE testcol_v1 ADD COLUMN OS String DEFAULT 'mac'
</code></pre>
<p>或是通过<code>AFTER</code>修饰符，在指定字段的后面增加新字段：</p>
<pre><code class="language-sql">ALTER TABLE testcol_v1 ADD COLUMN IP String AFTER ID
</code></pre>
<p>对于数据表中已经存在的旧数据而言，新追加的字段会使用默认值补全。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="修改数据类型"><a class="header" href="#修改数据类型">修改数据类型</a></h1>
<p>如果需要改变表字段的数据类型或者默认值，需要使用下面的语法：</p>
<pre><code class="language-sql">ALTER TABLE tb_name MODIFY COLUMN [IF EXISTS] name [type] [default_expr]
</code></pre>
<p>修改某个字段的数据类型，实质上会调用相应的toType转型方法。如果当前的类型与期望的类型不能兼容，则修改操作将会失败。</p>
<p>例如，将String类型的IP字段修改为IPv4类型是可行的：</p>
<pre><code class="language-sql">ALTER TABLE testcol_v1 MODIFY COLUMN IP IPv4
</code></pre>
<p>而尝试将String类型转为UInt类型就会出现错误：</p>
<pre><code class="language-sql">ALTER TABLE testcol_v1 MODIFY COLUMN OS UInt32
DB::Exception: Cannot parse string 'mac' as UInt32: syntax error at begin of string.
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="修改备注"><a class="header" href="#修改备注">修改备注</a></h1>
<p>做好信息备注是保持良好编程习惯的美德之一。追加备注的语法如下所示：</p>
<pre><code class="language-sql">ALTER TABLE tb_name COMMENT COLUMN [IF EXISTS] name 'some comment'
</code></pre>
<p>例如，为ID字段增加备注：</p>
<pre><code class="language-sql">ALTER TABLE testcol_v1 COMMENT COLUMN ID '主键ID'
</code></pre>
<p>使用DESC查询可以看到上述增加备注的操作已经生效：</p>
<pre><code class="language-sql">DESC testcol_v1
┌─name────────┬─type───┬─comment─┐
│ ID          │ String │ 主键ID   │
└─────────────┴────────┴─────────┘
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="删除已有字段"><a class="header" href="#删除已有字段">删除已有字段</a></h1>
<p>假如要删除某个字段，可以使用下面的语句：</p>
<pre><code class="language-sql">ALTER TABLE tb_name DROP COLUMN [IF EXISTS] name
</code></pre>
<p>例如，执行下面的语句删除URL字段：</p>
<pre><code class="language-sql">ALTER TABLE testcol_v1 DROP COLUMN URL
</code></pre>
<p>上述列字段在被删除之后，它的数据也会被连带删除。进一步来到testcol_v1的数据目录查验，会发现URL的数据文件已经被删除了：</p>
<pre><code class="language-sql"># pwd
/chbase/data/data/default/testcol_v1/201907_2_2_0
# ll
total 56
-rw-r-----. 1 clickhouse clickhouse  28 Jul  2 21:02 EventTime.bin
-rw-r-----. 1 clickhouse clickhouse  30 Jul  2 21:02 ID.bin
-rw-r-----. 1 clickhouse clickhouse  30 Jul  2 21:02 IP.bin
-rw-r-----. 1 clickhouse clickhouse  30 Jul  2 21:02 OS.bin
省略…
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="移动数据表"><a class="header" href="#移动数据表">移动数据表</a></h1>
<p>原文参考: <a href="https://clickhouse.com/docs/zh/sql-reference/statements/rename/">RENAME语法</a></p>
<p>在Linux系统中，<code>mv</code>命令的本意是将一个文件从原始位置A移动到目标位置B，但是如果位置A与位置B相同，则可以变相实现重命名的作用。</p>
<p>ClickHouse的<code>RENAME</code>查询就与之有着异曲同工之妙，<code>RENAME语句</code>的完整语法如下所示：</p>
<pre><code class="language-sql">RENAME TABLE [db_name11.]tb_name11 TO [db_name12.]tb_name12, [db_name21.]tb_name21 TO [db_name22.]tb_name22, ...
</code></pre>
<p>RENAME可以修改数据表的名称，如果将原始数据库与目标数据库设为不同的名称，那么就可以实现数据表在两个数据库之间移动的效果。</p>
<p>例如在下面的例子中，<code>testcol_v1</code>从<code>default</code>默认数据库被移动到了<code>db_test</code>数据库，同时数据表被重命名为<code>testcol_v2</code>：</p>
<pre><code class="language-sql">RENAME TABLE default.testcol_v1 TO db_test.testcol_v2
</code></pre>
<p>需要注意的是，数据表的移动只能在单个节点的范围内。</p>
<p>换言之，数据表移动的目标数据库和原始数据库必须处在同一个服务节点内，而不能是集群中的远程节点。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="清空数据表"><a class="header" href="#清空数据表">清空数据表</a></h1>
<p>假设需要将表内的数据全部清空，而不是直接删除这张表，则可以使用<code>TRUNCATE</code>语句，它的完整语法如下所示：</p>
<pre><code class="language-sql">TRUNCATE TABLE [IF EXISTS] [db_name.]tb_name
</code></pre>
<p>例如执行下面的语句，就能将<code>db_test.testcol_v2</code>的数据一次性清空：</p>
<pre><code class="language-sql">TRUNCATE TABLE db_test.testcol_v2
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="数据分区操作"><a class="header" href="#数据分区操作">数据分区操作</a></h1>
<p>了解并善用数据分区益处颇多，熟练掌握它的使用方法，可以为后续的程序设计带来极大的灵活性和便利性，目前只有<code>MergeTree</code>系列的表引擎支持数据分区。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="查询分区信息"><a class="header" href="#查询分区信息">查询分区信息</a></h1>
<p><code>ClickHouse</code>内置了许多<code>system系统表</code>，用于查询自身的状态信息。</p>
<p>其中<code>parts系统表</code>专门用于查询数据表的分区信息。</p>
<p>例如执行下面的语句，就能够得到数据表<code>partition_v2</code>的分区状况：</p>
<pre><code class="language-sql">SELECT partition_id,name,table,database FROM system.parts WHERE table = 'partition_v2'
┌─partition_id───┬─name───────────┬────table─────┬─database┐
│ 201905         │ 201905_1_1_0_6 │ partition_v2 │ default │
│ 201910         │ 201910_3_3_0_6 │ partition_v2 │ default │
│ 201911         │ 201911_4_4_0_6 │ partition_v2 │ default │
│ 201912         │ 201912_5_5_0_6 │ partition_v2 │ default │
└────────────────┴────────────────┴──────────────┴─────────┘
</code></pre>
<p>如上所示，目前<code>partition_v2</code>共拥有4个分区，其中<code>partition_id</code>或者<code>name</code>等同于分区的主键，可以基于它们的取值确定一个具体的分区。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="删除指定分区"><a class="header" href="#删除指定分区">删除指定分区</a></h1>
<p>合理地设计分区键并利用分区的删除功能，就能够达到数据更新的目的。删除一个指定分区的语法如下所示：</p>
<pre><code class="language-sql">ALTER TABLE tb_name DROP PARTITION partition_expr
</code></pre>
<p>假如现在需要更新partition_v2数据表整个7月份的数据，则可以先将7月份的分区删除：</p>
<pre><code class="language-sql">ALTER TABLE partition_v2 DROP PARTITION 201907
</code></pre>
<p>然后将整个7月份的新数据重新写入，就可以达到更新的目的：</p>
<pre><code class="language-sql">INSERT INTO partition_v2 VALUES ('A004-update','www.bruce.com', '2019-07-02'),…
</code></pre>
<p>查验数据表，可以看到7月份的数据已然更新：</p>
<pre><code class="language-sql">SELECT * from partition_v2 ORDER BY EventTime
┌─ID───────────┬──────URL──────┬ EventTime  ┐
│ A001         │ www.nauu.com  │ 2019-05-02 │
│ A002         │ www.nauu1.com │ 2019-06-02 │
│ A004-update  │ www.bruce.com │ 2019-07-02 │
└──────────────┴───────────────┴────────────┘
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="复制分区数据"><a class="header" href="#复制分区数据">复制分区数据</a></h1>
<p>ClickHouse支持将A表的分区数据复制到B表，这项特性可以用于快速数据写入、多表间数据同步和备份等场景，它的完整语法如下：</p>
<pre><code class="language-sql">ALTER TABLE B REPLACE PARTITION partition_expr FROM A
</code></pre>
<p>不过需要注意的是，并不是任意数据表之间都能够相互复制，它们还需要满足两个前提条件：</p>
<ul>
<li>两张表需要拥有相同的分区键；</li>
<li>它们的表结构完全相同。</li>
</ul>
<p>再执行下面的语句：</p>
<pre><code class="language-sql">ALTER TABLE partition_v2 REPLACE PARTITION 201908 FROM partition_v1
</code></pre>
<p>即能够将partition_v1的整个201908分区中的数据复制到partition_v2：</p>
<pre><code class="language-sql">SELECT * from partition_v2 ORDER BY EventTime
┌─────ID───────┬─────URL───────┬──EventTime─┐
│ A000         │ www.nauu.com  │ 2019-05-01 │
│ A001         │ www.nauu.com  │ 2019-05-02 │
省略…
│ A004-update  │ www.bruce.com │ 2019-07-02 │
│ A006-v1      │ www.v1.com    │ 2019-08-05 │
│ A007-v1      │ www.v1.com    │ 2019-08-20 │
└──────────────┴───────────────┴────────────┘
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="重置分区数据"><a class="header" href="#重置分区数据">重置分区数据</a></h1>
<p>如果数据表某一列的数据有误，需要将其重置为初始值，此时可以使用下面的语句实现：</p>
<pre><code class="language-sql">ALTER TABLE tb_name CLEAR COLUMN column_name IN PARTITION partition_expr
</code></pre>
<p>对于默认值的含义，笔者遵循如下原则：如果声明了默认值表达式，则以表达式为准；否则以相应数据类型的默认值为准。</p>
<p>例如，执行下面的语句会重置partition_v2表内201908分区的URL数据重置。</p>
<pre><code class="language-sql">ALTER TABLE partition_v2 CLEAR COLUMN URL in PARTITION 201908
</code></pre>
<p>查验数据后会发现，URL字段已成功被全部重置为空字符串了（String类型的默认值）。</p>
<pre><code class="language-sql">SELECT * from partition_v2
┌───ID────┬─URL──┬───EventTime┐
│ A006-v1 │      │ 2019-08-05 │
│ A007-v1 │      │ 2019-08-20 │
└─────────┴──────┴────────────┘
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="卸载与装载分区"><a class="header" href="#卸载与装载分区">卸载与装载分区</a></h1>
<p>表分区可以通过<code>DETACH</code>语句卸载，分区被卸载后，它的物理数据并没有删除，而是被转移到了当前数据表目录的<code>detached</code>子目录下。而装载分区则是反向操作，它能够将<code>detached</code>子目录下的某个分区重新装载回去。卸载与装载这一对伴生的操作，常用于分区数据的迁移和备份场景。卸载某个分区的语法如下所示：</p>
<pre><code class="language-sql">ALTER TABLE tb_name DETACH PARTITION partition_expr
</code></pre>
<p>例如，执行下面的语句能够将partition_v2表内整个8月份的分区卸载：</p>
<pre><code class="language-sql">ALTER TABLE partition_v2 DETACH PARTITION 201908
</code></pre>
<p>此时再次查询这张表，会发现其中2019年8月份的数据已经没有了。而进入partition_v2的磁盘目录，则可以看到被卸载的分区目录已经被移动到了detached目录中：</p>
<pre><code class="language-sql"># pwd
/chbase/data/data/default/partition_v2/detached
# ll
total 4
drwxr-x---. 2 clickhouse clickhouse 4096 Aug 31 23:16 201908_4_4_0
</code></pre>
<p>记住，一旦分区被移动到了detached子目录，就代表它已经脱离了ClickHouse的管理，ClickHouse并不会主动清理这些文件。这些分区文件会一直存在，除非我们主动删除或者使用ATTACH语句重新装载它们。装载某个分区的完整语法如下所示：</p>
<pre><code class="language-sql">ALTER TABLE tb_name ATTACH PARTITION partition_expr
</code></pre>
<p>再次执行下面的语句，就可以将刚才已被卸载的201908分区重新装载回去：</p>
<pre><code class="language-sql">ALTER TABLE partition_v2 ATTACH PARTITION 201908
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><ul>
<li><a href="clickhouse/op_partition_backup.html#%E5%A4%87%E4%BB%BD%E4%B8%8E%E8%BF%98%E5%8E%9F%E5%88%86%E5%8C%BA">备份与还原分区</a>
<ul>
<li><a href="clickhouse/op_partition_backup.html#%E5%AF%BC%E5%87%BA%E6%96%87%E4%BB%B6%E5%A4%87%E4%BB%BD">导出文件备份</a></li>
<li><a href="clickhouse/op_partition_backup.html#%E9%80%9A%E8%BF%87%E5%BF%AB%E7%85%A7%E8%A1%A8%E5%A4%87%E4%BB%BD">通过快照表备份</a></li>
<li><a href="clickhouse/op_partition_backup.html#%E6%8C%89%E5%88%86%E5%8C%BA%E5%A4%87%E4%BB%BD">按分区备份</a>
<ul>
<li><a href="clickhouse/op_partition_backup.html#%E4%BD%BF%E7%94%A8freeze%E5%A4%87%E4%BB%BD">使用FREEZE备份</a></li>
<li><a href="clickhouse/op_partition_backup.html#%E4%BD%BF%E7%94%A8fetch%E5%A4%87%E4%BB%BD">使用FETCH备份</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="备份与还原分区"><a class="header" href="#备份与还原分区">备份与还原分区</a></h1>
<p>ClickHouse自身提供了多种备份数据的方法，根据数据规模的不同，可以选择不同的形式。</p>
<h2 id="导出文件备份"><a class="header" href="#导出文件备份">导出文件备份</a></h2>
<p>如果数据的体量较小，可以通过dump的形式将数据导出为本地文件。例如执行下面的语句将test_backup的数据导出：</p>
<pre><code class="language-shell">&gt; clickhouse-client --query=&quot;SELECT * FROM test_backup&quot; &gt; /chbase/test_backup.tsv
</code></pre>
<p>将备份数据再次<code>导恢复数据</code>，则可以执行下面的语句：</p>
<pre><code class="language-sql">&gt; cat /chbase/test_backup.tsv | clickhouse-client --query &quot;INSERT INTO test_backup FORMAT TSV&quot;
</code></pre>
<p>上述这种dump形式的优势在于，可以利用SELECT查询并筛选数据，然后按需备份。如果是备份整个表的数据，也可以直接复制它的整个目录文件，例如：</p>
<pre><code class="language-sql">&gt; mkdir -p /chbase/backup/default/ &amp; cp -r /chbase/data/default/test_backup /chbase/backup/default/
</code></pre>
<h2 id="通过快照表备份"><a class="header" href="#通过快照表备份">通过快照表备份</a></h2>
<p>快照表实质上就是普通的数据表，它通常按照业务规定的备份频率创建，例如按天或者按周创建。</p>
<p>所以首先需要建立一张与原表结构相同的数据表，然后再使用INSERT INTO SELECT句式，点对点地将数据从原表写入备份表。</p>
<p>假设数据表<code>test_backup</code>需要按日进行备份，现在为它创建当天的备份表：</p>
<pre><code class="language-sql">CREATE TABLE test_backup_0206 AS test_backup
</code></pre>
<p>有了备份表之后，就可以点对点地备份数据了，例如：</p>
<pre><code class="language-sql">INSERT INTO TABLE test_backup_0206 SELECT * FROM test_backup
</code></pre>
<p>如果考虑到容灾问题，也可以将备份表放置在不同的ClickHouse节点上，此时需要将上述SQL语句改成远程查询的形式：</p>
<pre><code class="language-sql">INSERT INTO TABLE test_backup_0206 SELECT * FROM remote('ch5.nauu.com:9000', 'default', 'test_backup', 'default')
</code></pre>
<h2 id="按分区备份"><a class="header" href="#按分区备份">按分区备份</a></h2>
<p>基于数据分区的备份，ClickHouse目前提供了<code>FREEZE</code>与<code>FETCH</code>两种方式，现在分别介绍它们的使用方法。</p>
<h3 id="使用freeze备份"><a class="header" href="#使用freeze备份">使用FREEZE备份</a></h3>
<p>FREEZE的完整语法如下所示：</p>
<p>参考原文: <a href="https://clickhouse.com/docs/zh/sql-reference/statements/alter/#alter_freeze-partition">https://clickhouse.com/docs/zh/sql-reference/statements/alter/#alter_freeze-partition</a></p>
<pre><code class="language-sql">ALTER TABLE tb_name FREEZE PARTITION partition_expr
</code></pre>
<p>分区在被备份之后，会被统一保存到ClickHouse根路径/shadow/N子目录下。</p>
<p>其中，N是一个自增长的整数，它的含义是备份的次数（FREEZE执行过多少次），具体次数由shadow子目录下的increment.txt文件记录。</p>
<p>而分区备份实质上是对原始目录文件进行硬链接操作，所以并不会导致额外的存储空间。整个备份的目录会一直向上追溯至data根路径的整个链路：</p>
<pre><code class="language-shell">/data/[database]/[table]/[partition_folder]
</code></pre>
<p>例如执行下面的语句，会对数据表partition_v2的201908分区进行备份：</p>
<pre><code class="language-sql">:) ALTER TABLE partition_v2 FREEZE PARTITION 201908
</code></pre>
<p>进入shadow子目录，即能够看到刚才备份的分区目录：</p>
<pre><code class="language-shell"># pwd
/chbase/data/shadow/1/data/default/partition_v2
# ll
total 4
drwxr-x---. 2 clickhouse clickhouse 4096 Sep  1 00:22 201908_5_5_0
</code></pre>
<p><strong>对于备份分区的还原操作，则需要借助ATTACH装载分区的方式来实现。</strong></p>
<p><strong>这意味着如果要还原数据，首先需要主动将shadow子目录下的分区文件复制到相应数据表的detached目录下，然后再使用ATTACH语句装载。</strong></p>
<h3 id="使用fetch备份"><a class="header" href="#使用fetch备份">使用FETCH备份</a></h3>
<p>FETCH只支持ReplicatedMergeTree系列的表引擎，它的完整语法如下所示：</p>
<pre><code class="language-sql">ALTER TABLE tb_name FETCH PARTITION partition_id FROM zk_path
</code></pre>
<p>其工作原理与<code>ReplicatedMergeTree</code>同步数据的原理类似，FETCH通过指定的<code>zk_path</code>找到<code>ReplicatedMergeTree</code>的所有副本实例，然后从中选择一个最合适的副本，并下载相应的分区数据。例如执行下面的语句：</p>
<pre><code class="language-sql">ALTER TABLE test_fetch FETCH PARTITION 2019 FROM '/clickhouse/tables/01/test_fetch'
</code></pre>
<p>表示指定将test_fetch的2019分区下载到本地，并保存到对应数据表的detached目录下，目录如下所示：</p>
<pre><code class="language-sql">data/default/test_fetch/detached/2019_0_0_0
</code></pre>
<p>与FREEZE一样，对于备份分区的还原操作，也需要借助ATTACH装载分区来实现。</p>
<p>FREEZE和FETCH虽然都能实现对分区文件的备份，但是它们并不会备份数据表的元数据。</p>
<p>所以说如果想做到万无一失的备份，还需要对数据表的元数据进行备份，它们是<code>/data/metadata</code>目录下的<code>[table].sql</code>文件。目前这些元数据需要用户通过复制的形式单独备份。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="分布式ddl执行"><a class="header" href="#分布式ddl执行">分布式DDL执行</a></h1>
<p>ClickHouse支持集群模式，一个集群拥有1到多个节点。</p>
<p>CREATE、ALTER、DROP、RENMAE及TRUNCATE这些DDL语句，都支持分布式执行。</p>
<p>这意味着，如果在集群中任意一个节点上执行DDL语句，那么集群中的每个节点都会以相同的顺序执行相同的语句。</p>
<p>这项特性意义非凡，它就如同批处理命令一样，省去了需要依次去单个节点执行DDL的烦恼。</p>
<p>将一条普通的DDL语句转换成分布式执行十分简单，只需加上<code>ON CLUSTER cluster_name</code>声明即可。</p>
<p>例如，执行下面的语句后将会对<code>ch_cluster</code>集群内的所有节点广播这条DDL语句：</p>
<pre><code class="language-sql">CREATE TABLE partition_v3 ON CLUSTER ch_cluster( 
  ID String,
  URL String,
  EventTime Date
) ENGINE =  MergeTree()
PARTITION BY toYYYYMM(EventTime)
ORDER BY ID
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><ul>
<li><a href="clickhouse/insert_data.html#%E6%95%B0%E6%8D%AE%E7%9A%84%E5%86%99%E5%85%A5">数据的写入</a>
<ul>
<li><a href="clickhouse/insert_data.html#%E4%BD%BF%E7%94%A8values%E6%A0%BC%E5%BC%8F">使用VALUES格式</a></li>
<li><a href="clickhouse/insert_data.html#%E4%BD%BF%E7%94%A8%E6%8C%87%E5%AE%9A%E6%A0%BC%E5%BC%8F">使用指定格式</a></li>
<li><a href="clickhouse/insert_data.html#%E4%BD%BF%E7%94%A8select%E5%AD%90%E5%8F%A5%E5%BD%A2%E5%BC%8F">使用SELECT子句形式</a></li>
</ul>
</li>
</ul>
<h1 id="数据的写入"><a class="header" href="#数据的写入">数据的写入</a></h1>
<p>参考原文: <a href="https://clickhouse.com/docs/zh/sql-reference/statements/insert-into/">INSERT INTO 语句</a></p>
<p>INSERT语句支持三种语法范式，三种范式各有不同，可以根据写入的需求灵活运用。</p>
<h2 id="使用values格式"><a class="header" href="#使用values格式">使用VALUES格式</a></h2>
<p>语法:</p>
<pre><code class="language-sql">INSERT INTO [db.]table [(c1, c2, c3…)] VALUES (v11, v12, v13…), (v21, v22, v23…), ...
</code></pre>
<p>其中，c1、c2、c3是列字段声明，可省略。</p>
<p>VALUES后紧跟的是由元组组成的待写入数据，通过下标位与列字段声明一一对应。</p>
<p>数据支持批量声明写入，多行数据之间使用逗号分隔。</p>
<p>例如执行下面的语句，将批量写入多条数据：</p>
<pre><code class="language-sql">INSERT INTO partition_v2 VALUES 
('A0011','www.nauu.com', '2019-10-01'), 
('A0012','www.nauu.com', '2019-11-20'),
('A0013','www.nauu.com', '2019-12-20')
</code></pre>
<p>在使用VALUES格式的语法写入数据时，支持加入表达式或函数，例如：</p>
<pre><code class="language-sql">INSERT INTO partition_v2 VALUES ('A0014',toString(1+2), now())
</code></pre>
<h2 id="使用指定格式"><a class="header" href="#使用指定格式">使用指定格式</a></h2>
<p>语法:</p>
<pre><code class="language-sql">INSERT INTO [db.]table [(c1, c2, c3…)] FORMAT format_name data_set
</code></pre>
<p>ClickHouse支持多种数据格式（更多格式可参见官方手册），以常用的CSV格式写入为例：</p>
<pre><code class="language-sql">INSERT INTO partition_v2 FORMAT CSV \
'A0017','www.nauu.com', '2019-10-01' \
'A0018','www.nauu.com', '2019-10-01'
</code></pre>
<h2 id="使用select子句形式"><a class="header" href="#使用select子句形式">使用SELECT子句形式</a></h2>
<p>语法：</p>
<pre><code class="language-sql">INSERT INTO [db.]table [(c1, c2, c3…)] SELECT ...
</code></pre>
<p>通过SELECT子句可将查询结果写入数据表，假设需要将partition_v1的数据写入partition_v2，则可以使用下面的语句：</p>
<pre><code class="language-sql">INSERT INTO partition_v2 SELECT * FROM partition_v1
</code></pre>
<p>在通过SELECT子句写入数据的时候，同样也支持加入表达式或函数，例如：</p>
<pre><code class="language-sql">INSERT INTO partition_v2 SELECT 'A0020', 'www.jack.com', now()
</code></pre>
<p>虽然VALUES和SELECT子句的形式都支持声明表达式或函数，但是表达式和函数会带来额外的性能开销，从而导致写入性能的下降。</p>
<p>所以如果追求极致的写入性能，就应该尽可能避免使用它们。</p>
<p>ClickHouse内部所有的数据操作都是面向Block数据块的，所以INSERT查询最终会将数据转换为Block数据块。也正因如此，INSERT语句在单个数据块的写入过程中是具有原子性的。</p>
<p>在默认的情况下，每个数据块最多可以写入<code>1048576</code>行数据（由<code>max_insert_block_size</code>参数控制）。也就是说，如果一条<code>INSERT语句</code>写入的数据少于<code>max_insert_block_size</code>行，那么这批数据的写入是具有原子性的，即要么全部成功，要么全部失败。</p>
<blockquote>
<p><strong>注意</strong>:</p>
<p>只有在ClickHouse服务端处理数据的时候才具有这种原子写入的特性。</p>
<p>例如使用JDBC或者HTTP接口时。因为<code>max_insert_block_size</code>参数在使用<code>CLI命令行</code>或者<code>INSERT SELECT</code>子句写入时是不生效的。</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="数据的删除与修改"><a class="header" href="#数据的删除与修改">数据的删除与修改</a></h1>
<p>ClickHouse提供了<code>DELETE</code>和<code>UPDATE</code>的能力，这类操作被称为<code>Mutation</code>查询，它可以看作<code>ALTER</code>语句的变种。</p>
<p>虽然<code>Mutation</code>能最终实现修改和删除，但不能完全以通常意义上的<code>UPDATE</code>和<code>DELETE</code>来理解，我们必须清醒地认识到它的不同：</p>
<ul>
<li>
<p>首先，<code>Mutation语句</code>是一种 <strong>“很重”</strong> 的操作，更适用于批量数据的修改和删除；</p>
</li>
<li>
<p>其次，它不支持事务，一旦语句被提交执行，就会立刻对现有数据产生影响，无法回滚；</p>
</li>
<li>
<p>最后，<code>Mutation语句</code>的执行是一个异步的后台过程，语句被提交之后就会立即返回。</p>
</li>
<li>
<p>所以这并不代表具体逻辑已经执行完毕，它的具体执行进度需要通过<code>system.mutations</code>系统表查询。</p>
</li>
</ul>
<h2 id="数据删除"><a class="header" href="#数据删除">数据删除</a></h2>
<p>DELETE语句的完整语法如下所示:</p>
<pre><code class="language-sql">ALTER TABLE [db_name.]table_name DELETE WHERE filter_expr
</code></pre>
<p>数据删除的范围由WHERE查询子句决定。例如，执行下面语句可以删除partition_v2表内所有ID等于A003的数据：</p>
<pre><code class="language-sql">ALTER TABLE partition_v2 DELETE WHERE ID = 'A003'
</code></pre>
<p>由于演示的数据很少，DELETE操作给人的感觉和常用的OLTP数据库无异。但是我们心中应该要明白这是一个异步的后台执行动作。</p>
<p>再次进入数据目录，让我们看看删除操作是如何实现的：</p>
<pre><code class="language-shell"># pwd
/chbase/data/data/default/partition_v2
# ll
total 52
drwxr-x---. 2 clickhouse clickhouse 4096 Jul  6 15:03 201905_1_1_0
drwxr-x---. 2 clickhouse clickhouse 4096 Jul  6 15:03 201905_1_1_0_6
省略…
drwxr-x---. 2 clickhouse clickhouse 4096 Jul  6 15:03 201909_5_5_0
drwxr-x---. 2 clickhouse clickhouse 4096 Jul  6 15:03 201909_5_5_0_6
drwxr-x---. 2 clickhouse clickhouse 4096 Jul  6 15:02 detached
-rw-r-----. 1 clickhouse clickhouse    1 Jul  6 15:02 format_version.txt
-rw-r-----. 1 clickhouse clickhouse   89 Jul  6 15:03 mutation_6.txt
</code></pre>
<p>可以发现，在执行了DELETE操作之后数据目录发生了一些变化。每一个原有的数据目录都额外增加了一个同名目录，并且在末尾处增加了_6的后缀。此外，目录下还多了一个名为mutation_6.txt的文件，mutation_6.txt文件的内容如下所示：</p>
<pre><code class="language-shell"># cat mutation_6.txt
format version: 1
create time: 2019-07-06 15:03:27
commands: DELETE WHERE ID = \'A003\'
</code></pre>
<p>原来mutation_6.txt是一个日志文件，它完整地记录了这次DELETE操作的执行语句和时间，而文件名的后缀_6与新增目录的后缀对应。那么后缀的数字从何而来呢？继续查询system.mutations系统表，一探究竟：</p>
<pre><code class="language-sql">SELECT database, table ,mutation_id, block_numbers.number as num ,is_done FROM system.mutations

┌─database──┬────table─────┬──mutation_id───┬───num──┬─is_done─┐
│ default   │ partition_v2 │ mutation_6.txt │ [6]    │ 1       │
└───────────┴──────────────┴────────────────┴────────┴─────────┘
</code></pre>
<p>至此，整个Mutation操作的逻辑就比较清晰了。</p>
<ul>
<li>每执行一条ALTER DELETE语句，都会在mutations系统表中生成一条对应的执行计划，当is_done等于1时表示执行完毕。</li>
<li>与此同时，在数据表的根目录下，会以mutation_id为名生成与之对应的日志文件用于记录相关信息。</li>
<li>而数据删除的过程是以数据表的每个分区目录为单位，将所有目录重写为新的目录，新目录的命名规则是在原有名称上加上<code>system.mutations.block_numbers.number</code>。</li>
</ul>
<p>数据在重写的过程中会将需要删除的数据去掉。旧的数据目录并不会立即删除，而是会被标记成非激活状态（active为0）。
等到MergeTree引擎的下一次合并动作触发时，这些非激活目录才会被真正从物理意义上删除。</p>
<h2 id="数据修改"><a class="header" href="#数据修改">数据修改</a></h2>
<p>数据修改除了需要指定具体的列字段之外，整个逻辑与数据删除别无二致，它的完整语法如下所示：</p>
<pre><code class="language-sql">ALTER TABLE [db_name.]table_name UPDATE column1 = expr1 [, ...] WHERE filter_expr
</code></pre>
<p>UPDATE支持在一条语句中同时定义多个修改字段，分区键和主键不能作为修改字段。例如，执行下面的语句即能够根据WHERE条件同时修改partition_v2内的URL和OS字段：</p>
<pre><code class="language-sql">ALTER TABLE partition_v2 
UPDATE URL = 'www.wayne.com', OS = 'mac' 
WHERE ID IN (
    SELECT ID 
    FROM partition_v2 
    WHERE EventTime = '2019-06-01'
)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="副本与分片"><a class="header" href="#副本与分片">副本与分片</a></h1>
<p>摘自：《ClickHouse原理解析与应用实践》 — 朱凯</p>
<p>在豆瓣阅读书店查看：<a href="https://read.douban.com/ebook/149635956/?dcs=bookshelf">https://read.douban.com/ebook/149635956/?dcs=bookshelf</a></p>
<hr />
<p>纵使单节点性能再强，也会有遇到瓶颈的那一天。业务量的持续增长、服务器的意外故障，都是ClickHouse需要面对的洪水猛兽。常言道，“一个篱笆三个桩，一个好汉三个帮”，而集群、副本与分片，就是ClickHouse的三个“桩”和三个“帮手”。</p>
<h2 id="概述"><a class="header" href="#概述">概述</a></h2>
<p>集群是副本和分片的基础，它将ClickHouse的服务拓扑由单节点延伸到多个节点，但它并不像Hadoop生态的某些系统那样，要求所有节点组成一个单一的大集群。ClickHouse的集群配置非常灵活，用户既可以将所有节点组成一个单一集群，也可以按照业务的诉求，把节点划分为多个小的集群。在每个小的集群区域之间，它们的节点、分区和副本数量可以各不相同，如图10-1所示。</p>
<p><img src="clickhouse/../images/clickhouse01.jpg" alt="单集群和多集群" /></p>
<p>从作用来看，ClickHouse集群的工作更多是针对逻辑层面的。集群定义了多个节点的拓扑关系，这些节点在后续服务过程中可能会协同工作，而执行层面的具体工作则交给了副本和分片来执行。</p>
<p>副本和分片这对双胞胎兄弟，有时候看起来泾渭分明，有时候又让人分辨不清。这里有两种区分的方法。</p>
<p>一种是从数据层面区分，假设ClickHouse的N个节点组成了一个集群，在集群的各个节点上，都有一张结构相同的数据表Y。如果N1的Y和N2的Y中的数据完全不同，则N1和N2互为分片；如果它们的数据完全相同，则它们互为副本。换言之，分片之间的数据是不同的，而副本之间的数据是完全相同的。所以抛开表引擎的不同，单纯从数据层面来看，副本和分片有时候只有一线之隔。</p>
<p>另一种是从功能作用层面区分，使用副本的主要目的是防止数据丢失，增加数据存储的冗余；而使用分片的主要目的是实现数据的水平切分，如图10-2所示。</p>
<p><img src="clickhouse/../images/clickhouse02.jpg" alt="区分副本和分片的示意图" /></p>
<p>这种形态的变化过程像极了企业内的业务发展过程。在业务初期，我们从单张数据表开始；在业务上线之后，可能会为它增加副本，以保证数据的安全，或者希望进行读写分离；随着业务量的发展，单张数据表可能会遇到瓶颈，此时会进一步为它增加分片，从而实现数据的水平切分。</p>
<div style="break-before: page; page-break-before: always;"></div><ul>
<li><a href="clickhouse/data_replicas.html#%E6%95%B0%E6%8D%AE%E5%89%AF%E6%9C%AC">数据副本</a>
<ul>
<li><a href="clickhouse/data_replicas.html#%E5%89%AF%E6%9C%AC%E7%9A%84%E7%89%B9%E7%82%B9">副本的特点</a></li>
<li><a href="clickhouse/data_replicas.html#zookeeper%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%B9%E5%BC%8F">zookeeper的配置方式</a></li>
<li><a href="clickhouse/data_replicas.html#%E5%89%AF%E6%9C%AC%E7%9A%84%E5%AE%9A%E4%B9%89%E5%BD%A2%E5%BC%8F">副本的定义形式</a></li>
</ul>
</li>
</ul>
<h1 id="数据副本"><a class="header" href="#数据副本">数据副本</a></h1>
<p>在 <code>*MergeTree</code> 的前面增加<code>Replicated</code>的前缀，则能够组合成一个新的变种引擎，即<code>Replicated-MergeTree</code>复制表，如图所示。</p>
<p><img src="clickhouse/../images/clickhouse03.jpg" alt="多分片多副本示意图" /></p>
<p><img src="clickhouse/../images/clickhouse04.jpg" alt="多副本引擎" /></p>
<p>只有使用了<code>ReplicatedMergeTree</code>复制表系列引擎，才能应用副本的能力。或者用一种更为直接的方式理解，即使用<code>ReplicatedMergeTree</code>的数据表就是副本。</p>
<p><code>ReplicatedMergeTree</code>是<code>MergeTree</code>的派生引擎，它在<code>MergeTree</code>的基础上加入了分布式协同的能力，如图所示:</p>
<p><img src="clickhouse/../images/clickhouse05.jpg" alt="多副本引擎" /></p>
<p>在MergeTree中，一个数据分区由开始创建到全部完成，会历经两类存储区域。</p>
<p>（1）<strong>内存</strong>：数据首先会被写入内存缓冲区。
（2）<strong>本地磁盘</strong>：数据接着会被写入tmp临时目录分区，待全部完成后再将临时目录重命名为正式分区。</p>
<p><code>ReplicatedMergeTree</code>在上述基础之上增加了<code>ZooKeeper</code>的部分，它会进一步在<code>ZooKeeper</code>内创建一系列的监听节点，并以此实现多个实例之间的通信。在整个通信过程中，<code>ZooKeeper</code>并不会涉及表数据的传输。</p>
<h2 id="副本的特点"><a class="header" href="#副本的特点">副本的特点</a></h2>
<p>作为数据副本的主要实现载体，<code>ReplicatedMergeTree</code>在设计上有一些显著特点。</p>
<ul>
<li>
<p><strong>依赖ZooKeeper</strong>：在执行<code>INSERT</code>和<code>ALTER</code>查询的时候，<code>ReplicatedMergeTree</code>需要借助<code>ZooKeeper</code>的分布式协同能力，以实现多个副本之间的同步。但是在查询副本的时候，并不需要使用<code>ZooKeeper</code>。</p>
</li>
<li>
<p><strong>表级别的副本</strong>：副本是在表级别定义的，所以每张表的副本配置都可以按照它的实际需求进行个性化定义，包括副本的数量，以及副本在集群内的分布位置等。</p>
</li>
<li>
<p><strong>多主架构</strong>（Multi Master）：<strong>可以在任意一个副本上执行INSERT和ALTER查询，它们的效果是相同的</strong>。这些操作会借助<code>ZooKeeper</code>的协同能力被分发至每个副本以本地形式执行。</p>
</li>
<li>
<p><strong>Block数据块</strong>：在执行<code>INSERT</code>命令写入数据时，会依据<code>max_insert_block_size</code>的大小（默认<code>1048576</code>行）将数据切分成若干个<code>Block</code>数据块。所以<code>Block</code>数据块是数据写入的基本单元，并且具有写入的原子性和唯一性。</p>
</li>
<li>
<p><strong>原子性</strong>：在数据写入时，一个<code>Block</code>块内的数据要么全部写入成功，要么全部失败。</p>
</li>
<li>
<p><strong>唯一性</strong>：在写入一个<code>Block</code>数据块的时候，会按照当前<code>Block</code>数据块的数据顺序、数据行和数据大小等指标，计算Hash信息摘要并记录在案。在此之后，如果某个待写入的<code>Block</code>数据块与先前已被写入的<code>Block</code>数据块拥有相同的Hash摘要（<code>Block</code>数据块内数据顺序、数据大小和数据行均相同），则该<code>Block</code>数据块会被忽略。这项设计可以预防由异常原因引起的<code>Block</code>数据块重复写入的问题。</p>
</li>
</ul>
<h2 id="zookeeper的配置方式"><a class="header" href="#zookeeper的配置方式">zookeeper的配置方式</a></h2>
<p>在正式开始之前，还需要安装并配置ZooKeeper，因为ReplicatedMergeTree必须对接到它才能工作。</p>
<p>关于ZooKeeper的安装，参考官方文档，使用3.4.5及以上版本均可。</p>
<p>这里着重讲解如何在ClickHouse中增加ZooKeeper的配置。</p>
<p>ClickHouse使用一组zookeeper标签定义相关配置，默认情况下，在全局配置<code>config.xml</code>中定义即可。但是各个副本所使用的<code>Zookeeper</code>配置通常是相同的，为了便于在多个节点之间复制配置文件，更常见的做法是将这一部分配置抽离出来，独立使用一个文件保存。</p>
<p>首先，在服务器的<code>/etc/clickhouse-server/config.d</code>目录下创建一个名为<code>metrika.xml</code>的配置文件：</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;yandex&gt;
  &lt;zookeeper-servers&gt; &lt;!—ZooKeeper配置, 名称自定义 --&gt;
    &lt;node index=&quot;1&quot;&gt; &lt;!—节点配置, 可以配置多个地址--&gt;
      &lt;host&gt;hdp1.nauu.com&lt;/host&gt;
      &lt;port&gt;2181&lt;/port&gt;
    &lt;/node&gt;
  &lt;/zookeeper-servers&gt;
&lt;/yandex&gt;
</code></pre>
<p>接着，在全局配置<code>config.xml</code>中使用<code>&lt;include_from&gt;</code>标签导入刚才定义的配置：</p>
<pre><code class="language-xml">&lt;include_from&gt;/etc/clickhouse-server/config.d/metrika.xml&lt;/include_from&gt;
</code></pre>
<p>并引用ZooKeeper配置的定义：</p>
<pre><code class="language-xml">&lt;zookeeper incl=&quot;zookeeper-servers&quot; optional=&quot;false&quot; /&gt;
</code></pre>
<p>其中，incl与metrika.xml配置文件内的节点名称要彼此对应。至此，整个配置过程就完成了。</p>
<p>ClickHouse在它的系统表中，颇为贴心地提供了一张名为<code>zookeeper</code>的代理表。通过这张表，可以使用SQL查询的方式读取远端<code>ZooKeeper</code>内的数据。有一点需要注意，在用于查询的SQL语句中，必须指定<code>path</code>条件，例如查询根路径：</p>
<pre><code class="language-sql">SELECT * FROM system.zookeeper where path = '/'

┌─name────────────────┬───value─┬──czxid─┐
│ dolphinscheduler    │         │  2627  │
│ clickhouse          │         │ 92875  │
└─────────────────────┴─────────┴────────┘
</code></pre>
<p>进一步查询clickhouse目录：</p>
<pre><code class="language-sql">SELECT name, value, czxid, mzxid FROM system.zookeeper where path = '/clickhouse'

┌─────name─────┬───value─┬──czxid──┬───mzxid──┐
│ tables       │         │ 134107  │ 134107   │
│ task_queue   │         │  92876  │  92876   │
└──────────────┴─────────┴─────────┴──────────┘
</code></pre>
<h2 id="副本的定义形式"><a class="header" href="#副本的定义形式">副本的定义形式</a></h2>
<p>使用副本的好处甚多。<strong>首先，由于增加了数据的冗余存储，所以降低了数据丢失的风险；其次，由于副本采用了多主架构，所以每个副本实例都可以作为数据读、写的入口，这无疑分摊了节点的负载。</strong></p>
<p>在使用副本时，不需要依赖任何集群配置, <code>ReplicatedMergeTree</code>结合<code>ZooKeeper</code>就能完成全部工作。</p>
<p><code>ReplicatedMergeTree</code>的定义方式如下：</p>
<pre><code class="language-sql">ENGINE = ReplicatedMergeTree('zk_path', 'replica_name')
</code></pre>
<p><strong>zk_path</strong></p>
<ul>
<li>
<p>用于指定在<code>ZooKeeper</code>中创建的数据表的路径，路径名称是自定义的，并没有固定规则，用户可以设置成自己希望的任何路径。即便如此，ClickHouse还是提供了一些约定俗成的配置模板以供参考，例如：</p>
<pre><code class="language-sql">/clickhouse/tables/{shard}/table_name
</code></pre>
<p>其中：</p>
<ul>
<li><code>/clickhouse/tables/</code>是约定俗成的路径固定前缀，表示存放数据表的根路径。</li>
<li><code>{shard}</code>表示分片编号，通常用数值替代，例如01、02、03。一张数据表可以有多个分片，而每个分片都拥有自己的副本。</li>
<li><code>table_name</code>表示数据表的名称，为了方便维护，通常与物理表的名字相同（虽然ClickHouse并不强制要求路径中的表名称和物理表名相同）；</li>
</ul>
</li>
</ul>
<p><strong>replica_name</strong></p>
<ul>
<li>作用是定义在<code>ZooKeeper</code>中创建的副本名称，该名称是区分不同副本实例的唯一标识。一种约定俗成的命名方式是使用所在服务器的域名称。</li>
</ul>
<p>对于<code>zk_path</code>而言，同一张数据表的同一个分片的不同副本，应该定义相同的路径；</p>
<p>而对于<code>replica_name</code>而言，同一张数据表的同一个分片的不同副本，应该定义不同的名称。</p>
<p>是不是有些绕口呢？下面列举几个示例。</p>
<p>1个分片、1个副本的情形：</p>
<pre><code class="language-sql">-- 1分片, 1副本. zk_path相同, replica_name不同
ReplicatedMergeTree('/clickhouse/tables/01/test_1', 'ch5.nauu.com')
ReplicatedMergeTree('/clickhouse/tables/01/test_1', 'ch6.nauu.com')
</code></pre>
<p>多个分片、1个副本的情形：</p>
<pre><code class="language-sql">-- 分片1
-- 2分片, 1副本. zk_path相同, 其中{shard}=01, replica_name不同
ReplicatedMergeTree('/clickhouse/tables/01/test_1', 'ch5.nauu.com')
ReplicatedMergeTree('/clickhouse/tables/01/test_1', 'ch6.nauu.com')

-- 分片2
-- 2分片, 1副本. zk_path相同, 其中{shard}=02, replica_name不同
ReplicatedMergeTree('/clickhouse/tables/02/test_1', 'ch7.nauu.com')
ReplicatedMergeTree('/clickhouse/tables/02/test_1', 'ch8.nauu.com')
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><ul>
<li><a href="clickhouse/replicated_megetree_principle.html#replicatedmergetree%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90">ReplicatedMergeTree原理解析</a>
<ul>
<li><a href="clickhouse/replicated_megetree_principle.html#1-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84">1. 数据结构</a>
<ul>
<li><a href="clickhouse/replicated_megetree_principle.html#11-zookeeper%E5%86%85%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84">1.1 zookeeper内的数据结构</a></li>
<li><a href="clickhouse/replicated_megetree_principle.html#12-entry%E6%97%A5%E5%BF%97%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84">1.2 Entry日志对象的数据结构</a></li>
</ul>
</li>
<li><a href="clickhouse/replicated_megetree_principle.html#2-%E5%89%AF%E6%9C%AC%E5%8D%8F%E5%90%8C%E7%9A%84%E6%A0%B8%E5%BF%83%E6%B5%81%E7%A8%8B">2. 副本协同的核心流程</a>
<ul>
<li><a href="clickhouse/replicated_megetree_principle.html#21-insert%E7%9A%84%E6%A0%B8%E5%BF%83%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B">2.1 INSERT的核心执行流程</a></li>
<li><a href="clickhouse/replicated_megetree_principle.html#22-merge%E7%9A%84%E6%A0%B8%E5%BF%83%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B">2.2 MERGE的核心执行流程</a></li>
<li><a href="clickhouse/replicated_megetree_principle.html#23-mutation%E7%9A%84%E6%A0%B8%E5%BF%83%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B">2.3 MUTATION的核心执行流程</a></li>
<li><a href="clickhouse/replicated_megetree_principle.html#24-alter%E7%9A%84%E6%A0%B8%E5%BF%83%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B">2.4 ALTER的核心执行流程</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="replicatedmergetree原理解析"><a class="header" href="#replicatedmergetree原理解析">ReplicatedMergeTree原理解析</a></h1>
<p>ReplicatedMergeTree作为复制表系列的基础表引擎，涵盖了数据副本最为核心的逻辑，将它拿来作为副本的研究标本是最合适不过了。因为只要剖析了ReplicatedMergeTree的核心原理，就能掌握整个ReplicatedMergeTree系列表引擎的使用方法。</p>
<h2 id="1-数据结构"><a class="header" href="#1-数据结构">1. 数据结构</a></h2>
<p>在<code>ReplicatedMergeTree</code>的核心逻辑中，大量运用了<code>ZooKeeper</code>的能力，以实现多个<code>ReplicatedMergeTree</code>副本实例之间的协同，包括主副本选举、副本状态感知、操作日志分发、任务队列和<code>BlockID</code>去重判断等。在执行<code>INSERT</code>数据写入、<code>MERGE</code>分区和<code>MUTATION</code>操作的时候，都会涉及与<code>ZooKeeper</code>的通信。但是在通信的过程中，并不会涉及任何表数据的传输，在查询数据的时候也不会访问<code>ZooKeeper</code>，所以不必过于担心<code>ZooKeeper</code>的承载压力。</p>
<h3 id="11-zookeeper内的数据结构"><a class="header" href="#11-zookeeper内的数据结构">1.1 zookeeper内的数据结构</a></h3>
<p><code>ReplicatedMergeTree</code>需要依靠<code>ZooKeeper</code>的事件监听机制以实现各个副本之间的协同。所以，在每张<code>ReplicatedMergeTree</code>表的创建过程中，它会以<code>zk_path</code>为根路径，在<code>Zoo-Keeper</code>中为这张表创建一组监听节点。按照作用的不同，监听节点可以大致分成如下几类：</p>
<p><strong>元数据</strong>:</p>
<ul>
<li><strong>/metadata</strong><a name="metadata"></a>：保存元数据信息，包括主键、分区键、采样表达式等。</li>
<li><strong>/columns</strong><a name="columns"></a>：保存列字段信息，包括列名称和数据类型。</li>
<li><strong>/replicas</strong><a name="replicas"></a>：保存副本名称，对应设置参数中的replica_name。</li>
</ul>
<p><strong>判断标识</strong>:</p>
<ul>
<li><strong>/leader_election</strong><a name="leader_election"></a>：用于主副本的选举工作，主副本会主导MERGE和MUTATION操作（ALTER DELETE和ALTER UPDATE）。这些任务在主副本完成之后再借助ZooKeeper将消息事件分发至其他副本。</li>
<li><strong>/blocks</strong><a name="blocks"></a>：记录Block数据块的Hash信息摘要，以及对应的partition_id。通过Hash摘要能够判断Block数据块是否重复；通过partition_id，则能够找到需要同步的数据分区。</li>
<li><strong>/block_numbers</strong><a name="block_numbers"></a>：按照分区的写入顺序，以相同的顺序记录partition_id。各个副本在本地进行MERGE时，都会依照相同的block_numbers顺序进行。</li>
<li><strong>/quorum</strong><a name="quorum"></a>：记录quorum的数量，当至少有quorum数量的副本写入成功后，整个写操作才算成功。quorum的数量由insert_quorum参数控制，默认值为0。</li>
</ul>
<p><strong>操作日志</strong>：</p>
<ul>
<li><strong>/log</strong><a name="log"></a>：常规操作日志节点（INSERT、MERGE和DROP PARTITION），它是整个工作机制中最为重要的一环，保存了副本需要执行的任务指令。log使用了ZooKeeper的持久顺序型节点，每条指令的名称以log-为前缀递增，例如log-0000000000、log-0000000001等。每一个副本实例都会监听/log节点，当有新的指令加入时，它们会把指令加入副本各自的任务队列，并执行任务。关于这方面的执行逻辑，稍后会进一步展开。</li>
<li><strong>/mutations</strong><a name="mutations"></a>：MUTATION操作日志节点，作用与log日志类似，当执行ALER DELETE和ALER UPDATE查询时，操作指令会被添加到这个节点。mutations同样使用了ZooKeeper的持久顺序型节点，但是它的命名没有前缀，每条指令直接以递增数字的形式保存，例如0000000000、0000000001等。关于这方面的执行逻辑，同样稍后展开。</li>
<li><strong>/replicas/{replica_name}/*</strong><a name="replicas"></a>：每个副本各自的节点下的一组监听节点，用于指导副本在本地执行具体的任务指令，其中较为重要的节点有如下几个：</li>
<li><strong>/queue</strong><a name="queue"></a>：任务队列节点，用于执行具体的操作任务。当副本从/log或/mutations节点监听到操作指令时，会将执行任务添加至该节点下，并基于队列执行。</li>
<li><strong>/log_pointer</strong><a name="log_pointer"></a>：log日志指针节点，记录了最后一次执行的log日志下标信息，例如log_pointer：4对应了/log/log-0000000003（从0开始计数）。</li>
<li><strong>/mutation_pointer</strong><a name="mutation_pointer"></a>：mutations日志指针节点，记录了最后一次执行的mutations日志名称，例如mutation_pointer：0000000000对应了/mutations/000000000。</li>
</ul>
<h3 id="12-entry日志对象的数据结构"><a class="header" href="#12-entry日志对象的数据结构">1.2 Entry日志对象的数据结构</a></h3>
<p><code>ReplicatedMergeTree</code>在<code>ZooKeeper</code>中有两组非常重要的父节点，那就是<a href="clickhouse/replicated_megetree_principle.html#log">/log</a>和<a href="clickhouse/replicated_megetree_principle.html#mutations">/mutations</a>。它们的作用犹如一座通信塔，是分发操作指令的信息通道，而发送指令的方式，则是为这些父节点添加子节点。所有的副本实例，都会监听父节点的变化，当有子节点被添加时，它们能实时感知。</p>
<p>这些被添加的子节点在<code>ClickHouse</code>中被统一抽象为<code>Entry</code>对象，而具体实现则由<code>Log-Entry</code>和<code>MutationEntry</code>对象承载，分别对应<a href="clickhouse/replicated_megetree_principle.html#log">/log</a>和<a href="clickhouse/replicated_megetree_principle.html#mutations">/mutations</a>节点。</p>
<p><strong>LogEntry</strong>:</p>
<p>LogEntry用于封装/log的子节点信息，它拥有如下几个核心属性：</p>
<ul>
<li><strong>source replica</strong>：发送这条Log指令的副本来源，对应replica_name。</li>
<li><strong>type</strong>：操作指令类型，主要有get、merge和mutate三种，分别对应从远程副本下载分区、合并分区和MUTATION操作。</li>
<li><strong>block_id</strong>：当前分区的BlockID，对应/blocks路径下子节点的名称。</li>
<li><strong>partition_name</strong>：当前分区目录的名称。</li>
</ul>
<p><strong>MutationEntry</strong>:</p>
<p>MutationEntry用于封装/mutations的子节点信息，它同样拥有如下几个核心属性：</p>
<ul>
<li><strong>source replica</strong>：发送这条MUTATION指令的副本来源，对应replica_name。</li>
<li><strong>commands</strong>：操作指令，主要有ALTER DELETE和ALTER UPDATE。</li>
<li><strong>mutation_id</strong>：MUTATION操作的版本号。</li>
<li><strong>partition_id</strong>：当前分区目录的ID。</li>
</ul>
<h2 id="2-副本协同的核心流程"><a class="header" href="#2-副本协同的核心流程">2. 副本协同的核心流程</a></h2>
<p>副本协同的核心流程主要有<code>INSERT</code>、<code>MERGE</code>、<code>MUTATION</code>和<code>ALTER</code>四种，分别对应了<em>数据写入</em>、<em>分区合并</em>、<em>数据修改</em>和<em>元数据修改</em>。</p>
<p><code>INSERT</code>和<code>ALTER</code>查询是分布式执行的。借助<code>ZooKeeper</code>的事件通知机制，多个副本之间会自动进行有效协同，但是它们不会使用<code>ZooKeeper</code>存储任何分区数据。</p>
<p>而其他查询并不支持分布式执行，包括<code>SELECT</code>、<code>CREATE</code>、<code>DROP</code>、<code>RENAME</code>和<code>ATTACH</code>。</p>
<p>例如，为了创建多个副本，我们需要分别登录每个ClickHouse节点，在它们本地执行各自的<code>CREATE</code>语句（后面将会介绍如何利用集群配置简化这一操作）。接下来，会依次介绍上述流程的工作机理。</p>
<p>首先，拟定一个演示场景，即使用<code>ReplicatedMergeTree</code>实现一张拥有1分片、1副本的数据表，并以此来贯穿整个讲解过程（对于大于1个副本的场景，流程以此类推）。</p>
<p>接着，通过对<code>ReplicatedMergeTree</code>分别执行<code>INSERT</code>、<code>MERGE</code>、<code>MUTATION</code>和<code>ALTER</code>操作，以此来讲解相应的工作原理。与此同时，通过实际案例，论证工作原理。</p>
<h3 id="21-insert的核心执行流程"><a class="header" href="#21-insert的核心执行流程">2.1 INSERT的核心执行流程</a></h3>
<p>当需要在<code>ReplicatedMergeTree</code>中执行<code>INSERT</code>查询以写入数据时，即会进入<code>INSERT</code>核心流程，其整体示意如图所示。</p>
<p>整个流程从上至下按照时间顺序进行，其大致可分成8个步骤。现在，根据图所示编号讲解整个过程。</p>
<p><img src="clickhouse/../images/clickhouse06.jpg" alt="协同的核心流程" /></p>
<ul>
<li>
<p>1）创建第一个副本实例</p>
<p>假设首先从CH5节点开始，对CH5节点执行下面的语句后，会创建第一个副本实例：</p>
<pre><code class="language-sql">CREATE TABLE replicated_sales_1(
id String,
price Float64,
create_time DateTime
) ENGINE =  ReplicatedMergeTree('/clickhouse/tables/01/replicated_sales_1','ch5.nauu.com')
PARTITION BY toYYYYMM(create_time) 
ORDER BY id
</code></pre>
<p>在创建的过程中，ReplicatedMergeTree会进行一些初始化操作，例如：</p>
<ul>
<li>根据zk_path初始化所有的ZooKeeper节点。</li>
<li>在/replicas/节点下注册自己的副本实例ch5.nauu.com。</li>
<li>启动监听任务，监听/log日志节点。</li>
<li>参与副本选举，选举出主副本，选举的方式是向/leader_election/插入子节点，第一个插入成功的副本就是主副本。</li>
</ul>
</li>
<li>
<ol start="2">
<li>创建第二个副本实例</li>
</ol>
<p>接着，在CH6节点执行下面的语句，创建第二个副本实例。表结构和zk_path需要与第一个副本相同，而replica_name则需要设置成CH6的域名：</p>
<pre><code class="language-sql">CREATE TABLE replicated_sales_1(
-- 相同结构
) ENGINE =  ReplicatedMergeTree('/clickhouse/tables/01/replicated_sales_1','ch6.nauu.com')
-- 相同结构
</code></pre>
<p>在创建过程中，第二个ReplicatedMergeTree同样会进行一些初始化操作，例如：</p>
<ul>
<li>在/replicas/节点下注册自己的副本实例ch6.nauu.com。</li>
<li>启动监听任务，监听/log日志节点。</li>
<li>参与副本选举，选举出主副本。在这个例子中，CH5副本成为主副本。</li>
</ul>
</li>
<li>
<p>3）向第一个副本实例写入数据</p>
<p>现在尝试向第一个副本CH5写入数据。执行如下命令：</p>
<pre><code class="language-sql">INSERT INTO TABLE replicated_sales_1 VALUES('A001',100,'2019-05-10 00:00:00')
</code></pre>
<p>上述命令执行之后，首先会在本地完成分区目录的写入：</p>
<pre><code class="language-sql">Renaming temporary part tmp_insert_201905_1_1_0 to 201905_0_0_0
</code></pre>
<p>接着向/blocks节点写入该数据分区的block_id：</p>
<pre><code class="language-sql">Wrote block with ID '201905_2955817577822961065_12656761735954722499'
</code></pre>
<p>该block_id将作为后续去重操作的判断依据。如果此时再次执行刚才的INSERT语句，试图写入重复数据，则会出现如下提示：</p>
<pre><code class="language-sql">Block with ID 201905_2955817577822961065_12656761735954722499 already exists; ignoring it.
</code></pre>
<p>即副本会自动忽略block_id重复的待写入数据。</p>
<p>此外，如果设置了insert_quorum参数（默认为0），并且insert_quorum&gt;=2，则CH5会进一步监控已完成写入操作的副本个数，只有当写入副本个数大于或等于insert_quorum时，整个写入操作才算成功。</p>
</li>
<li>
<p>4）由第一个副本实例推送Log日志</p>
<p>在3步骤完成之后，会继续由执行了INSERT的副本向/log节点推送操作日志。在这个例子中，会由第一个副本CH5担此重任。日志的编号是/log/log-0000000000，而LogEntry的核心属性如下：</p>
<pre><code class="language-sql">/log/log-0000000000
source replica: ch5.nauu.com
block_id:  201905_...
type :   get
partition_name :201905_0_0_0
</code></pre>
</li>
<li>
<ol start="5">
<li>第二个副本实例拉取Log日志</li>
</ol>
<p>CH6副本会一直监听/log节点变化，当CH5推送了/log/log-0000000000之后，CH6便会触发日志的拉取任务并更新log_pointer，将其指向最新日志下标：</p>
<pre><code class="language-sql">/replicas/ch6.nauu.com/log_pointer : 0
</code></pre>
<p>在拉取了LogEntry之后，它并不会直接执行，而是将其转为任务对象放至队列：</p>
<pre><code class="language-sql">/replicas/ch6.nauu.com/queue/
Pulling 1 entries to queue: log-0000000000 - log-0000000000
</code></pre>
<p>这是因为在复杂的情况下，考虑到在同一时段内，会连续收到许多个LogEntry，所以使用队列的形式消化任务是一种更为合理的设计。注意，拉取的LogEntry是一个区间，这同样也是因为可能会连续收到多个LogEntry。</p>
</li>
<li>
<p>6）第二个副本实例向其他副本发起下载请求</p>
<p>CH6基于/queue队列开始执行任务。当看到type类型为get的时候，ReplicatedMerge-Tree会明白此时在远端的其他副本中已经成功写入了数据分区，而自己需要同步这些数据。</p>
<p>CH6上的第二个副本实例会开始选择一个远端的其他副本作为数据的下载来源。远端副本的选择算法大致是这样的：</p>
<ol>
<li>从/replicas节点拿到所有的副本节点。</li>
<li>遍历这些副本，选取其中一个。选取的副本需要拥有最大的log_pointer下标，并且/queue子节点数量最少。log_pointer下标最大，意味着该副本执行的日志最多，数据应该更加完整；而/queue最小，则意味着该副本目前的任务执行负担较小。</li>
</ol>
<p>在这个例子中，算法选择的远端副本是CH5。于是，CH6副本向CH5发起了HTTP请求，希望下载分区201905_0_0_0：</p>
<pre><code class="language-sql">Fetching part 201905_0_0_0 from replicas/ch5.nauu.com
Sending request to http://ch5.nauu.com:9009/?endpoint=DataPartsExchange
</code></pre>
<p>如果第一次下载请求失败，在默认情况下，CH6再尝试请求4次，一共会尝试5次（由<code>max_fetch_partition_retries_count</code>参数控制，默认为5）。</p>
</li>
<li>
<p>7）第一个副本实例响应数据下载</p>
<p>CH5的DataPartsExchange端口服务接收到调用请求，在得知对方来意之后，根据参数做出响应，将本地分区201905_0_0_0基于DataPartsExchang的服务响应发送回CH6：</p>
<pre><code class="language-sql">Sending part 201905_0_0_0
</code></pre>
</li>
<li>
<p>8）第二个副本实例下载数据并完成本地写入</p>
<p>CH6副本在收到CH5的分区数据后，首先将其写至临时目录：</p>
<pre><code class="language-sql">tmp_fetch_201905_0_0_0
</code></pre>
<p>待全部数据接收完成之后，重命名该目录：</p>
<pre><code class="language-sql">Renaming temporary part tmp_fetch_201905_0_0_0 to 201905_0_0_0
</code></pre>
<p>至此，整个写入流程结束。</p>
<p>可以看到，在<code>INSERT</code>的写入过程中，<code>ZooKeeper</code>不会进行任何实质性的数据传输。本着谁执行谁负责的原则，在这个案例中由CH5首先在本地写入了分区数据。之后，也由这个副本负责发送Log日志，通知其他副本下载数据。如果设置了<code>insert_quorum</code>并且<code>insert_quorum&gt;=2</code>，则还会由该副本监控完成写入的副本数量。其他副本在接收到Log日志之后，会选择一个最合适的远端副本，点对点地下载分区数据。</p>
</li>
</ul>
<h3 id="22-merge的核心执行流程"><a class="header" href="#22-merge的核心执行流程">2.2 MERGE的核心执行流程</a></h3>
<p>当ReplicatedMergeTree触发分区合并动作时，即会进入这个部分的流程，它的核心流程如图所示。</p>
<p><img src="clickhouse/../images/clickhouse07.jpg" alt="与其他副本的协同核心流程" /></p>
<p>无论MERGE操作从哪个副本发起，其合并计划都会交由主副本来制定。在INSERT的例子中，CH5节点已经成功竞选为主副本，所以为了方便论证，这个案例就从CH6节点开始。整个流程从上至下按照时间顺序进行，其大致分成5个步骤。现在，根据图中所示编号讲解整个过程。</p>
<ul>
<li>
<p>1）创建远程连接，尝试与主副本通信</p>
<p>首先在CH6节点执行OPTIMIZE，强制触发MERGE合并。这个时候，CH6通过/replicas找到主副本CH5，并尝试建立与它的远程连接。</p>
<pre><code class="language-sql">optimize table replicated_sales_1
Connection (ch5.nauu.com:9000): Connecting. Database: default. User: default
</code></pre>
</li>
<li>
<p>2）主副本接收通信</p>
<p>主副本CH5接收并建立来自远端副本CH6的连接。</p>
<pre><code class="language-sql">Connected ClickHouse Follower replica version 19.17.0, revision: 54428, database: default, user: default.
</code></pre>
</li>
<li>
<p>3）由主副本制定MERGE计划并推送Log日志</p>
<p>由主副本CH5制定MERGE计划，并判断哪些分区需要被合并。在选定之后，CH5将合并计划转换为Log日志对象并推送Log日志，以通知所有副本开始合并。日志的核心信息如下：</p>
<pre><code class="language-log">/log/log-0000000002
source replica: ch5.nauu.com
block_id:  
type :   merge
201905_0_0_0
201905_1_1_0
into
201905_0_1_1
</code></pre>
<p>从日志内容中可以看出，操作类型为Merge合并，而这次需要合并的分区目录是201905_0_0_0和201905_1_1_0。</p>
<p>与此同时，主副本还会锁住执行线程，对日志的接收情况进行监听：</p>
<pre><code class="language-sql">Waiting for queue-0000000002 to disappear from ch5.nauu.com queue
</code></pre>
<p>其监听行为由<code>replication_alter_partitions_sync</code>参数控制，默认值为<code>1</code>。当此参数为0时，不做任何等待；为<code>1</code>时，只等待主副本自身完成；为<code>2</code>时，会等待所有副本拉取完成。</p>
</li>
<li>
<p>4）各个副本分别拉取Log日志</p>
<p>CH5和CH6两个副本实例将分别监听/log/log-0000000002日志的推送，它们也会分别拉取日志到本地，并推送到各自的/queue任务队列：</p>
<pre><code class="language-sql">Pulling 1 entries to queue: log-0000000002 - log-0000000002
</code></pre>
</li>
<li>
<p>5）各个副本分别在本地执行MERGE</p>
<p>CH5和CH6基于各自的/queue队列开始执行任务：</p>
<pre><code class="language-sql">Executing log entry to merge parts 201905_0_0_0, 201905_1_1_0 to 201905_0_1_1
</code></pre>
<p>各个副本开始在本地执行MERGE：</p>
<pre><code class="language-sql">Merged 2 parts: from 201905_0_0_0 to 201905_1_1_0
</code></pre>
<p>至此，整个合并流程结束。</p>
</li>
</ul>
<p>可以看到，<strong>在MERGE的合并过程中，ZooKeeper也不会进行任何实质性的数据传输，所有的合并操作，最终都是由各个副本在本地完成的</strong>。</p>
<p><strong>而无论合并动作在哪个副本被触发，都会首先被转交至主副本，再由主副本负责合并计划的制定、消息日志的推送以及对日志接收情况的监控。</strong></p>
<h3 id="23-mutation的核心执行流程"><a class="header" href="#23-mutation的核心执行流程">2.3 MUTATION的核心执行流程</a></h3>
<p>当对ReplicatedMergeTree执行ALTER DELETE或者ALTER UPDATE操作的时候，即会进入MUTATION部分的逻辑，它的核心流程如图10-8所示。</p>
<p>与MERGE类似，无论MUTATION操作从哪个副本发起，首先都会由主副本进行响应。所以为了方便论证，这个案例还是继续从CH6节点开始（因为CH6不是主副本）。整个流程从上至下按照时间顺序进行，其大致分成5个步骤。现在根据图10-8中所示编号讲解整个过程。</p>
<p><img src="clickhouse/../images/clickhouse08.jpeg" alt="与其他副本的协同核心流程" /></p>
<ul>
<li>
<p>1）推送MUTATION日志</p>
<p>在CH6节点尝试通过DELETE来删除数据（执行UPDATE的效果与此相同），执行如下命令：</p>
<pre><code class="language-sql">ALTER TABLE replicated_sales_1 DELETE WHERE id = '1'
</code></pre>
<p>执行之后，该副本会接着进行两个重要事项：</p>
<ul>
<li>
<p>创建MUTATION ID：</p>
<pre><code class="language-sql">Created mutation with ID 0000000000
</code></pre>
</li>
<li>
<p>将MUTATION操作转换为MutationEntry日志，并推送到/mutations/0000000000。MutationEntry的核心属性如下：</p>
<pre><code class="language-sql">/mutations/0000000000
source replica: ch6.nauu.com
mutation_id:  2
partition_id: 201905
commands: DELETE WHERE id = \'1\'
</code></pre>
</li>
</ul>
<p>由此也能知晓，MUTATION的操作日志是经由/mutations节点分发至各个副本的。</p>
</li>
<li>
<p>2）所有副本实例各自监听MUTATION日志</p>
<p>CH5和CH6都会监听/mutations节点，所以一旦有新的日志子节点加入，它们都能实时感知：</p>
<pre><code class="language-sql">Loading 1 mutation entries: 0000000000 – 0000000000
</code></pre>
<p>当监听到有新的MUTATION日志加入时，并不是所有副本都会直接做出响应，它们首先会判断自己是否为主副本。</p>
</li>
<li>
<p>3）由主副本实例响应MUTATION日志并推送Log日志</p>
<p>只有主副本才会响应MUTATION日志，在这个例子中主副本为CH5，所以CH5将MUTATION日志转换为LogEntry日志并推送至/log节点，以通知各个副本执行具体的操作。日志的核心信息如下：</p>
<pre><code class="language-sql">/log/log-0000000003
 source replica: ch5.nauu.com
 block_id:  
 type :   mutate
 201905_0_1_1
 to
 201905_0_1_1_2
</code></pre>
<p>从日志内容中可以看出，上述操作的类型为mutate，而这次需要将201905_0_1_1分区修改为201905_0_1_1_2(201905_0_1_1 +&quot;_&quot; + mutation_id)。</p>
</li>
<li>
<p>4）各个副本实例分别拉取Log日志</p>
<p>CH5和CH6两个副本分别监听/log/log-0000000003日志的推送，它们也会分别拉取日志到本地，并推送到各自的/queue任务队列：</p>
<pre><code class="language-sql">Pulling 1 entries to queue: log-0000000003 - log-0000000003
</code></pre>
</li>
<li>
<p>5）各个副本实例分别在本地执行MUTATION</p>
<p>CH5和CH6基于各自的/queue队列开始执行任务：</p>
<pre><code class="language-sql">Executing log entry to mutate part 201905_0_1_1 to 201905_0_1_1_2
</code></pre>
<p>各个副本，开始在本地执行MUTATION：</p>
<pre><code class="language-sql">Cloning part 201905_0_1_1 to tmp_clone_201905_0_1_1_2
Renaming temporary part tmp_clone_201905_0_1_1_2 to 201905_0_1_1_2.
</code></pre>
<p>至此，整个MUTATION流程结束。</p>
</li>
</ul>
<p>可以看到，在MUTATION的整个执行过程中，ZooKeeper同样不会进行任何实质性的数据传输。所有的MUTATION操作，最终都是由各个副本在本地完成的。而MUTATION操作是经过<a href="clickhouse/replicated_megetree_principle.html#mutations">/mutations</a>节点实现分发的。</p>
<p>本着谁执行谁负责的原则，在这个案例中由CH6负责了消息的推送。但是无论MUTATION动作从哪个副本被触发，之后都会被转交至主副本，再由主副本负责推送Log日志，以通知各个副本执行最终的MUTATION逻辑。同时也由主副本对日志接收的情况实行监控。</p>
<h3 id="24-alter的核心执行流程"><a class="header" href="#24-alter的核心执行流程">2.4 ALTER的核心执行流程</a></h3>
<p>当对ReplicatedMergeTree执行ALTER操作进行元数据修改的时候，即会进入ALTER部分的逻辑，例如增加、删除表字段等。而ALTER的核心流程如图所示。</p>
<p>与之前的几个流程相比，ALTET的流程会简单很多，其执行过程中并不会涉及/log日志的分发。整个流程从上至下按照时间顺序进行，其大致分成3个步骤。现在根据图中所示编号讲解整个过程。</p>
<p><img src="clickhouse/../images/clickhouse09.jpeg" alt="与其他副本的协同核心流程" /></p>
<ul>
<li>
<p>1）修改共享元数据</p>
<p>在CH6节点尝试增加一个列字段，执行如下语句：</p>
<pre><code class="language-sql">ALTER TABLE replicated_sales_1 ADD COLUMN id2 String
</code></pre>
<p>执行之后，CH6会修改ZooKeeper内的共享元数据节点：</p>
<pre><code class="language-sql">/metadata, /columns
Updated shared metadata nodes in ZooKeeper. Waiting for replicas to apply changes.
</code></pre>
<p>数据修改后，节点的版本号也会同时提升：</p>
<pre><code class="language-sql">Version of metadata nodes in ZooKeeper changed. Waiting for structure write lock.
</code></pre>
<p>与此同时，CH6还会负责监听所有副本的修改完成情况：</p>
<pre><code class="language-sql">Waiting for ch5.nauu.com to apply changes
Waiting for ch6.nauu.com to apply changes
</code></pre>
</li>
<li>
<p>2）监听共享元数据变更并各自执行本地修改</p>
<p>CH5和CH6两个副本分别监听共享元数据的变更。之后，它们会分别对本地的元数据版本号与共享版本号进行对比。在这个案例中，它们会发现本地版本号低于共享版本号，于是它们开始在各自的本地执行更新操作：</p>
<pre><code class="language-sql">Metadata changed in ZooKeeper. Applying changes locally.
Applied changes to the metadata of the table.
</code></pre>
</li>
<li>
<p>3）确认所有副本完成修改</p>
<p>CH6确认所有副本均已完成修改：</p>
<pre><code class="language-sql">ALTER finished
Done processing query
</code></pre>
<p>至此，整个ALTER流程结束。</p>
</li>
</ul>
<p>可以看到，在ALTER整个的执行过程中，ZooKeeper不会进行任何实质性的数据传输。所有的ALTER操作，最终都是由各个副本在本地完成的。</p>
<p>本着谁执行谁负责的原则，在这个案例中由CH6负责对共享元数据的修改以及对各个副本修改进度的监控。</p>
<div style="break-before: page; page-break-before: always;"></div><ul>
<li><a href="clickhouse/data_shards.html#%E6%95%B0%E6%8D%AE%E5%88%86%E7%89%87">数据分片</a>
<ul>
<li><a href="clickhouse/data_shards.html#1-%E9%9B%86%E7%BE%A4%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%B9%E5%BC%8F">1. 集群的配置方式</a>
<ul>
<li><a href="clickhouse/data_shards.html#11-%E4%B8%8D%E5%8C%85%E5%90%AB%E5%89%AF%E6%9C%AC%E7%9A%84%E5%88%86%E7%89%87">1.1 不包含副本的分片</a></li>
<li><a href="clickhouse/data_shards.html#12-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E7%89%87%E4%B8%8E%E5%89%AF%E6%9C%AC">1.2 自定义分片与副本</a></li>
</ul>
</li>
<li><a href="clickhouse/data_shards.html#2-%E5%9F%BA%E4%BA%8E%E9%9B%86%E7%BE%A4%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8Fddl">2. 基于集群实现分布式DDL</a>
<ul>
<li><a href="clickhouse/data_shards.html#21-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84">2.1 数据结构</a></li>
<li><a href="clickhouse/data_shards.html#22-%E5%88%86%E5%B8%83%E5%BC%8Fddl%E7%9A%84%E6%A0%B8%E5%BF%83%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B">2.2 分布式DDL的核心执行流程</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="数据分片"><a class="header" href="#数据分片">数据分片</a></h1>
<p>通过引入数据副本，虽然能够有效降低数据的丢失风险（多份存储），并提升查询的性能（分摊查询、读写分离），但是仍然有一个问题没有解决，那就是数据表的容量问题。到目前为止，每个副本自身，仍然保存了数据表的全量数据。所以在业务量十分庞大的场景中，依靠副本并不能解决单表的性能瓶颈。想要从根本上解决这类问题，需要借助另外一种手段，即进一步将数据水平切分，也就是数据分片。</p>
<p>ClickHouse中的每个服务节点都可称为一个shard（分片）。从理论上来讲，假设有N(N&gt;=1)张数据表A，分布在N个ClickHouse服务节点，而这些数据表彼此之间没有重复数据，那么就可以说数据表A拥有N个分片。然而在工程实践中，如果只有这些分片表，那么整个Sharding（分片）方案基本是不可用的。对于一个完整的方案来说，还需要考虑数据在写入时，如何被均匀地写至各个shard，以及数据在查询时，如何路由到每个shard，并组合成结果集。所以，ClickHouse的数据分片需要结合Distributed表引擎一同使用，如图所示。</p>
<p><img src="clickhouse/../images/clickhouse10.jpeg" alt="关系示意图" /></p>
<p>Distributed表引擎自身不存储任何数据，它能够作为分布式表的一层透明代理，在集群内部自动开展数据的写入、分发、查询、路由等工作。</p>
<h2 id="1-集群的配置方式"><a class="header" href="#1-集群的配置方式">1. 集群的配置方式</a></h2>
<p>在ClickHouse中，集群配置用shard代表分片、用replica代表副本。那么在逻辑层面，表示1分片、0副本语义的配置如下所示：</p>
<pre><code class="language-xml">&lt;shard&gt; &lt;!-- 分片 --&gt;
  &lt;replica&gt; &lt;!-- 副本 --&gt;
  &lt;/replica&gt;
&lt;/shard&gt;
</code></pre>
<p>而表示1分片、1副本语义的配置则是：</p>
<pre><code class="language-xml">&lt;shard&gt; &lt;!-- 分片 --&gt;
  &lt;replica&gt;&lt;!—副本 --&gt;
  &lt;/replica&gt;
  &lt;replica&gt;
  &lt;/replica&gt;
&lt;/shard&gt;
</code></pre>
<p>可以看到，这样的配置似乎有些反直觉，shard更像是逻辑层面的分组，而无论是副本还是分片，它们的载体都是replica，所以从某种角度来看，副本也是分片。关于这方面的详细介绍会在后续展开，现在先回到之前的话题。</p>
<p>由于<code>Distributed</code>表引擎需要读取集群的信息，所以首先必须为ClickHouse添加集群的配置。找到前面在介绍ZooKeeper配置时增加的<code>metrika.xml</code>配置文件，将其加入集群的配置信息。</p>
<p>集群有两种配置形式:</p>
<h3 id="11-不包含副本的分片"><a class="header" href="#11-不包含副本的分片">1.1 不包含副本的分片</a></h3>
<p>如果直接使用node标签定义分片节点，那么该集群将只包含分片，不包含副本。以下面的配置为例：</p>
<pre><code class="language-xml">&lt;yandex&gt;
  &lt;!--自定义配置名, 与config.xml配置的incl属性对应即可 --&gt;
  &lt;clickhouse_remote_servers&gt;
    &lt;shard_2&gt;&lt;!--自定义集群名称--&gt;
      &lt;node&gt;&lt;!--定义ClickHouse节点--&gt;
        &lt;host&gt;ch5.nauu.com&lt;/host&gt;
        &lt;port&gt;9000&lt;/port&gt;
        &lt;!--选填参数
            &lt;weight&gt;1&lt;/weight&gt;
            &lt;user&gt;&lt;/user&gt;
            &lt;password&gt;&lt;/password&gt;
            &lt;secure&gt;&lt;/secure&gt;
            &lt;compression&gt;&lt;/compression&gt;
        --&gt;
      &lt;/node&gt;
      &lt;node&gt;
        &lt;host&gt;ch6.nauu.com&lt;/host&gt;
        &lt;port&gt;9000&lt;/port&gt;
      &lt;/node&gt;
    &lt;/shard_2&gt;
    ……
  &lt;/clickhouse_remote_servers&gt;
</code></pre>
<p>该配置定义了一个名为shard_2的集群，其包含了2个分片节点，它们分别指向了CH5和CH6服务器。现在分别对配置项进行说明：</p>
<ul>
<li><strong>shard_2</strong>: 表示自定义的集群名称，全局唯一，是后续引用集群配置的唯一标识。在一个配置文件内，可以定义任意组集群。</li>
<li><strong>node</strong>: 用于定义分片节点，不包含副本。</li>
<li><strong>host</strong>: 指定部署了ClickHouse节点的服务器地址。</li>
<li><strong>port</strong>: 指定ClickHouse服务的TCP端口。</li>
</ul>
<p>接下来介绍选填参数：</p>
<ul>
<li><strong>weight</strong>: 分片权重默认为1，在后续小节中会对其详细介绍。</li>
<li><strong>user</strong>: 为ClickHouse用户，默认为default。</li>
<li><strong>password</strong>: 为ClickHouse的用户密码，默认为空字符串。</li>
<li><strong>secure</strong>: 为SSL连接的端口，默认为9440。</li>
<li><strong>compression</strong>: 表示是否开启数据压缩功能，默认为true.</li>
</ul>
<h3 id="12-自定义分片与副本"><a class="header" href="#12-自定义分片与副本">1.2 自定义分片与副本</a></h3>
<p>集群配置支持自定义分片和副本的数量，这种形式需要使用shard标签代替先前的node，除此之外的配置完全相同。在这种自定义配置的方式下，分片和副本的数量完全交由配置者掌控。其中，shard表示逻辑上的数据分片，而物理上的分片则用replica表示。如果在1个shard标签下定义N(N&gt;=1)组replica，则该shard的语义表示1个分片和N-1个副本。接下来用几组配置示例进行说明。</p>
<ul>
<li>
<p>1）不包含副本的分片</p>
<p>下面所示的这组集群配置的效果与先前介绍的shard_2集群相同：</p>
<pre><code class="language-xml">&lt;!-- 2个分片、0个副本 --&gt;
&lt;sharding_simple&gt; &lt;!-- 自定义集群名称 --&gt;
  &lt;shard&gt; &lt;!-- 分片 --&gt;
    &lt;replica&gt; &lt;!-- 副本 --&gt;
      &lt;host&gt;ch5.nauu.com&lt;/host&gt;
      &lt;port&gt;9000&lt;/port&gt;
    &lt;/replica&gt;
  &lt;/shard&gt;
  &lt;shard&gt;
    &lt;replica&gt;
      &lt;host&gt;ch6.nauu.com&lt;/host&gt;
      &lt;port&gt;9000&lt;/port&gt;
    &lt;/replica&gt;
  &lt;/shard&gt;
&lt;/sharding_simple&gt;
</code></pre>
<p>sharding_simple集群的语义为2分片、0副本（1分片、0副本，再加上1分片、0副本）。</p>
</li>
<li>
<p>2）N个分片和N个副本</p>
<p>这种形式可以按照实际需求自由组合，例如下面的这组配置，集群sharding_simple_1拥有1个分片和1个副本：</p>
<pre><code class="language-xml">&lt;!-- 1个分片 1个副本--&gt;
&lt;sharding_simple_1&gt;
  &lt;shard&gt;
    &lt;replica&gt;
      &lt;host&gt;ch5.nauu.com&lt;/host&gt;
      &lt;port&gt;9000&lt;/port&gt;
    &lt;/replica&gt;
    &lt;replica&gt;
      &lt;host&gt;ch6.nauu.com&lt;/host&gt;
      &lt;port&gt;9000&lt;/port&gt;
    &lt;/replica&gt;
  &lt;/shard&gt;
&lt;/sharding_simple_1&gt;
</code></pre>
<p>从上面的配置信息中能够得出结论，集群中replica数量的上限是由ClickHouse节点的数量决定的，例如为了部署集群sharding_ha，需要4个ClickHouse服务节点作为支撑。</p>
<p>在完成上述配置之后，可以查询系统表验证集群配置是否已被加载：</p>
<pre><code class="language-sql">:) SELECT cluster, host_name FROM system.clusters

┌─cluster──────────────┬──host_name────┐
│ shard_2              │ ch5.nauu.com  │
│ shard_2              │ ch6.nauu.com  │
│ sharding_simple      │ ch5.nauu.com  │
│ sharding_simple      │ ch6.nauu.com  │
│ sharding_simple_1    │ ch5.nauu.com  │
│ sharding_simple_1    │ ch6.nauu.com  │
└──────────────────────┴───────────────┘
</code></pre>
</li>
</ul>
<h2 id="2-基于集群实现分布式ddl"><a class="header" href="#2-基于集群实现分布式ddl">2. 基于集群实现分布式DDL</a></h2>
<p>默认的情况下，<code>CREATE</code>、<code>DROP</code>、<code>RENAME</code>和<code>ALTER</code>等<code>DDL语句</code>并不支持分布式执行。而在加入集群配置后，就可以使用新的语法实现分布式DDL执行了，其语法形式如下：</p>
<pre><code class="language-sql">CREATE/DROP/RENAME/ALTER TABLE  ON CLUSTER cluster_name
</code></pre>
<p>其中，cluster_name对应了配置文件中的集群名称，ClickHouse会根据集群的配置信息顺藤摸瓜，分别去各个节点执行DDL语句。</p>
<p>下面是在10.2.3节中使用的多副本示例：</p>
<pre><code class="language-sql">-- 1分片, 2副本. zk_path相同, replica_name不同。
ReplicatedMergeTree('/clickhouse/tables/01/test_1, 'ch5.nauu.com')
ReplicatedMergeTree('/clickhouse/tables/01/test_1, 'ch6.nauu.com')
</code></pre>
<p>现在将它改写为分布式DDL的形式：</p>
<pre><code class="language-sql">CREATE TABLE test_1_local ON CLUSTER shard_2(
  id UInt64
  --这里可以使用任意其他表引擎, 
)ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/test_1', '{replica}')
ORDER BY id

┌─host───────────┬─port──┬─status───┬─error──┬─num_hosts_active──┐
│ ch6.nauu.com   │ 9000  │      0   │        │               0   │
│ ch5.nauu.com   │ 9000  │      0   │        │               0   │
└────────────────┴───────┴──────────┴────────┴───────────────────┘
</code></pre>
<p>在执行了上述语句之后，ClickHouse会根据集群shard_2的配置信息，分别在CH5和CH6节点本地创建test_1_local。</p>
<p>如果要删除test_1_local，则执行下面的分布式DROP：</p>
<pre><code class="language-sql">DROP TABLE test_1_local ON CLUSTER shard_2

┌─host───────────┬─port──┬─status───┬─error──┬─num_hosts_active──┐
│ ch6.nauu.com   │ 9000  │      0   │        │               0   │
│ ch5.nauu.com   │ 9000  │      0   │        │               0   │
└────────────────┴───────┴──────────┴────────┴───────────────────┘
</code></pre>
<p>值得注意的是，在改写的CREATE语句中，用{shard}和{replica}两个动态宏变量代替了先前的硬编码方式。执行下面的语句查询系统表，能够看到当前ClickHouse节点中已存在的宏变量：</p>
<pre><code class="language-sql">--ch5节点
SELECT * FROM system.macros

┌─macro─────┬─substitution──┐
│ replica   │ ch5.nauu.com  │
│ shard     │ 01            │
└───────────┴───────────────┘

--ch6节点
SELECT * FROM remote('ch6.nauu.com:9000', 'system', 'macros', 'default')

┌─macro─────┬─substitution──┐
│ replica   │ ch6.nauu.com  │
│ shard     │ 02            │
└───────────┴───────────────┘
</code></pre>
<p>这些宏变量是通过配置文件的形式预先定义在各个节点的配置文件中的，配置文件如下所示。</p>
<p>在CH5节点的config.xml配置中预先定义了分区01的宏变量：</p>
<pre><code class="language-xml">&lt;macros&gt;
  &lt;shard&gt;01&lt;/shard&gt;
  &lt;replica&gt;ch5.nauu.com&lt;/replica&gt;
&lt;/macros&gt;
</code></pre>
<p>在CH6节点的config.xml配置中预先定义了分区02的宏变量：</p>
<pre><code class="language-xml">&lt;macros&gt;
  &lt;shard&gt;02&lt;/shard&gt;
  &lt;replica&gt;ch6.nauu.com&lt;/replica&gt;
&lt;/macros&gt;
</code></pre>
<h3 id="21-数据结构"><a class="header" href="#21-数据结构">2.1 数据结构</a></h3>
<p>与ReplicatedMergeTree类似，分布式DDL语句在执行的过程中也需要借助ZooKeeper的协同能力，以实现日志分发。</p>
<ul>
<li>
<p>1）ZooKeeper内的节点结构</p>
<p>在默认情况下，分布式DDL在ZooKeeper内使用的根路径为：</p>
<pre><code class="language-shell">/clickhouse/task_queue/ddl
</code></pre>
<p>该路径由config.xml内的distributed_ddl配置指定：</p>
<pre><code class="language-xml">&lt;distributed_ddl&gt;
  &lt;!-- Path in ZooKeeper to queue with DDL queries --&gt;
  &lt;path&gt;/clickhouse/task_queue/ddl&lt;/path&gt;
&lt;/distributed_ddl&gt;
</code></pre>
<p>在此根路径之下，还有一些其他的监听节点，其中包括/query-[seq]，其是DDL操作日志，每执行一次分布式DDL查询，在该节点下就会新增一条操作日志，以记录相应的操作指令。当各个节点监听到有新日志加入的时候，便会响应执行。DDL操作日志使用ZooKeeper的持久顺序型节点，每条指令的名称以query-为前缀，后面的序号递增，例如query-0000000000、query-0000000001等。在每条query-[seq]操作日志之下，还有两个状态节点：</p>
<ul>
<li>（1）/query-[seq]/active：用于状态监控等用途，在任务的执行过程中，在该节点下会临时保存当前集群内状态为active的节点。</li>
<li>（2）/query-[seq]/finished：用于检查任务完成情况，在任务的执行过程中，每当集群内的某个host节点执行完毕之后，便会在该节点下写入记录。例如下面的语句。</li>
</ul>
<pre><code class="language-sql">/query-000000001/finished
ch5.nauu.com:9000 : 0
ch6.nauu.com:9000 : 0
</code></pre>
<p>上述语句表示集群内的CH5和CH6两个节点已完成任务。</p>
</li>
<li>
<p>2）DDLLogEntry日志对象的数据结构</p>
<p>在/query-[seq]下记录的日志信息由DDLLogEntry承载，它拥有如下几个核心属性：</p>
<ul>
<li>
<p>（1）query记录了DDL查询的执行语句，例如：</p>
<pre><code class="language-sql">query: DROP TABLE default.test_1_local ON CLUSTER shard_2
</code></pre>
</li>
<li>
<p>（2）hosts记录了指定集群的hosts主机列表，集群由分布式DDL语句中的ON CLUSTER指定，例如：</p>
<pre><code class="language-sql">hosts: ['ch5.nauu.com:9000','ch6.nauu.com:9000']
</code></pre>
<p>在分布式DDL的执行过程中，会根据hosts列表逐个判断它们的执行状态。</p>
</li>
<li>
<p>（3）initiator记录初始化host主机的名称，hosts主机列表的取值来自于初始化host节点上的集群，例如：</p>
<pre><code class="language-sql">initiator: ch5.nauu.com:9000
</code></pre>
<p>hosts主机列表的取值来源等同于下面的查询：</p>
<pre><code class="language-sql">--从initiator节点查询cluster信息
SELECT host_name 
FROM remote('ch5.nauu.com:9000', 'system', 'clusters', 'default')  
WHERE cluster = 'shard_2'

┌─host_name───────┐
│ ch5.nauu.com    │
│ ch6.nauu.com    │
└─────────────────┘
</code></pre>
</li>
</ul>
</li>
</ul>
<h3 id="22-分布式ddl的核心执行流程"><a class="header" href="#22-分布式ddl的核心执行流程">2.2 分布式DDL的核心执行流程</a></h3>
<p>与副本协同的核心流程类似，接下来，就以之前介绍的创建<code>test_1_local</code>的过程为例，解释分布式DDL的核心执行流程。整个流程如图所示。</p>
<p><img src="clickhouse/../images/clickhouse11.jpeg" alt="DDL流程示意图" /></p>
<p>（1）<strong>推送DDL日志</strong>：首先在CH5节点执行CREATE TABLE ON CLUSTER，本着谁执行谁负责的原则，在这个案例中将会由CH5节点负责创建DDLLogEntry日志并将日志推送到ZooKeeper，同时也会由这个节点负责监控任务的执行进度。</p>
<p>（2）<strong>拉取日志并执行</strong>：CH5和CH6两个节点分别监听/ddl/query-0000000064日志的推送，于是它们分别拉取日志到本地。首先，它们会判断各自的host是否被包含在DDLLog-Entry的hosts列表中。如果包含在内，则进入执行流程，执行完毕后将状态写入finished节点；如果不包含，则忽略这次日志的推送。</p>
<p>（3）<strong>确认执行进度</strong>：在步骤1执行DDL语句之后，客户端会阻塞等待180秒，以期望所有host执行完毕。如果等待时间大于180秒，则会转入后台线程继续等待（等待时间由distributed_ddl_task_timeout参数指定，默认为180秒）。</p>
<div style="break-before: page; page-break-before: always;"></div><ul>
<li><a href="clickhouse/distribute_principle.html#distributed%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90">Distributed原理解析</a>
<ul>
<li><a href="clickhouse/distribute_principle.html#1-%E5%AE%9A%E4%B9%89%E5%BD%A2%E5%BC%8F">1. 定义形式</a></li>
<li><a href="clickhouse/distribute_principle.html#2-%E6%9F%A5%E8%AF%A2%E7%9A%84%E5%88%86%E7%B1%BB">2. 查询的分类</a></li>
<li><a href="clickhouse/distribute_principle.html#3-%E5%88%86%E7%89%87%E8%A7%84%E5%88%99">3. 分片规则</a>
<ul>
<li><a href="clickhouse/distribute_principle.html#31-%E5%88%86%E7%89%87%E6%9D%83%E9%87%8D">3.1 分片权重</a></li>
<li><a href="clickhouse/distribute_principle.html#32-slot%E6%A7%BD">3.2 slot（槽）</a></li>
<li><a href="clickhouse/distribute_principle.html#33-%E9%80%89%E6%8B%A9%E5%87%BD%E6%95%B0">3.3 选择函数</a></li>
</ul>
</li>
<li><a href="clickhouse/distribute_principle.html#4-%E5%88%86%E5%B8%83%E5%BC%8F%E5%86%99%E5%85%A5%E7%9A%84%E6%A0%B8%E5%BF%83%E6%B5%81%E7%A8%8B">4. 分布式写入的核心流程</a>
<ul>
<li><a href="clickhouse/distribute_principle.html#41-%E5%B0%86%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5%E5%88%86%E7%89%87%E7%9A%84%E6%A0%B8%E5%BF%83%E6%B5%81%E7%A8%8B">4.1 将数据写入分片的核心流程</a></li>
<li><a href="clickhouse/distribute_principle.html#42-%E5%89%AF%E6%9C%AC%E5%A4%8D%E5%88%B6%E6%95%B0%E6%8D%AE%E7%9A%84%E6%A0%B8%E5%BF%83%E6%B5%81%E7%A8%8B">4.2 副本复制数据的核心流程</a></li>
</ul>
</li>
<li><a href="clickhouse/distribute_principle.html#5-%E5%88%86%E5%B8%83%E5%BC%8F%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%A0%B8%E5%BF%83%E6%B5%81%E7%A8%8B">5. 分布式查询的核心流程</a>
<ul>
<li><a href="clickhouse/distribute_principle.html#51-%E5%A4%9A%E5%89%AF%E6%9C%AC%E7%9A%84%E8%B7%AF%E7%94%B1%E8%A7%84%E5%88%99">5.1 多副本的路由规则</a></li>
<li><a href="clickhouse/distribute_principle.html#52-%E5%A4%9A%E5%88%86%E7%89%87%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%A0%B8%E5%BF%83%E6%B5%81%E7%A8%8B">5.2 多分片查询的核心流程</a></li>
<li><a href="clickhouse/distribute_principle.html#53-%E4%BD%BF%E7%94%A8global%E4%BC%98%E5%8C%96%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%90%E6%9F%A5%E8%AF%A2">5.3 使用Global优化分布式子查询</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="distributed原理解析"><a class="header" href="#distributed原理解析">Distributed原理解析</a></h1>
<p>Distributed表引擎是分布式表的代名词，它自身不存储任何数据，而是作为数据分片的透明代理，能够自动路由数据至集群中的各个节点，所以Distributed表引擎需要和其他数据表引擎一起协同工作. 如图所示：</p>
<p><img src="clickhouse/../images/clickhouse12.jpeg" alt="关系示意图" /></p>
<p>从实体表层面来看，一张分片表由两部分组成：</p>
<ul>
<li>
<p><strong>本地表</strong>：通常以<code>_local</code>为后缀进行命名。本地表是承接数据的载体，可以使用非<code>Distributed</code>的任意表引擎，一张本地表对应了一个数据分片。</p>
</li>
<li>
<p><strong>分布式表</strong>：通常以<code>_all</code>为后缀进行命名。分布式表只能使用<code>Distributed</code>表引擎，它与本地表形成一对多的映射关系，日后将通过分布式表代理操作多张本地表。</p>
</li>
</ul>
<p>对于分布式表与本地表之间表结构的一致性检查，Distributed表引擎采用了读时检查的机制，这意味着如果它们的表结构不兼容，只有在查询时才会抛出错误，而在创建表时并不会进行检查。不同ClickHouse节点上的本地表之间，使用不同的表引擎也是可行的，但是通常不建议这么做，保持它们的结构一致，有利于后期的维护并避免造成不可预计的错误。</p>
<h2 id="1-定义形式"><a class="header" href="#1-定义形式">1. 定义形式</a></h2>
<p>Distributed表引擎的定义形式如下所示：</p>
<pre><code class="language-sql">ENGINE = Distributed(cluster, database, table [,sharding_key])
</code></pre>
<p>其中，各个参数的含义分别如下：</p>
<ul>
<li><strong>cluster</strong>：集群名称，与集群配置中的自定义名称相对应。在对分布式表执行写入和查询的过程中，它会使用集群的配置信息来找到相应的host节点。</li>
<li><strong>database和table</strong>：分别对应数据库和表的名称，分布式表使用这组配置映射到本地表。</li>
<li><strong>sharding_key</strong>：分片键，选填参数。在数据写入的过程中，分布式表会依据分片键的规则，将数据分布到各个host节点的本地表。</li>
</ul>
<p>现在用示例说明Distributed表的声明方式，建表语句如下所示：</p>
<pre><code class="language-sql">CREATE TABLE test_shard_2_all ON CLUSTER sharding_simple (
  id UInt64
)ENGINE = Distributed(sharding_simple, default, test_shard_2_local,rand())
</code></pre>
<p>上述表引擎参数的语义可以理解为，代理的本地表为default.test_shard_2_local，它们分布在集群sharding_simple的各个shard，在数据写入时会根据rand()随机函数的取值决定数据写入哪个分片。值得注意的是，此时此刻本地表还未创建，所以从这里也能看出，Distributed表运用的是读时检查的机制，对创建分布式表和本地表的顺序并没有强制要求。同样值得注意的是，在上面的语句中使用了ON CLUSTER分布式DDL，这意味着在集群的每个分片节点上，都会创建一张Distributed表，如此一来便可以从其中任意一端发起对所有分片的读、写请求，如图所示。</p>
<p><img src="clickhouse/../images/clickhouse13.jpeg" alt="关系拓扑图" /></p>
<p>接着需要创建本地表，一张本地表代表着一个数据分片。这里同样可以利用先前已经配置好的集群配置，使用分布式DDL语句迅速的在各个节点创建相应的本地表：</p>
<pre><code class="language-sql">CREATE TABLE test_shard_2_local ON CLUSTER sharding_simple (
    id UInt64
) ENGINE = MergeTree()
ORDER BY id
PARTITION BY id
</code></pre>
<p>至此，拥有两个数据分片的分布式表test_shard_2就建好了。</p>
<h2 id="2-查询的分类"><a class="header" href="#2-查询的分类">2. 查询的分类</a></h2>
<p>Distributed表的查询操作可以分为如下几类：</p>
<ul>
<li>
<p><strong>会作用于本地表的查询</strong>：对于<code>INSERT</code>和<code>SELECT</code>查询，<code>Distributed</code>将会以分布式的方式作用于<code>local本地表</code>。而对于这些查询的具体执行逻辑，将会在后续小节介绍。</p>
</li>
<li>
<p><strong>只会影响Distributed自身，不会作用于本地表的查询</strong>：<code>Distributed</code>支持部分元数据操作，包括<code>CREATE</code>、<code>DROP</code>、<code>RENAME</code>和<code>ALTER</code>，其中<code>ALTER</code>并不包括分区的操作（<code>ATTACH PARTITION</code>、<code>REPLACE PARTITION</code>等）。这些查询只会修改<code>Distributed</code>表自身，并不会修改<code>local</code>本地表。例如要彻底删除一张分布式表，则需要分别删除分布式表和本地表，示例如下。</p>
<pre><code class="language-sql">--删除分布式表
DROP TABLE test_shard_2_all ON CLUSTER sharding_simple

--删除本地表
DROP TABLE test_shard_2_local ON CLUSTER sharding_simple
</code></pre>
</li>
<li>
<p><strong>不支持的查询</strong>：Distributed表不支持任何MUTATION类型的操作，包括<code>ALTER DELETE</code>和<code>ALTER UPDATE</code>。</p>
</li>
</ul>
<h2 id="3-分片规则"><a class="header" href="#3-分片规则">3. 分片规则</a></h2>
<p>关于分片的规则这里将做进一步的展开说明。分片键要求返回一个整型类型的取值，包括Int系列和UInt系列。例如分片键可以是一个具体的整型列字段：</p>
<pre><code class="language-sql">-- 按照用户id的余数划分
Distributed(cluster, database, table ,userid)
</code></pre>
<p>也可以是一个返回整型的表达式：</p>
<pre><code class="language-sql">--按照随机数划分
Distributed(cluster, database, table ,rand())

--按照用户id的散列值划分
Distributed(cluster, database, table , intHash64(userid))
</code></pre>
<p>如果不声明分片键，那么分布式表只能包含一个分片，这意味着只能映射一张本地表，否则，在写入数据时将会得到如下异常：</p>
<pre><code class="language-log">Method write is not supported by storage Distributed with more than one shard and no sharding key provided
</code></pre>
<p>如果一张分布式表只包含一个分片，那就意味着其失去了使用的意义了。所以虽然分片键是选填参数，但是通常都会按照业务规则进行设置。
那么数据具体是如何被划分的呢？想要讲清楚这部分逻辑，首先需要明确几个概念。</p>
<h3 id="31-分片权重"><a class="header" href="#31-分片权重">3.1 分片权重</a></h3>
<p>在集群的配置中，有一项weight（分片权重）的设置：</p>
<pre><code class="language-xml">&lt;sharding_simple&gt;&lt;!-- 自定义集群名称 --&gt;
  &lt;shard&gt;&lt;!-- 分片 --&gt;
    &lt;weight&gt;10&lt;/weight&gt;&lt;!-- 分片权重 --&gt;
    ……
  &lt;/shard&gt;
  &lt;shard&gt;
    &lt;weight&gt;20&lt;/weight&gt;
    ……
  &lt;/shard&gt;
  …
</code></pre>
<p>weight默认为1，虽然可以将它设置成任意整数，但官方建议应该尽可能设置成较小的值。分片权重会影响数据在分片中的倾斜程度，一个分片权重值越大，那么它被写入的数据就会越多。</p>
<h3 id="32-slot槽"><a class="header" href="#32-slot槽">3.2 slot（槽）</a></h3>
<p>slot可以理解成许多小的水槽，如果把数据比作是水的话，那么数据之水会顺着这些水槽流进每个数据分片。slot的数量等于所有分片的权重之和，假设集群sharding_simple有两个Shard分片，第一个分片的weight为10，第二个分片的weight为20，那么slot的数量则等于30。slot按照权重元素的取值区间，与对应的分片形成映射关系。在这个示例中，如果slot值落在[0,10)区间，则对应第一个分片；如果slot值落在[10,20]区间，则对应第二个分片。</p>
<h3 id="33-选择函数"><a class="header" href="#33-选择函数">3.3 选择函数</a></h3>
<p>选择函数用于判断一行待写入的数据应该被写入哪个分片，整个判断过程大致分成两个步骤：</p>
<p>（1）它会找出slot的取值，其计算公式如下：</p>
<pre><code class="language-python">slot = shard_value % sum_weight
</code></pre>
<p>其中，shard_value是分片键的取值；sum_weight是所有分片的权重之和；slot等于shard_value和sum_weight的余数。假设某一行数据的shard_value是10，sum_weight是30（两个分片，第一个分片权重为10，第二个分片权重为20），那么slot值等于10（10%30=10）。</p>
<p>（2）基于slot值找到对应的数据分片。当slot值等于10的时候，它属于[10,20)区间，所以这行数据会对应到第二个Shard分片。
整个过程的示意如图所示。</p>
<p><img src="clickhouse/../images/clickhouse14.jpeg" alt="逻辑示意图" /></p>
<h2 id="4-分布式写入的核心流程"><a class="header" href="#4-分布式写入的核心流程">4. 分布式写入的核心流程</a></h2>
<p>在向集群内的分片写入数据时，通常有两种思路：一种是借助外部计算系统，事先将数据均匀分片，再借由计算系统直接将数据写入ClickHouse集群的各个本地表，如图所示。</p>
<p><img src="clickhouse/../images/clickhouse15.jpeg" alt="逻辑示意图" /></p>
<p>上述这种方案通常拥有更好的写入性能，因为分片数据是被并行点对点写入的。但是这种方案的实现主要依赖于外部系统，而不在于ClickHouse自身，所以这里主要会介绍第二种思路。</p>
<p>第二种思路是通过Distributed表引擎代理写入分片数据的，接下来开始介绍数据写入的核心流程。
为了便于理解整个过程，这里会将分片写入、副本复制拆分成两个部分进行讲解。在讲解过程中，会使用两个特殊的集群分别进行演示：第一个集群拥有2个分片和0个副本，通过这个示例向大家讲解分片写入的核心流程；第二个集群拥有1个分片和1个副本，通过这个示例向大家讲解副本复制的核心流程。</p>
<h3 id="41-将数据写入分片的核心流程"><a class="header" href="#41-将数据写入分片的核心流程">4.1 将数据写入分片的核心流程</a></h3>
<p>在对Distributed表执行INSERT查询的时候，会进入数据写入分片的执行逻辑，它的核心流程如图所示。</p>
<p>![写入多个分片]](../images/clickhouse16.jpeg)</p>
<p>在这个流程中，继续使用集群sharding_simple的示例，该集群由2个分片和0个副本组成。整个流程从上至下按照时间顺序进行，其大致分成5个步骤。现在根据图片所示编号讲解整个过程。</p>
<ul>
<li>
<p>1）在第一个分片节点写入本地分片数据</p>
<p>首先在CH5节点，对分布式表test_shard_2_all执行INSERT查询，尝试写入10、30、200和55四行数据。执行之后分布式表主要会做两件事情：第一，根据分片规则划分数据，在这个示例中，30会归至分片1，而10、200和55则会归至分片2；第二，将属于当前分片的数据直接写入本地表test_shard_2_local。</p>
</li>
<li>
<p>2）第一个分片建立远端连接，准备发送远端分片数据</p>
<p>将归至远端分片的数据以分区为单位，分别写入test_shard_2_all存储目录下的临时bin文件，数据文件的命名规则如下：</p>
<pre><code class="language-sql">/database@host:port/[increase_num].bin
</code></pre>
<p>由于在这个示例中只有一个远端分片CH6，所以它的临时数据文件如下所示：</p>
<pre><code class="language-sql">/test_shard_2_all/default@ch6.nauu.com:9000/1.bin
</code></pre>
<p>10、200和55三行数据会被写入上述这个临时数据文件。接着，会尝试与远端CH6分片建立连接：</p>
<pre><code class="language-sql">Connection (ch6.nauu.com:9000): Connected to ClickHouse server
</code></pre>
</li>
<li>
<p>3）第一个分片向远端分片发送数据</p>
<p>此时，会有另一组监听任务负责监听/test_shard_2_all目录下的文件变化，这些任务负责将目录数据发送至远端分片：</p>
<pre><code class="language-sql">test_shard_2_all.Distributed.DirectoryMonitor:
Started processing /test_shard_2_all/default@ch6.nauu.com:9000/1.bin
</code></pre>
<p>其中，每份目录将会由独立的线程负责发送，数据在传输之前会被压缩。</p>
</li>
<li>
<p>4）第二个分片接收数据并写入本地</p>
<p>CH6分片节点确认建立与CH5的连接：</p>
<pre><code class="language-sql">TCPHandlerFactory: TCP Request. Address: CH5:45912
TCPHandler: Connected ClickHouse server
</code></pre>
<p>在接收到来自CH5发送的数据后，将它们写入本地表：</p>
<pre><code class="language-sql">executeQuery: (from CH5) INSERT INTO default.test_shard_2_local

--第一个分区
Reserving 1.00 MiB on disk 'default'
Renaming temporary part tmp_insert_10_1_1_0 to 10_1_1_0.

--第二个分区
Reserving 1.00 MiB on disk 'default'
Renaming temporary part tmp_insert_200_2_2_0 to 200_2_2_0.

--第三个分区
Reserving 1.00 MiB on disk 'default'
Renaming temporary part tmp_insert_55_3_3_0 to 55_3_3_0.
</code></pre>
</li>
<li>
<p>5）由第一个分片确认完成写入</p>
<p>最后，还是由CH5分片确认所有的数据发送完毕：</p>
<pre><code class="language-sql">Finished processing /test_shard_2_all/default@ch6.nauu.com:9000/1.bin
</code></pre>
<p>至此，整个流程结束。</p>
</li>
</ul>
<p>可以看到，在整个过程中，Distributed表负责所有分片的写入工作。本着谁执行谁负责的原则，在这个示例中，由CH5节点的分布式表负责切分数据，并向所有其他分片节点发送数据。</p>
<p>在由Distributed表负责向远端分片发送数据时，有异步写和同步写两种模式：如果是异步写，则在Distributed表写完本地分片之后，INSERT查询就会返回成功写入的信息；如果是同步写，则在执行INSERT查询之后，会等待所有分片完成写入。使用何种模式由insert_distributed_sync参数控制，默认为false，即异步写。如果将其设置为true，则可以一进步通过insert_distributed_timeout参数控制同步等待的超时时间。</p>
<h3 id="42-副本复制数据的核心流程"><a class="header" href="#42-副本复制数据的核心流程">4.2 副本复制数据的核心流程</a></h3>
<p>如果在集群的配置中包含了副本，那么除了刚才的分片写入流程之外，还会触发副本数据的复制流程。数据在多个副本之间，有两种复制实现方式：一种是继续借助Distributed表引擎，由它将数据写入副本；另一种则是借助ReplicatedMergeTree表引擎实现副本数据的分发。两种方式的区别如图所示。</p>
<p><img src="clickhouse/../images/clickhouse17.jpeg" alt="对比示意图" /></p>
<ul>
<li>
<p>1）通过Distributed复制数据</p>
<p>在这种实现方式下，即使本地表不使用ReplicatedMergeTree表引擎，也能实现数据副本的功能。Distributed会同时负责分片和副本的数据写入工作，而副本数据的写入流程与分片逻辑相同。现在用一个简单示例说明。首先让我们再重温一下集群sharding_simple_1的配置，它的配置如下：</p>
<pre><code class="language-xml">&lt;!-- 1个分片 1个副本--&gt;
&lt;sharding_simple_1&gt;
  &lt;shard&gt;
    &lt;replica&gt;
      &lt;host&gt;ch5.nauu.com&lt;/host&gt;
      &lt;port&gt;9000&lt;/port&gt;
    &lt;/replica&gt;
    &lt;replica&gt;
      &lt;host&gt;ch6.nauu.com&lt;/host&gt;
      &lt;port&gt;9000&lt;/port&gt;
    &lt;/replica&gt;
  &lt;/shard&gt;
&lt;/sharding_simple_1&gt;
</code></pre>
<p>现在，尝试在这个集群内创建数据表，首先创建本地表：</p>
<pre><code class="language-sql">CREATE TABLE test_sharding_simple1_local ON CLUSTER sharding_simple_1(
  id UInt64
)ENGINE = MergeTree()
ORDER BY id
</code></pre>
<p>接着创建Distributed分布式表：</p>
<pre><code class="language-sql">CREATE TABLE test_sharding_simple1_all
(
  id UInt64
)ENGINE = Distributed(sharding_simple_1, default, test_sharding_simple1_local,rand())
</code></pre>
<p>之后，向Distributed表写入数据，它会负责将数据写入集群内的每个replica。</p>
<p>在这种实现方案下，Distributed节点需要同时负责分片和副本的数据写入工作，它很有可能会成为写入的单点瓶颈，所以就有了接下来将要说明的第二种方案。</p>
</li>
<li>
<p>2）通过ReplicatedMergeTree复制数据</p>
<p>如果在集群的shard配置中增加internal_replication参数并将其设置为true（默认为false），那么Distributed表在该shard中只会选择一个合适的replica并对其写入数据。此时，如果使用ReplicatedMergeTree作为本地表的引擎，则在该shard内，多个replica副本之间的数据复制会交由ReplicatedMergeTree自己处理，不再由Distributed负责，从而为其减负。</p>
<p>在shard中选择replica的算法大致如下：首选，在ClickHouse的服务节点中，拥有一个全局计数器errors_count，当服务出现任何异常时，该计数累积加1；接着，当一个shard内拥有多个replica时，选择errors_count错误最少的那个。</p>
<p>加入internal_replication配置后示例如下所示：</p>
<pre><code class="language-xml">&lt;shard&gt;
  &lt;!-- 由ReplicatedMergeTree复制表自己负责数据分发 --&gt;
  &lt;internal_replication&gt;true&lt;/internal_replication&gt;
  &lt;replica&gt;
      &lt;host&gt;ch5.nauu.com&lt;/host&gt;
      &lt;port&gt;9000&lt;/port&gt;
  &lt;/replica&gt;
  &lt;replica&gt;
      &lt;host&gt;ch6.nauu.com&lt;/host&gt;
      &lt;port&gt;9000&lt;/port&gt;
  &lt;/replica&gt;
&lt;/shard&gt;
</code></pre>
<p>关于Distributed表引擎如何将数据写入分片，请参见<a href="clickhouse/(#4-%E5%88%86%E5%B8%83%E5%BC%8F%E5%86%99%E5%85%A5%E7%9A%84%E6%A0%B8%E5%BF%83%E6%B5%81%E7%A8%8B)">第 4 节</a>；而关于Replicated-MergeTree表引擎如何复制分发数据，请参见<a href="clickhouse/distribute_principle.html#3-%E5%88%86%E7%89%87%E8%A7%84%E5%88%99">第3节</a>。</p>
</li>
</ul>
<h2 id="5-分布式查询的核心流程"><a class="header" href="#5-分布式查询的核心流程">5. 分布式查询的核心流程</a></h2>
<p>与数据写入有所不同，在面向集群查询数据的时候，只能通过Distributed表引擎实现。当Distributed表接收到SELECT查询的时候，它会依次查询每个分片的数据，再合并汇总返回。接下来将对数据查询时的重点逻辑进行介绍。</p>
<h3 id="51-多副本的路由规则"><a class="header" href="#51-多副本的路由规则">5.1 多副本的路由规则</a></h3>
<p>在查询数据的时候，如果集群中的一个shard，拥有多个replica，那么Distributed表引擎需要面临副本选择的问题。它会使用负载均衡算法从众多replica中选择一个，而具体使用何种负载均衡算法，则由load_balancing参数控制：</p>
<pre><code class="language-sql">load_balancing = random/nearest_hostname/in_order/first_or_random
</code></pre>
<p>有如下四种负载均衡算法：</p>
<ul>
<li>
<p>1）random</p>
<p>random是默认的负载均衡算法，正如前文所述，在ClickHouse的服务节点中，拥有一个全局计数器errors_count，当服务发生任何异常时，该计数累积加1。而random算法会选择errors_count错误数量最少的replica，如果多个replica的errors_count计数相同，则在它们之中随机选择一个。</p>
</li>
<li>
<p>2）nearest_hostname</p>
<p>nearest_hostname可以看作random算法的变种，首先它会选择errors_count错误数量最少的replica，如果多个replica的errors_count计数相同，则选择集群配置中host名称与当前host最相似的一个。而相似的规则是以当前host名称为基准按字节逐位比较，找出不同字节数最少的一个，例如CH5-1-1和CH5-1-2.nauu.com有一个字节不同：</p>
<pre><code class="language-sql">CH5-1-1
CH5-1-2.nauu.com
</code></pre>
<p>而CH5-1-1和CH5-2-2则有两个字节不同：</p>
<pre><code class="language-sql">CH5-1-1
CH5-2-2
</code></pre>
</li>
<li>
<p>3）in_order</p>
<p>in_order同样可以看作random算法的变种，首先它会选择errors_count错误数量最少的replica，如果多个replica的errors_count计数相同，则按照集群配置中replica的定义顺序逐个选择。</p>
</li>
<li>
<p>4）first_or_random</p>
<p>first_or_random可以看作in_order算法的变种，首先它会选择errors_count错误数量最少的replica，如果多个replica的errors_count计数相同，它首先会选择集群配置中第一个定义的replica，如果该replica不可用，则进一步随机选择一个其他的replica。</p>
</li>
</ul>
<h3 id="52-多分片查询的核心流程"><a class="header" href="#52-多分片查询的核心流程">5.2 多分片查询的核心流程</a></h3>
<p>分布式查询与分布式写入类似，同样本着谁执行谁负责的原则，它会由接收SELECT查询的Distributed表，并负责串联起整个过程。首先它会将针对分布式表的SQL语句，按照分片数量将查询拆分成若干个针对本地表的子查询，然后向各个分片发起查询，最后再汇总各个分片的返回结果。如果对分布式表按如下方式发起查询：</p>
<pre><code class="language-sql">SELECT * FROM distributed_table
</code></pre>
<p>那么它会将其转为如下形式之后，再发送到远端分片节点来执行：</p>
<pre><code class="language-sql">SELECT * FROM local_table
</code></pre>
<p>以sharding_simple集群的test_shard_2_all为例，假设在CH5节点对分布式表发起查询：</p>
<pre><code class="language-sql">SELECT COUNT(*) FROM test_shard_2_all
</code></pre>
<p>那么，Distributed表引擎会将查询计划转换为多个分片的UNION联合查询，如图所示。</p>
<p><img src="clickhouse/../images/clickhouse18.jpeg" alt="执行计划" /></p>
<p>整个执行计划从下至上大致分成两个步骤：</p>
<ul>
<li>
<p>1）查询各个分片数据</p>
<p>在图所示执行计划中，One和Remote步骤是并行执行的，它们分别负责了本地和远端分片的查询动作。其中，在One步骤会将SQL转换成对本地表的查询：</p>
<pre><code class="language-sql">SELECT COUNT() FROM default.test_shard_2_local
</code></pre>
<p>而在Remote步骤中，会建立与CH6节点的连接，并向其发起远程查询：</p>
<pre><code class="language-sql">Connection (ch6.nauu.com:9000): Connecting. Database: …
</code></pre>
<p>CH6节点在接收到来自CH5的查询请求后，开始在本地执行。同样，SQL会转换成对本地表的查询：</p>
<pre><code class="language-sql">executeQuery: (from CH5:45992, initial_query_id: 4831b93b-5ae6-4b18-bac9-e10cc9614353) WITH toUInt32(2) AS _shard_num 
SELECT COUNT() FROM default.test_shard_2_local
</code></pre>
</li>
<li>
<p>2）合并返回结果</p>
<p>多个分片数据均查询返回后，按如下方法在CH5节点将它们合并：</p>
<pre><code class="language-sql">Read 2 blocks of partially aggregated data, total 2 rows.
Aggregator: Converting aggregated data to blocks
……
</code></pre>
</li>
</ul>
<h3 id="53-使用global优化分布式子查询"><a class="header" href="#53-使用global优化分布式子查询">5.3 使用Global优化分布式子查询</a></h3>
<p>如果在分布式查询中使用子查询，可能会面临两难的局面。下面来看一个示例。假设有这样一张分布式表test_query_all，它拥有两个分片，而表内的数据如下所示：</p>
<pre><code class="language-sql">-- CH5节点test_query_local
┌─id──┬─repo──┐
│  1  │  100  │
│  2  │  100  │
│  3  │  100  │
└─────┴───────┘

-- CH6节点test_query_local
┌─id──┬─repo──┐
│  3  │  200  │
│  4  │  200  │
└─────┴───────┘
</code></pre>
<p>其中，id代表用户的编号，repo代表仓库的编号。如果现在有一项查询需求，要求找到同时拥有两个仓库的用户，应该如何实现？对于这类交集查询的需求，可以使用IN子查询，此时你会面临两难的选择：IN查询的子句应该使用本地表还是分布式表？（使用JOIN面临的情形与IN类似）。</p>
<ul>
<li>
<p>1）使用本地表的问题</p>
<p>如果在IN查询中使用本地表，例如下面的语句：</p>
<pre><code class="language-sql">SELECT uniq(id) FROM test_query_all WHERE repo = 100 
AND id IN (SELECT id FROM test_query_local WHERE repo = 200)

┌─uniq(id)───┐
│        0   │
└────────────┘
</code></pre>
<p>那么你会发现返回的结果是错误的。这是为什么呢？这是因为分布式表在接收到查询之后，会将上述SQL替换成本地表的形式，再发送到每个分片进行执行：</p>
<pre><code class="language-sql">SELECT uniq(id) FROM test_query_local WHERE repo = 100 
AND id IN (SELECT id FROM test_query_local WHERE repo = 200)
</code></pre>
<p>注意，IN查询的子句使用的是本地表：</p>
<pre><code class="language-sql">SELECT id FROM test_query_local WHERE repo = 200
</code></pre>
<p>由于在单个分片上只保存了部分的数据，所以该SQL语句没有匹配到任何数据，如图所示。</p>
<p><img src="clickhouse/../images/clickhouse19.jpeg" alt="执行逻辑" /></p>
<p>从上图中可以看到，单独在分片1或分片2内均无法找到repo同时等于100和200的数据。</p>
</li>
<li>
<p>2）使用分布式表的问题</p>
<p>为了解决返回结果错误的问题，现在尝试在IN查询子句中使用分布式表：</p>
<pre><code class="language-sql">SELECT uniq(id) 
FROM test_query_all 
WHERE repo = 100 AND id IN (
    SELECT id 
    FROM test_query_all 
    WHERE repo = 200
)

┌─uniq(id)───┐
│        1   │
└────────────┘
</code></pre>
<p>这次返回了正确的查询结果。那是否意味着使用这种方案就万无一失了呢？通过进一步观察执行日志会发现，情况并非如此，该查询的请求被放大了两倍。</p>
<p>这是由于在IN查询子句中，同样也使用了分布式表查询：</p>
<pre><code class="language-sql">SELECT id FROM test_query_all WHERE repo = 200
</code></pre>
<p>所以在CH6节点接收到这条SQL之后，它将再次向其他分片发起远程查询，如图所示。</p>
<p><img src="clickhouse/../images/clickhouse20.jpeg" alt="放大原因示意图" /></p>
<p>因此可以得出结论，在IN查询子句使用分布式表的时候，查询请求会被放大N的平方倍，其中N等于集群内分片节点的数量，假如集群内有10个分片节点，则在一次查询的过程中，会最终导致100次的查询请求，这显然是不可接受的。</p>
</li>
<li>
<p>3）使用GLOBAL优化查询</p>
<p>为了解决查询放大的问题，可以使用GLOBAL IN或JOIN进行优化。现在对刚才的SQL进行改造，为其增加GLOBAL修饰符：</p>
<pre><code class="language-sql">SELECT uniq(id) FROM test_query_all WHERE repo = 100 
AND id GLOBAL IN (SELECT id FROM test_query_all WHERE repo = 200)
</code></pre>
<p>再次分析查询的核心过程，如图所示。</p>
<p><img src="clickhouse/../images/clickhouse21.jpeg" alt="流程示意图" /></p>
<p>整个过程由上至下大致分成5个步骤：</p>
<ul>
<li>（1）将IN子句单独提出，发起了一次分布式查询。</li>
<li>（2）将分布式表转local本地表后，分别在本地和远端分片执行查询。</li>
<li>（3）将IN子句查询的结果进行汇总，并放入一张临时的内存表进行保存。</li>
<li>（4）将内存表发送到远端分片节点。</li>
<li>（5）将分布式表转为本地表后，开始执行完整的SQL语句，IN子句直接使用临时内存表的数据。</li>
</ul>
<p>至此，整个核心流程结束。可以看到，在使用<code>GLOBAL</code>修饰符之后，ClickHouse使用内存表临时保存了IN子句查询到的数据，并将其发送到远端分片节点，以此到达了数据共享的目的，从而避免了查询放大的问题。</p>
<p>由于数据会在网络间分发，所以需要特别注意临时表的大小，<code>IN</code>或者<code>JOIN子句</code>返回的数据不宜过大。如果表内存在重复数据，也可以事先在<code>子句SQL</code>中增加<code>DISTINCT</code>以实现去重。</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="管理与运维"><a class="header" href="#管理与运维">管理与运维</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="用户配置"><a class="header" href="#用户配置">用户配置</a></h1>
<p><code>user.xml</code>配置文件默认位于<code>/etc/clickhouse-server</code>路径下，ClickHouse使用它来定义用户相关的配置项，包括系统参数的设定、用户的定义、权限以及熔断机制等。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="用户profile"><a class="header" href="#用户profile">用户profile</a></h1>
<p>用户<code>profile</code>的作用类似于用户角色。可以预先在<code>user.xml</code>中为ClickHouse定义多组<code>profile</code>，并为每组<code>profile</code>定义不同的配置项，以实现配置的复用。以下面的配置为例：</p>
<pre><code class="language-xml">&lt;yandex&gt;
  &lt;profiles&gt;&lt;!-- 配置profile --&gt;

    &lt;default&gt; &lt;!-- 自定义名称, 默认角色--&gt;
      &lt;max_memory_usage&gt;10000000000&lt;/max_memory_usage&gt;
      &lt;use_uncompressed_cache&gt;0&lt;/use_uncompressed_cache&gt;
    &lt;/default&gt;

    &lt;test1&gt; &lt;!-- 自定义名称, 默认角色--&gt;
      &lt;allow_experimental_live_view&gt;1&lt;/allow_experimental_live_view&gt;
      &lt;distributed_product_mode&gt;allow&lt;/distributed_product_mode&gt;
    &lt;/test1&gt;
  &lt;/profiles&gt;
  ……
</code></pre>
<p>在这组配置中，预先定义了<code>default</code>和<code>test1</code>两组<code>profile</code>。引用相应的<code>profile</code>名称，便会获得相应的配置。我们可以在CLI中直接切换到想要的<code>profile</code>：</p>
<pre><code class="language-shell">SET profile = test1
</code></pre>
<p>或是在定义用户的时候直接引用: 参考<a href="clickhouse/../clickhouse/manage_user_define.html">用户定义</a></p>
<p>在所有的<code>profile</code>配置中，名称为<code>default</code>的<code>profile</code>将作为默认的配置被加载，所以它必须存在。如果缺失了名为<code>default</code>的<code>profile</code>，在登录时将会出现如下错误提示：</p>
<pre><code class="language-shell">DB::Exception: There is no profile 'default' in configuration file..
</code></pre>
<p>profile配置支持继承，实现继承的方式是在定义中引用其他的profile名称，例如下面的例子所示：</p>
<pre><code class="language-xml">&lt;normal_inherit&gt; &lt;!-- 只有read查询权限--&gt;
  &lt;profile&gt;test1&lt;/profile&gt;
  &lt;profile&gt;test2&lt;/profile&gt;
  &lt;distributed_product_mode&gt;deny&lt;/distributed_product_mode&gt;
&lt;/normal_inherit&gt;
</code></pre>
<p>这个名为<code>normal_inherit</code>的<code>profile</code>继承了<code>test1</code>和<code>test2</code>的所有配置项，并且使用新的参数值覆盖了<code>test1</code>中原有的<code>distributed_product_mode</code>配置项。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="用户约束"><a class="header" href="#用户约束">用户约束</a></h1>
<p><code>constraints</code>标签可以设置一组约束条件，以保障<code>profile</code>内的参数值不会被随意修改。约束条件有如下三种规则：</p>
<ul>
<li>
<p><strong>Min</strong>：最小值约束，在设置相应参数的时候，取值不能小于该阈值。</p>
</li>
<li>
<p><strong>Max</strong>：最大值约束，在设置相应参数的时候，取值不能大于该阈值。</p>
</li>
<li>
<p><strong>Readonly</strong>：只读约束，该参数值不允许被修改。</p>
</li>
</ul>
<p>现在举例说明：</p>
<pre><code class="language-xml">&lt;profiles&gt;&lt;!-- 配置profiles --&gt;

  &lt;default&gt; &lt;!-- 自定义名称, 默认角色--&gt;
    &lt;max_memory_usage&gt;10000000000&lt;/max_memory_usage&gt;
    &lt;distributed_product_mode&gt;allow&lt;/distributed_product_mode&gt;

    &lt;constraints&gt;&lt;!-- 配置约束--&gt;
      &lt;max_memory_usage&gt;
        &lt;min&gt;5000000000&lt;/min&gt;
        &lt;max&gt;20000000000&lt;/max&gt;
      &lt;/max_memory_usage&gt;
      &lt;distributed_product_mode&gt;
        &lt;readonly/&gt;
      &lt;/distributed_product_mode&gt;
    &lt;/constraints&gt;

  &lt;/default&gt;
</code></pre>
<p>从上面的配置定义中可以看出，在<code>default</code>默认的<code>profile</code>内，给两组参数设置了约束。其中，为<code>max_memory_usage</code>设置了<code>min</code>和<code>max</code>阈值；而为<code>distributed_product_mode</code>设置了<code>只读约束</code>。现在尝试修改<code>max_memory_usage</code>参数，将它改为<code>50</code>：</p>
<pre><code class="language-sql">SET max_memory_usage = 50
DB::Exception: Setting max_memory_usage shouldn't be less than 5000000000.
</code></pre>
<p>可以看到，最小值约束阻止了这次修改。</p>
<p>接着继续修改<code>distributed_product_mode</code>参数的取值：</p>
<pre><code class="language-sql">SET distributed_product_mode = 'deny'
DB::Exception: Setting distributed_product_mode should not be changed.
</code></pre>
<p>同样，配置约束成功阻止了预期外的修改。</p>
<p>还有一点需要特别明确，在<code>default</code>中默认定义的<code>constraints</code>约束，将作为默认的全局约束，自动被其他<code>profile</code>继承。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="用户定义"><a class="header" href="#用户定义">用户定义</a></h1>
<p>使用users标签可以配置自定义用户。如果打开<code>user.xml</code>配置文件，会发现已经默认配置了<code>default</code>用户，在此之前的所有示例中，一直使用的正是这个用户。</p>
<p>定义一个新用户，必须包含以下几项属性。</p>
<ol>
<li>
<p><strong>username</strong></p>
<p>username用于指定登录用户名，这是全局唯一属性。该属性比较简单，这里就不展开介绍了。</p>
</li>
<li>
<p><strong>password</strong></p>
<p>password用于设置登录密码，支持明文、SHA256加密和double_sha1加密三种形式，可以任选其中一种进行设置。现在分别介绍它们的使用方法。</p>
<p>（1）明文密码：在使用明文密码的时候，直接通过password标签定义，例如下面的代码。</p>
<pre><code class="language-xml">&lt;password&gt;123&lt;/password&gt;
</code></pre>
<p>如果password为空，则表示免密码登录：</p>
<pre><code class="language-xml">&lt;password&gt;&lt;/password&gt;
</code></pre>
<p>（2）SHA256加密：在使用SHA256加密算法的时候，需要通过password_sha256_hex标签定义密码，例如下面的代码。</p>
<pre><code class="language-xml">&lt;password_sha256_hex&gt;a665a45920422f9d417e4867efdc4fb8a04a1f3fff1fa07e998e86f7f7a27ae3&lt;/password_sha256_hex&gt;
</code></pre>
<p>可以执行下面的命令获得密码的加密串，例如对明文密码123进行加密：</p>
<pre><code class="language-shell"># echo -n 123 | openssl dgst -sha256
(stdin)= a665a45920422f9d417e4867efdc4fb8a04a1f3fff1fa07e998e86f7f7a27ae3
</code></pre>
<p>（3）double_sha1加密：在使用double_sha1加密算法的时候，则需要通过password_double_sha1_hex标签定义密码，例如下面的代码。</p>
<pre><code class="language-xml">&lt;password_double_sha1_hex&gt;23ae809ddacaf96af0fd78ed04b6a265e05aa257&lt;/password_double_sha1_hex&gt;
</code></pre>
<p>可以执行下面的命令获得密码的加密串，例如对明文密码123进行加密：</p>
<pre><code class="language-shell"># echo -n 123 | openssl dgst -sha1 -binary | openssl dgst -sha1
(stdin)= 23ae809ddacaf96af0fd78ed04b6a265e05aa257
</code></pre>
</li>
<li>
<p><strong>networks</strong></p>
<p>networks表示被允许登录的网络地址，用于限制用户登录的客户端地址，关于这方面参考<a href="clickhouse/../clickhouse/manage_authority.html">权限管理</a></p>
</li>
<li>
<p><strong>profile</strong></p>
<p>用户所使用的profile配置，直接引用相应的名称即可，例如：</p>
<pre><code class="language-xml">&lt;default&gt;
    &lt;profile&gt;default&lt;/profile&gt;
&lt;/default&gt;
</code></pre>
<p>该配置的语义表示，用户default使用了名为default的profile。</p>
</li>
<li>
<p><strong>quota</strong></p>
<p><code>quota</code>用于设置该用户能够使用的资源限额，可以理解成一种熔断机制。关于这方面参考<a href="clickhouse/../clickhouse/manage_circuit.html">熔断机制</a></p>
<p>现在用一个完整的示例说明用户的定义方法。首先创建一个使用明文密码的用户user_plaintext：</p>
<pre><code class="language-xml">&lt;yandex&gt;
    &lt;profiles&gt;
        ……
    &lt;/profiles&gt;
    &lt;users&gt;
        &lt;default&gt;&lt;!—默认用户 --&gt;
        ……
        &lt;/default&gt;
        &lt;user_plaintext&gt;
        &lt;password&gt;123&lt;/password&gt;
        &lt;networks&gt;
            &lt;ip&gt;::/0&lt;/ip&gt;
        &lt;/networks&gt;
        &lt;profile&gt;normal_1&lt;/profile&gt;
        &lt;quota&gt;default&lt;/quota&gt;
        &lt;/user_plaintext&gt;
</code></pre>
<p>由于配置了密码，所以在登录的时候需要附带密码参数：</p>
<pre><code class="language-shell"># clickhouse-client -h 10.37.129.10 -u user_plaintext --password 123
Connecting to 10.37.129.10:9000 as user user_plaintext.
</code></pre>
<p>接下来是两组使用了加密算法的用户，首先是用户user_sha256：</p>
<pre><code class="language-xml">&lt;user_sha256&gt;
    &lt;!-- echo -n 123 | openssl dgst -sha256 !--&gt;
    &lt;password_sha256_hex&gt;a665a45920422f9d417e4867efdc4fb8a04a1f3fff1fa07e998e86f7f7a27ae3&lt;/password_sha256_hex&gt;
    &lt;networks&gt;
        &lt;ip&gt;::/0&lt;/ip&gt;
    &lt;/networks&gt;
    &lt;profile&gt;default&lt;/profile&gt;
    &lt;quota&gt;default&lt;/quota&gt;
&lt;/user_sha256&gt;
</code></pre>
<p>然后是用户user_double_sha1：</p>
<pre><code class="language-xml">&lt;user_double_sha1&gt;
    &lt;!-- echo -n 123 | openssl dgst -sha1 -binary | openssl dgst -sha1 !--&gt;
    &lt;password_double_sha1_hex&gt;23ae809ddacaf96af0fd78ed04b6a265e05aa257&lt;/pass-word_double_sha1_hex&gt;
    &lt;networks&gt;
        &lt;ip&gt;::/0&lt;/ip&gt;
    &lt;/networks&gt;
    &lt;profile&gt;default&lt;/profile&gt;
    &lt;quota&gt;limit_1&lt;/quota&gt;
&lt;/user_double_sha1&gt;
</code></pre>
<p>这些用户在登录时同样需要附带加密前的密码，例如：</p>
<pre><code class="language-shell"># clickhouse-client -h 10.37.129.10 -u user_sha256 --password 123
Connecting to 10.37.129.10:9000 as user user_sha256.
</code></pre>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="权限管理"><a class="header" href="#权限管理">权限管理</a></h1>
<p>权限管理是一个始终都绕不开的话题，ClickHouse分别从<code>访问</code>、<code>查询</code>和<code>数据</code>等角度出发，层层递进，为我们提供了一个较为立体的权限体系。</p>
<div style="break-before: page; page-break-before: always;"></div><ul>
<li><a href="clickhouse/authority_access.html#%E8%AE%BF%E9%97%AE%E6%9D%83%E9%99%90">访问权限</a>
<ul>
<li><a href="clickhouse/authority_access.html#1%E7%BD%91%E7%BB%9C%E8%AE%BF%E9%97%AE%E6%9D%83%E9%99%90">1.网络访问权限</a></li>
<li><a href="clickhouse/authority_access.html#2%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E5%AD%97%E5%85%B8%E8%AE%BF%E9%97%AE%E6%9D%83%E9%99%90">2.数据库与字典访问权限</a></li>
</ul>
</li>
</ul>
<h1 id="访问权限"><a class="header" href="#访问权限">访问权限</a></h1>
<p>访问层控制是整个权限体系的第一层防护，它又可进一步细分成两类权限。</p>
<h2 id="1网络访问权限"><a class="header" href="#1网络访问权限">1.网络访问权限</a></h2>
<p>网络访问权限使用networks标签设置，用于限制某个用户登录的客户端地址，有IP地址、host主机名称以及正则匹配三种形式，可以任选其中一种进行设置。</p>
<p>（1）IP地址：直接使用IP地址进行设置。</p>
<pre><code class="language-xml">&lt;ip&gt;127.0.0.1&lt;/ip&gt;
</code></pre>
<p>（2）host主机名称：通过host主机名称设置。</p>
<pre><code class="language-xml">&lt;host&gt;ch5.nauu.com&lt;/host&gt;
</code></pre>
<p>（3）正则匹配：通过表达式来匹配host名称。</p>
<pre><code class="language-xml">&lt;host&gt;^ch\d.nauu.com$&lt;/host&gt;
</code></pre>
<p>现在用一个示例说明：</p>
<pre><code class="language-xml">&lt;user_normal&gt;
  &lt;password&gt;&lt;/password&gt;
  &lt;networks&gt;
    &lt;ip&gt;10.37.129.13&lt;/ip&gt;
  &lt;/networks&gt;
  &lt;profile&gt;default&lt;/profile&gt;
  &lt;quota&gt;default&lt;/quota&gt;
&lt;/user_normal&gt;
</code></pre>
<p>用户user_normal限制了客户端IP，在设置之后，该用户将只能从指定的地址登录。此时如果从非指定IP的地址进行登录，例如：</p>
<pre><code class="language-shell"># 从10.37.129.10登录
&gt; clickhouse-client -u user_normal
</code></pre>
<p>则将会得到如下错误：</p>
<pre><code class="language-shell">DB::Exception: User user_normal is not allowed to connect from address 10.37.129.10.
</code></pre>
<h2 id="2数据库与字典访问权限"><a class="header" href="#2数据库与字典访问权限">2.数据库与字典访问权限</a></h2>
<p>在客户端连入服务之后，可以进一步限制某个用户数据库和字典的访问权限，它们分别通过allow_databases和allow_dictionaries标签进行设置。如果不进行任何定义，则表示不进行限制。现在继续在用户user_normal的定义中增加权限配置：</p>
<pre><code class="language-xml">&lt;user_normal&gt;
  ……
  &lt;allow_databases&gt;
    &lt;database&gt;default&lt;/database&gt;
    &lt;database&gt;test_dictionaries&lt;/database&gt;
  &lt;/allow_databases&gt;
  &lt;allow_dictionaries&gt;
    &lt;dictionary&gt;test_flat_dict&lt;/dictionary&gt;
  &lt;/allow_dictionaries&gt;
&lt;/user_normal&gt;
</code></pre>
<p>通过上述操作，该用户在登录之后，将只能看到为其开放了访问权限的数据库和字典。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="查询权限"><a class="header" href="#查询权限">查询权限</a></h1>
<p>查询权限是整个权限体系的第二层防护，它决定了一个用户能够执行的查询语句。查询权限可以分成以下五类：</p>
<ul>
<li>
<p><strong>读权限</strong>：包括SELECT、EXISTS、SHOW和DESCRIBE查询。</p>
</li>
<li>
<p><strong>写权限</strong>：包括INSERT和OPTIMIZE查询。</p>
</li>
<li>
<p><strong>设置权限</strong>：包括SET查询。</p>
</li>
<li>
<p><strong>DDL权限</strong>：包括CREATE、DROP、ALTER、RENAME、ATTACH、DETACH和TRUNCATE查询。</p>
</li>
<li>
<p><strong>其他权限</strong>：包括KILL和USE查询，任何用户都可以执行这些查询。</p>
</li>
</ul>
<p>上述这五类权限，通过以下两项配置标签控制：</p>
<ul>
<li>
<p>（1）<strong>readonly</strong>：读权限、写权限和设置权限均由此标签控制，它有三种取值。</p>
<ul>
<li><strong>当取值为0时</strong>，不进行任何限制（默认值）。</li>
<li><strong>当取值为1时</strong>，只拥有读权限（只能执行SELECT、EXISTS、SHOW和DESCRIBE）。</li>
<li><strong>当取值为2时</strong>，拥有读权限和设置权限（在读权限基础上，增加了SET查询）。</li>
</ul>
</li>
<li>
<p>（2）<strong>allow_ddl</strong>：DDL权限由此标签控制，它有两种取值。</p>
<ul>
<li>
<p><strong>当取值为0时</strong>，不允许DDL查询。</p>
</li>
<li>
<p><strong>当取值为1时</strong>，允许DDL查询（默认值）。</p>
</li>
</ul>
</li>
</ul>
<p>现在继续用一个示例说明。与刚才的配置项不同，<code>readonly</code>和<code>allow_ddl</code>需要定义在用户profiles中，例如：</p>
<pre><code class="language-xml">&lt;profiles&gt;        
  &lt;normal&gt; &lt;!-- 只有read读权限--&gt;
    &lt;readonly&gt;1&lt;/readonly&gt;
    &lt;allow_ddl&gt;0&lt;/allow_ddl&gt;
  &lt;/normal&gt;
  &lt;normal_1&gt; &lt;!-- 有读和设置参数权限--&gt;
    &lt;readonly&gt;2&lt;/readonly&gt;
    &lt;allow_ddl&gt;0&lt;/allow_ddl&gt;
  &lt;/normal_1&gt;
</code></pre>
<p>继续在先前的profiles配置中追加了两个新角色。其中，normal只有读权限，而normal_1则有读和设置参数的权限，它们都没有DDL查询的权限。</p>
<p>再次修改用户的user_normal的定义，将它的profile设置为刚追加的normal，这意味着该用户只有读权限。现在开始验证权限的设置是否生效。使用user_normal登录后尝试写操作：</p>
<pre><code class="language-sql">--登录
# clickhouse-client -h 10.37.129.10 -u user_normal

--写操作
:) INSERT INTO TABLE test_ddl VALUES (1)

DB::Exception: Cannot insert into table in readonly mode.
</code></pre>
<p>可以看到，写操作如期返回了异常。接着执行DDL查询，会发现该操作同样会被限制执行：</p>
<pre><code class="language-sql">:) CREATE DATABASE test_3

DB::Exception: Cannot create database in readonly mode.
</code></pre>
<p>至此，权限设置已然生效。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="数据行级权限"><a class="header" href="#数据行级权限">数据行级权限</a></h1>
<p>数据权限是整个权限体系中的第三层防护，它决定了一个用户能够看到什么数据。数据权限使用databases标签定义，它是用户定义中的一项选填设置。database通过定义用户级别的查询过滤器来实现数据的行级粒度权限，它的定义规则如下所示：</p>
<pre><code class="language-xml">&lt;databases&gt;
  &lt;database_name&gt;&lt;!--数据库名称--&gt;
    &lt;table_name&gt;&lt;!--表名称--&gt;
      &lt;filter&gt; id &lt; 10&lt;/filter&gt;&lt;!--数据过滤条件--&gt;
        &lt;/table_name&gt;
      &lt;/database_name&gt;
</code></pre>
<p>其中，database_name表示数据库名称；table_name表示表名称；而filter则是权限过滤的关键所在，它等同于定义了一条WHERE条件子句，与WHERE子句类似，它支持组合条件。现在用一个示例说明。这里还是用user_normal，为它追加databases定义：</p>
<pre><code class="language-xml">&lt;user_normal&gt;
  ……
  &lt;databases&gt;
    &lt;default&gt;&lt;!--默认数据库--&gt;
      &lt;test_row_level&gt;&lt;!—表名称--&gt;
        &lt;filter&gt;id &lt; 10&lt;/filter&gt;
          &lt;/test_row_level&gt;

        &lt;!—支持组合条件 
        &lt;test_query_all&gt;
          &lt;filter&gt;id &lt;= 100 or repo &gt;= 100&lt;/filter&gt;
            &lt;/test_query_all&gt; --&gt;
          &lt;/default&gt;
        &lt;/databases&gt;
</code></pre>
<p>基于上述配置，通过为user_normal用户增加全局过滤条件，实现了该用户在数据表default.test_row_level的行级粒度数据上的权限设置。test_row_level的表结构如下所示：</p>
<pre><code class="language-sql">CREATE TABLE test_row_level(
  id UInt64,
  name UInt64
)
ENGINE = MergeTree()
ORDER BY id
</code></pre>
<p>下面验证权限是否生效。首先写入测试数据：</p>
<pre><code class="language-sql">INSERT INTO TABLE test_row_level VALUES (1,100),(5,200),(20,200),(30,110)
</code></pre>
<p>写入之后，登录user_normal用户并查询这张数据表：</p>
<pre><code class="language-sql">SELECT * FROM test_row_level

┌─id──┬─name──┐
│  1  │  100  │
│  5  │  200  │
└─────┴───────┘
</code></pre>
<p>可以看到，在返回的结果数据中，只包含<code>&lt;filter&gt; id&lt;10 &lt;/filter&gt;</code>的部分，证明权限设置生效了。</p>
<p>那么数据权限的设定是如何实现的呢？进一步分析它的执行日志：</p>
<pre><code class="language-sql">Expression
    Expression
        Filter –增加了过滤的步骤
            MergeTreeThread
</code></pre>
<p>可以发现，上述代码在普通查询计划的基础之上自动附加了Filter过滤的步骤。</p>
<p>对于数据权限的使用有一点需要明确，在使用了这项功能之后，PREWHERE优化将不再生效，例如执行下面的查询语句：</p>
<pre><code class="language-sql">SELECT * FROM test_row_level where name = 5
</code></pre>
<p>此时如果使用了数据权限，那么这条SQL将不会进行PREWHERE优化；反之，如果没有设置数据权限，则会进行PREWHERE优化，例如：</p>
<pre><code class="language-sql">InterpreterSelectQuery: MergeTreeWhereOptimizer: condition &quot;name = 5&quot; moved to PREWHERE
</code></pre>
<p>所以，是直接利用ClickHouse的内置过滤器，还是通过拼接WHERE查询条件的方式实现行级数据权限，需要用户在具体的使用场景中进行权衡。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="熔断机制"><a class="header" href="#熔断机制">熔断机制</a></h1>
<p>熔断是限制资源被过度使用的一种自我保护机制，当使用的资源数量达到阈值时，那么正在进行的操作会被自动中断。按照使用资源统计方式的不同，熔断机制可以分为两类。</p>
<h2 id="1根据时间周期的累积用量熔断"><a class="header" href="#1根据时间周期的累积用量熔断">1.根据时间周期的累积用量熔断</a></h2>
<p>在这种方式下，系统资源的用量是按照时间周期累积统计的，当累积量达到阈值，则直到下个计算周期开始之前，该用户将无法继续进行操作。这种方式通过users.xml内的quotas标签来定义资源配额。以下面的配置为例：</p>
<pre><code class="language-xml">&lt;quotas&gt;
  &lt;default&gt; &lt;!-- 自定义名称 --&gt;
    &lt;interval&gt;
      &lt;duration&gt;3600&lt;/duration&gt;&lt;!-- 时间周期 单位：秒 --&gt;
      &lt;queries&gt;0&lt;/queries&gt;
      &lt;errors&gt;0&lt;/errors&gt;
      &lt;result_rows&gt;0&lt;/result_rows&gt;
      &lt;read_rows&gt;0&lt;/read_rows&gt;
      &lt;execution_time&gt;0&lt;/execution_time&gt;
    &lt;/interval&gt;
  &lt;/default&gt;
&lt;/quotas&gt;
</code></pre>
<p>其中，各配置项的含义如下：</p>
<ul>
<li><strong>default</strong>：表示自定义名称，全局唯一。</li>
<li><strong>duration</strong>：表示累积的时间周期，单位是秒。</li>
<li><strong>queries</strong>：表示在周期内允许执行的查询次数，0表示不限制。</li>
<li><strong>errors</strong>：表示在周期内允许发生异常的次数，0表示不限制。</li>
<li><strong>result_row</strong>：表示在周期内允许查询返回的结果行数，0表示不限制。</li>
<li><strong>read_rows</strong>：表示在周期内在分布式查询中，允许远端节点读取的数据行数，0表示不限制。</li>
<li><strong>execution_time</strong>：表示周期内允许执行的查询时间，单位是秒，0表示不限制。</li>
</ul>
<p>由于上述示例中各配置项的值均为0，所以对资源配额不做任何限制。现在继续声明另外一组资源配额：</p>
<pre><code class="language-xml">&lt;limit_1&gt;
  &lt;interval&gt;
    &lt;duration&gt;3600&lt;/duration&gt;
    &lt;queries&gt;100&lt;/queries&gt;
    &lt;errors&gt;100&lt;/errors&gt;
    &lt;result_rows&gt;100&lt;/result_rows&gt;
    &lt;read_rows&gt;2000&lt;/read_rows&gt;
    &lt;execution_time&gt;3600&lt;/execution_time&gt;
  &lt;/interval&gt;
&lt;/limit_1&gt;
</code></pre>
<p>为了便于演示，在这个名为limit_1的配额中，在1小时（3600秒）的周期内只允许100次查询。继续修改用户user_normal的配置，为它添加limit_1配额的引用：</p>
<pre><code class="language-xml">&lt;user_normal&gt;
  &lt;password&gt;&lt;/password&gt;
  &lt;networks&gt;
    &lt;ip&gt;10.37.129.13&lt;/ip&gt;
  &lt;/networks&gt;
  &lt;profile&gt;normal&lt;/profile&gt;
  &lt;quota&gt;limit_1&lt;/quota&gt;
&lt;/user_normal&gt;
</code></pre>
<p>最后使用user_normal用户登录，测试配额是否生效。在执行了若干查询以后，会发现之后的任何一次查询都将会得到如下异常：</p>
<pre><code class="language-sql">Quota for user 'user_normal' for 1 hour has been exceeded. Total result rows: 149, max: 100. Interval will end at 2019-08-29 22:00:00. Name of quota template: 'limit_1'..
</code></pre>
<p>上述结果证明熔断机制已然生效。</p>
<h2 id="2根据单次查询的用量熔断"><a class="header" href="#2根据单次查询的用量熔断">2.根据单次查询的用量熔断</a></h2>
<p>在这种方式下，系统资源的用量是按照单次查询统计的，而具体的熔断规则，则是由许多不同配置项组成的，这些配置项需要定义在用户profile中。如果某次查询使用的资源用量达到了阈值，则会被中断。以配置项max_memory_usage为例，它限定了单次查询可以使用的内存用量，在默认的情况下其规定不得超过10 GB，如果一次查询的内存用量超过10 GB，则会得到异常。需要注意的是，在单次查询的用量统计中，ClickHouse是以分区为最小单元进行统计的（不是数据行的粒度），这意味着单次查询的实际内存用量是有可能超过阈值的。</p>
<p>由于篇幅所限，完整的熔断配置请参阅官方手册，这里只列举个别的常用配置项。</p>
<p>首先介绍一组针对普通查询的熔断配置。</p>
<ul>
<li>
<p>（1）<strong>max_memory_usage</strong>：在单个ClickHouse服务进程中，运行一次查询限制使用的最大内存量，默认值为10 GB，其配置形式如下。</p>
<pre><code class="language-xml">&lt;max_memory_usage&gt;10000000000&lt;/max_memory_usage&gt;
</code></pre>
</li>
<li>
<p>（2）<strong>max_memory_usage_for_user</strong>：在单个ClickHouse服务进程中，以用户为单位进行统计，单个用户在运行查询时限制使用的最大内存量，默认值为0，即不做限制。</p>
</li>
<li>
<p>（3）<strong>max_memory_usage_for_all_queries</strong>：在单个ClickHouse服务进程中，所有运行的查询累加在一起所限制使用的最大内存量，默认为0，即不做限制。</p>
</li>
</ul>
<p>接下来介绍的是一组与数据写入和聚合查询相关的熔断配置。</p>
<ul>
<li>
<p>（1）<strong>max_partitions_per_insert_block</strong>：在单次INSERT写入的时候，限制创建的最大分区个数，默认值为100个。如果超出这个阈值，将会出现如下异常：</p>
<pre><code class="language-xml">Too many partitions for single INSERT block ……
</code></pre>
</li>
<li>
<p>（2）<strong>max_rows_to_group_by</strong>：在执行GROUP BY聚合查询的时候，限制去重后聚合</p>
<p>KEY的最大个数，默认值为0，即不做限制。当超过阈值时，其处理方式由group_by_overflow_mode参数决定。</p>
</li>
<li>
<p>（3）<strong>group_by_overflow_mode</strong>：当max_rows_to_group_by熔断规则触发时，group_by_overflow_mode将会提供三种处理方式。</p>
<ul>
<li>throw：抛出异常，此乃默认值。</li>
<li>break：立即停止查询，并返回当前数据。</li>
<li>any：仅根据当前已存在的聚合KEY继续完成聚合查询。</li>
</ul>
</li>
<li>
<p>（4）<strong>max_bytes_before_external_group_by</strong>：在执行GROUP BY聚合查询的时候，限制使用的最大内存量，默认值为0，即不做限制。当超过阈值时，聚合查询将会进一步借用本地磁盘。</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="数据备份"><a class="header" href="#数据备份">数据备份</a></h1>
<p>参考: <a href="clickhouse/../clickhouse/op_partition_backup.html">备份与还原分区</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="服务监控"><a class="header" href="#服务监控">服务监控</a></h1>
<p>基于原生功能对ClickHouse进行监控，可以从两方面着手——<code>系统表</code>和<code>查询日志</code>。接下来分别介绍它们的使用方法。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="常用语句"><a class="header" href="#常用语句">常用语句</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="查询数据大小"><a class="header" href="#查询数据大小">查询数据大小</a></h1>
<h2 id="mysql-1"><a class="header" href="#mysql-1">MYSQL</a></h2>
<pre><code class="language-sql">select
 table_schema as '数据库',
 table_name as '表名',
 table_rows as '记录数',
 truncate(data_length / 1024 / 1024, 2) as '数据容量(MB)',
 truncate(index_length / 1024 / 1024, 2) as '索引容量(MB)'
from
 information_schema.tables
order by
 data_length desc,
 index_length desc;
</code></pre>
<h2 id="clickhouse-1"><a class="header" href="#clickhouse-1">ClickHouse</a></h2>
<h3 id="查看数据库容量行数压缩率"><a class="header" href="#查看数据库容量行数压缩率">查看数据库容量、行数、压缩率</a></h3>
<pre><code class="language-sql">SELECT 
    sum(rows) AS `总行数`,
    formatReadableSize(sum(data_uncompressed_bytes)) AS `原始大小`,
    formatReadableSize(sum(data_compressed_bytes)) AS `压缩大小`,
    round((sum(data_compressed_bytes) / sum(data_uncompressed_bytes)) * 100, 0) AS `压缩率`
FROM system.parts
</code></pre>
<p>输出:</p>
<pre><code class="language-shell">┌────总行数─┬─原始大小──┬─压缩大小─┬─压缩率─┐
│ 326819026 │ 77.15 GiB │ 5.75 GiB │      7 │
└───────────┴───────────┴──────────┴────────┘

1 rows in set. Elapsed: 0.047 sec. Processed 1.04 thousand rows, 520.93 KB (21.95 thousand
rows/s., 11.02 MB/s.) 
</code></pre>
<h3 id="查看数据表容量行数压缩率"><a class="header" href="#查看数据表容量行数压缩率">查看数据表容量、行数、压缩率</a></h3>
<pre><code class="language-sql">SELECT 
    table AS `表名`,
    sum(rows) AS `总行数`,
    formatReadableSize(sum(data_uncompressed_bytes)) AS `原始大小`,
    formatReadableSize(sum(data_compressed_bytes)) AS `压缩大小`,
    round((sum(data_compressed_bytes) / sum(data_uncompressed_bytes)) * 100, 0) AS `压缩率`
FROM system.parts
WHERE table IN ('temp_1')
GROUP BY table
</code></pre>
<p>输出:</p>
<pre><code class="language-shell">┌─表名───┬──总行数─┬─原始大小───┬─压缩大小──┬─压缩率─┐
│ temp_1 │ 3127523 │ 838.21 MiB │ 60.04 MiB │      7 │
└────────┴─────────┴────────────┴───────────┴────────┘

1 rows in set. Elapsed: 0.008 sec.
</code></pre>
<h3 id="查看数据表分区信息"><a class="header" href="#查看数据表分区信息">查看数据表分区信息</a></h3>
<pre><code class="language-sql">--查看测试表在19年12月的分区信息
SELECT 
    partition AS `分区`,
    sum(rows) AS `总行数`,
    formatReadableSize(sum(data_uncompressed_bytes)) AS `原始大小`,
    formatReadableSize(sum(data_compressed_bytes)) AS `压缩大小`,
    round((sum(data_compressed_bytes) / sum(data_uncompressed_bytes)) * 100, 0) AS `压缩率`
FROM system.parts
WHERE (database IN ('default')) AND (table IN ('temp_1')) AND (partition LIKE '2019-12-%')
GROUP BY partition
ORDER BY partition ASC
</code></pre>
<p>输出:</p>
<pre><code class="language-shell">┌─分区───────┬─总行数─┬─原始大小──┬─压缩大小───┬─压缩率─┐
│ 2019-12-01 │     24 │ 6.17 KiB  │ 2.51 KiB   │     41 │
│ 2019-12-02 │   9215 │ 2.45 MiB  │ 209.74 KiB │      8 │
│ 2019-12-03 │  17265 │ 4.46 MiB  │ 453.78 KiB │     10 │
│ 2019-12-04 │  27741 │ 7.34 MiB  │ 677.25 KiB │      9 │
│ 2019-12-05 │  31500 │ 8.98 MiB  │ 469.30 KiB │      5 │
│ 2019-12-06 │    157 │ 37.50 KiB │ 4.95 KiB   │     13 │
│ 2019-12-07 │    110 │ 32.75 KiB │ 3.86 KiB   │     12 │
└────────────┴────────┴───────────┴────────────┴────────┘

7 rows in set. Elapsed: 0.005 sec. 
</code></pre>
<h3 id="查看数据表字段的信息"><a class="header" href="#查看数据表字段的信息">查看数据表字段的信息</a></h3>
<pre><code class="language-sql">SELECT 
    column AS `字段名`,
    any(type) AS `类型`,
    formatReadableSize(sum(column_data_uncompressed_bytes)) AS `原始大小`,
    formatReadableSize(sum(column_data_compressed_bytes)) AS `压缩大小`,
    sum(rows) AS `行数`
FROM system.parts_columns
WHERE (database = 'default') AND (table = 'temp_1')
GROUP BY column
ORDER BY column ASC
</code></pre>
<p>输出:</p>
<pre><code class="language-shell">┌─字段名───────────┬─类型─────┬─原始大小───┬─压缩大小───┬────行数─┐
│ a                │ String   │ 23.83 MiB  │ 134.13 KiB │ 3127523 │
│ b                │ String   │ 19.02 MiB  │ 127.72 KiB │ 3127523 │
│ c                │ String   │ 5.97 MiB   │ 49.09 KiB  │ 3127523 │
│ d             │ String   │ 3.95 MiB   │ 532.86 KiB │ 3127523 │
│ e                │ String   │ 5.17 MiB   │ 49.47 KiB  │ 3127523 │
│ totalDate        │ DateTime │ 11.93 MiB  │ 1.26 MiB   │ 3127523 │
└──────────────────┴──────────┴────────────┴────────────┴─────────┘
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script type="text/javascript">
            var socket = new WebSocket("ws://localhost:3000/__livereload");
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
    </body>
</html>
